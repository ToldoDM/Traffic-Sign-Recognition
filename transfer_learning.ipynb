{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "95feb99553e5f381"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T15:51:50.440247Z",
     "start_time": "2024-05-08T15:51:50.424620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch.utils.data import random_split\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import urllib.request"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T15:51:50.455874Z",
     "start_time": "2024-05-08T15:51:50.440247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(123)  # for replication\n",
    "os.makedirs('./models', exist_ok=True)"
   ],
   "id": "625f7f9d2019b024",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Download the dataset",
   "id": "f7f8dbccd37131cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T15:51:50.487126Z",
     "start_time": "2024-05-08T15:51:50.455874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def download_file(url, file_name):\n",
    "    if not os.path.exists('dataset/' + file_name):\n",
    "        with urllib.request.urlopen(url) as response, open('dataset/' + file_name, 'wb') as out_file:\n",
    "            content_length = int(response.headers['Content-Length'])\n",
    "            with tqdm(total=content_length, unit='B', unit_scale=True, desc=url.split('/')[-1]) as pbar:\n",
    "                while True:\n",
    "                    chunk = response.read(1024)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    out_file.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "    else:\n",
    "        print(f\"{file_name} already exists.\")\n",
    "\n",
    "\n",
    "os.makedirs(\"dataset/\", exist_ok=True)\n",
    "# Training\n",
    "download_file('https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip',\n",
    "              'GTSRB_Final_Training_Images.zip')\n",
    "# Testing\n",
    "download_file('https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip',\n",
    "              'GTSRB_Final_Test_Images.zip')\n",
    "# Ground truth\n",
    "download_file('https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip',\n",
    "              'GTSRB_Final_Test_GT.zip')"
   ],
   "id": "cc5fa7a029122762",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTSRB_Final_Training_Images.zip already exists.\n",
      "GTSRB_Final_Test_Images.zip already exists.\n",
      "GTSRB_Final_Test_GT.zip already exists.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract zip files",
   "id": "c093146128e9ddcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T15:52:45.871056Z",
     "start_time": "2024-05-08T15:51:50.487126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_file(file_name):\n",
    "    with zipfile.ZipFile(f\"dataset/{file_name}\", 'r') as zip_ref:\n",
    "        file_list = zip_ref.namelist()\n",
    "        with tqdm(total=len(file_list), desc=\"Extracting\") as pbar:\n",
    "            for file in file_list:\n",
    "                zip_ref.extract(file, 'dataset/')\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "extract_file('GTSRB_Final_Training_Images.zip')\n",
    "extract_file('GTSRB_Final_Test_Images.zip')\n",
    "extract_file('GTSRB_Final_Test_GT.zip')"
   ],
   "id": "389d12c94d866d1a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 39299/39299 [00:40<00:00, 975.33it/s] \n",
      "Extracting: 100%|██████████| 12635/12635 [00:14<00:00, 878.73it/s] \n",
      "Extracting: 100%|██████████| 1/1 [00:00<00:00, 250.00it/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading CSV file",
   "id": "104f0cad0ed5e5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T15:52:45.981609Z",
     "start_time": "2024-05-08T15:52:45.875061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#IMAGES: './dataset/GTSRB/test_images'\n",
    "#CSV ANNOTATIONS: './dataset/GTSRB/test_images/GT-final_test.csv'\n",
    "def csv_loader(csv_path):\n",
    "    data = np.loadtxt(csv_path,\n",
    "                      delimiter=\";\", dtype=str, skiprows=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "#You should download the testset ('GTSRB_Final_Test_Images.zip') from the website which contains only the images\n",
    "#Then you have to download the ground truth csv ('GTSRB_Final_Test_GT.zip') from the website and paste it into the testset images folder\n",
    "annotations = csv_loader('./dataset/GT-final_test.csv')\n",
    "#sort the annotations\n",
    "annotations = annotations[:, [0, 7]]\n",
    "num_samples = len(annotations)\n",
    "#Column 0: filename - Column 1: classid\n",
    "annotations = annotations[annotations[:, 1].astype(int).argsort()]"
   ],
   "id": "a53c1f1a5b33603f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Making training data accordingly",
   "id": "bd60ed935fd3b869"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T15:52:46.276950Z",
     "start_time": "2024-05-08T15:52:45.985605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def move_directories(source, destination):\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "    # Get a list of all directories in the source directory\n",
    "    directories = [d for d in os.listdir(source) if os.path.isdir(os.path.join(source, d))]\n",
    "\n",
    "    # Move each directory to the destination\n",
    "    for directory in tqdm(directories):\n",
    "        source_path = os.path.join(source, directory)\n",
    "        destination_path = os.path.join(destination, directory)\n",
    "        shutil.move(source_path, destination_path)\n",
    "\n",
    "\n",
    "# Move directories with contents\n",
    "move_directories(\"./dataset/GTSRB/Final_Training/Images\", \"./dataset/GTSRB/train\")\n",
    "shutil.rmtree(\"./dataset/GTSRB/Final_Training\")"
   ],
   "id": "dc6f492567de374f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Destination path './dataset/GTSRB/train\\00000\\00000' already exists",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mError\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 15\u001B[0m\n\u001B[0;32m     11\u001B[0m         shutil\u001B[38;5;241m.\u001B[39mmove(source_path, destination_path)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Move directories with contents\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[43mmove_directories\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./dataset/GTSRB/Final_Training/Images\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./dataset/GTSRB/train\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m shutil\u001B[38;5;241m.\u001B[39mrmtree(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./dataset/GTSRB/Final_Training\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[20], line 11\u001B[0m, in \u001B[0;36mmove_directories\u001B[1;34m(source, destination)\u001B[0m\n\u001B[0;32m      9\u001B[0m source_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(source, directory)\n\u001B[0;32m     10\u001B[0m destination_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(destination, directory)\n\u001B[1;32m---> 11\u001B[0m \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmove\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdestination_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Traffic-Sign-Recognition\\lib\\shutil.py:814\u001B[0m, in \u001B[0;36mmove\u001B[1;34m(src, dst, copy_function)\u001B[0m\n\u001B[0;32m    811\u001B[0m     real_dst \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dst, _basename(src))\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(real_dst):\n\u001B[1;32m--> 814\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Error(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDestination path \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m already exists\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m real_dst)\n\u001B[0;32m    815\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    816\u001B[0m     os\u001B[38;5;241m.\u001B[39mrename(src, real_dst)\n",
      "\u001B[1;31mError\u001B[0m: Destination path './dataset/GTSRB/train\\00000\\00000' already exists"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Making test data accordingly",
   "id": "f097b4654916ac17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for class_id in tqdm(np.unique(annotations[:, 1]), desc='Class_ID'):\n",
    "    newpath = './dataset/GTSRB/test/' + class_id.zfill(5)\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    for image_filename in annotations[annotations[:, 1] == class_id]:\n",
    "        shutil.move('./dataset/GTSRB/Final_Test/Images/' + image_filename[0], newpath + '/' + image_filename[0])\n",
    "\n",
    "shutil.rmtree(\"./dataset/GTSRB/Final_Test\")"
   ],
   "id": "3015c24a4b068090",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Helper functions",
   "id": "920e26d20bf8c3c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_classes_preds(images, labels, preds, probs):\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx + 1, xticks=[], yticks=[])\n",
    "        norm_img = cv2.normalize(images[idx].cpu().numpy(), None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "        rgb_img = np.transpose(norm_img, (1, 2, 0)).astype(np.uint8)\n",
    "        plt.imshow(rgb_img)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            preds[idx],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[idx]),\n",
    "            color=(\"green\" if preds[idx] == labels[idx].item() else \"red\"))\n",
    "    return fig"
   ],
   "id": "5b5b2a8dbc382e69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading the train dataset",
   "id": "1e0e1c4761d44bcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Directory containing the train dataset\n",
    "train_dir = './dataset/GTSRB/train'\n",
    "\n",
    "# Load the dataset using the torchvision.datasets.ImageFolder\n",
    "train_dataset = datasets.ImageFolder(train_dir, ResNet50_Weights.IMAGENET1K_V2.transforms())\n",
    "train_size = len(train_dataset)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "print('Train size:', train_size)\n",
    "print('Class names:', class_names)\n",
    "\n",
    "# Use numpy to count occurrences of each class index in targets\n",
    "counts = np.bincount(train_dataset.targets)\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(class_names, counts, color='blue')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of images')\n",
    "plt.title('Number of Images per Class')\n",
    "plt.xticks(rotation=90)  # Rotate class names for better visibility if needed\n",
    "plt.yticks(np.arange(0, max(counts) + 10, 250))  # Adjust the range and step size as needed\n",
    "plt.show()"
   ],
   "id": "233a264dd2428bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1239b390bd17bb84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading the test dataset",
   "id": "8199467383be87c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Directory containing the test dataset\n",
    "test_dir = './dataset/GTSRB/test'\n",
    "\n",
    "# Load the dataset using the torchvision.datasets.ImageFolder\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=ResNet50_Weights.IMAGENET1K_V2.transforms())\n",
    "test_size = len(test_dataset)\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "print('Test size:', test_size)\n",
    "print('Class names:', class_names)\n",
    "\n",
    "# Use numpy to count occurrences of each class index in targets\n",
    "counts = np.bincount(test_dataset.targets)\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(class_names, counts, color='blue')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of images')\n",
    "plt.title('Number of Images per Class')\n",
    "plt.xticks(rotation=90)  # Rotate class names for better visibility if needed\n",
    "plt.yticks(np.arange(0, max(counts) + 10, 50))  # Adjust the range and step size as needed\n",
    "plt.show()\n"
   ],
   "id": "c995d79a7ef2dab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining the training phase",
   "id": "3191a2bde55202e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_model(trained_model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        trained_model.eval()\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = trained_model(images)\n",
    "            softmax_outputs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(softmax_outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = float(correct / total)\n",
    "    print('{} Model accuracy: {:.4f}'.format('Test phase - ', test_accuracy))\n",
    "    writer.add_scalar('Training/Test Accuracy', test_accuracy)\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "def train_model(device, model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=25,\n",
    "                model_name='trained_model'):\n",
    "    since = time.time()\n",
    "    time_train = 0\n",
    "    time_val = 0\n",
    "\n",
    "    # Save the initial model\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Choose the appropriate data loader\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                data_total_steps = len(train_loader)\n",
    "                data_loader = train_loader\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "                data_total_steps = len(val_loader)\n",
    "                data_loader = val_loader\n",
    "\n",
    "            for i, (images, labels) in enumerate(data_loader):\n",
    "                # time_t = epoch * len(data_loader) * i + i\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images)\n",
    "                    softmax_outputs = F.softmax(outputs, dim=1)\n",
    "                    probs, preds = torch.max(softmax_outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                #prints the stats every 20 steps (20 batches performed)\n",
    "                if (i + 1) % int(data_total_steps / 8) == 0:\n",
    "                    print(\n",
    "                        f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{data_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "                    # Log image predictions\n",
    "                    selected_indices = random.sample(range(len(images)), 4)  # Select 4 random indices\n",
    "                    selected_images = images[selected_indices]\n",
    "                    selected_labels = labels[selected_indices]\n",
    "                    selected_preds = preds[selected_indices]\n",
    "                    selected_probs = probs[selected_indices]\n",
    "                    if phase == 'train':\n",
    "                        writer.add_figure('Training/Training Predictions',\n",
    "                                          plot_classes_preds(selected_images, selected_labels, selected_preds,\n",
    "                                                             selected_probs),\n",
    "                                          global_step=time_train)\n",
    "                    else:\n",
    "                        writer.add_figure('Training/Validation Predictions',\n",
    "                                          plot_classes_preds(selected_images, selected_labels, selected_preds,\n",
    "                                                             selected_probs),\n",
    "                                          global_step=time_val)\n",
    "\n",
    "                # Log scalars\n",
    "                if phase == 'train':\n",
    "                    writer.add_scalar('Training/Training Loss',\n",
    "                                      loss.item(),\n",
    "                                      time_train)\n",
    "                    writer.add_scalar('Policy/Learning Rate',\n",
    "                                      np.array(scheduler.get_last_lr()),\n",
    "                                      time_train)\n",
    "                    time_train += 1\n",
    "                else:\n",
    "                    writer.add_scalar('Training/Validation Loss',\n",
    "                                      loss.item(),\n",
    "                                      time_val)\n",
    "                    time_val += 1\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(data_loader.dataset)\n",
    "\n",
    "            if phase == 'train':\n",
    "                print('{} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    'Train phase - ', epoch + 1, epoch_loss, epoch_acc))\n",
    "                writer.add_scalar('Training/Training Accuracy',\n",
    "                                  epoch_acc,\n",
    "                                  epoch)\n",
    "                if (epoch + 1) % max(int(num_epochs / 5), 1) == 0:  # checkpoint the model\n",
    "                    print(\"----> model checkpoint...\")\n",
    "                    torch.save(model, f'./models/trained_model_{model_name}_epoch_{epoch + 1}.pth')\n",
    "            else:\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('{} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    'Validation phase - ', epoch + 1, epoch_loss, epoch_acc))\n",
    "                writer.add_scalar('Training/Validation Accuracy',\n",
    "                                  epoch_acc,\n",
    "                                  epoch)\n",
    "                # Uncomment to use scheduler\n",
    "                #scheduler.step()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc:{:.4f}'.format(best_acc))\n",
    "    # Return the model with the best accuracy in the validation\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_dynamic_network(num_features, num_classes, neuron_list=None, dropout_values=None):\n",
    "    if neuron_list is None:\n",
    "        neuron_list = []\n",
    "    layers = []\n",
    "    num_layers = len(neuron_list)\n",
    "    # Input layer to first hidden layer\n",
    "    if num_layers > 0:\n",
    "        layers.append(nn.Linear(num_features, neuron_list[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        if dropout_values[0] != 0:\n",
    "            layers.append(nn.Dropout(dropout_values[0]))\n",
    "\n",
    "    # Additional hidden layers\n",
    "    for i in range(1, num_layers):\n",
    "        layers.append(nn.Linear(neuron_list[i - 1], neuron_list[i]))\n",
    "        layers.append(nn.ReLU())\n",
    "        if dropout_values[i] != 0:\n",
    "            layers.append(nn.Dropout(dropout_values[i]))\n",
    "\n",
    "    # Always include the final specified layer\n",
    "    layers.append(nn.Linear(neuron_list[-1] if num_layers > 0 else num_features, num_classes))\n",
    "    # layers.append(nn.Softmax(dim=1)) not needed cause cross entropy criterion\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ],
   "id": "d1388a73ca0b9760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Setup",
   "id": "596398e0642aca56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setting device for the computation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "hyperparams = {\n",
    "    \"num_epochs\": 15,\n",
    "    \"batch_size\": 64,\n",
    "    #optimizer\n",
    "    \"opt\": \"adam\",\n",
    "    \"learning_rate\": 2e-4,\n",
    "    #scheduler\n",
    "    \"decay_rate\": 0.5,\n",
    "    #nnet\n",
    "    \"neuron_layer_list\": [512, 256],\n",
    "    \"dropout_values\": [0.25, 0.25],\n",
    "}"
   ],
   "id": "50d7d9e3cbf71956",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setting up the model using ResNet50 as backbone",
   "id": "7d53679acd744b28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "model_name = 'ResNet50-vanilla_dataset'\n",
    "writer = SummaryWriter(f'runs/{model_name}')\n",
    "\n",
    "test_abs = int(len(train_dataset) * 0.8)\n",
    "train_subset, val_subset = random_split(\n",
    "    train_dataset, [test_abs, len(train_dataset) - test_abs])\n",
    "\n",
    "train_data_size = len(train_subset)\n",
    "\n",
    "# Create DataLoader instances for training and validation\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_subset,\n",
    "    batch_size=hyperparams[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=hyperparams[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=hyperparams[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "\n",
    "# Model initialization\n",
    "model = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Define the layers you want to add\n",
    "model.fc = create_dynamic_network(model.fc.in_features, num_classes=43, neuron_list=hyperparams[\"neuron_layer_list\"],\n",
    "                                  dropout_values=hyperparams[\"dropout_values\"])\n",
    "writer.add_graph(model, torch.rand(1, 3, 224, 224))\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function, optimizer, etc.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Set optimizers\n",
    "if hyperparams['opt'] == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.fc.parameters(), lr=hyperparams[\"learning_rate\"])\n",
    "elif hyperparams['opt'] == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.fc.parameters(), lr=hyperparams[\"learning_rate\"])\n",
    "elif hyperparams['opt'] == 'rmsprop':\n",
    "    optimizer = torch.optim.RMSprop(model.fc.parameters(), lr=hyperparams[\"learning_rate\"])\n",
    "else:\n",
    "    raise ValueError('Invalid optimizer provided')\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, factor=hyperparams[\"decay_rate\"], min_lr=1e-6,\n",
    "                                            mode='min', threshold=1e-3)"
   ],
   "id": "d53ebf690ba17e92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train the model",
   "id": "6a9c4fc45c415b8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train model\n",
    "trained_model = train_model(device=device, model=model, criterion=criterion, optimizer=optimizer,scheduler=scheduler,\n",
    "                            train_loader=train_loader, val_loader=val_loader, num_epochs=hyperparams[\"num_epochs\"],\n",
    "                            model_name=model_name)\n",
    "\n",
    "ta = test_model(trained_model=trained_model, test_loader=test_loader)\n",
    "writer.add_hparams({key: str(value) if isinstance(value, list) else value for key, value in hyperparams.items()},\n",
    "                   metric_dict={'Training/Test Accuracy': ta})"
   ],
   "id": "731771455515444c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Saving the trained model",
   "id": "e4d9605ef361a0d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Finished Training')\n",
    "torch.save(trained_model, f'./models/trained_model_{model_name}_final.pth')"
   ],
   "id": "9f5f26cdefec21bb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
