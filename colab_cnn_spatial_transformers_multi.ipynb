{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53bb43bad4c869b9",
   "metadata": {
    "id": "53bb43bad4c869b9"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "P_5LiGFJ3Akj",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:14:39.402678Z",
     "start_time": "2024-06-27T19:14:36.518573Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_5LiGFJ3Akj",
    "outputId": "3f140c27-1fc6-458e-f504-2e9ba18ac4ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in ./venv/lib/python3.11/site-packages (1.4.10)\n",
      "Requirement already satisfied: numpy<2,>=1.24.4 in ./venv/lib/python3.11/site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in ./venv/lib/python3.11/site-packages (from albumentations) (1.13.0)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in ./venv/lib/python3.11/site-packages (from albumentations) (0.23.2)\n",
      "Requirement already satisfied: PyYAML in ./venv/lib/python3.11/site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in ./venv/lib/python3.11/site-packages (from albumentations) (4.11.0)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in ./venv/lib/python3.11/site-packages (from albumentations) (1.4.2)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in ./venv/lib/python3.11/site-packages (from albumentations) (2.7.1)\n",
      "Requirement already satisfied: albucore>=0.0.11 in ./venv/lib/python3.11/site-packages (from albumentations) (0.0.12)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in ./venv/lib/python3.11/site-packages (from albumentations) (4.9.0.80)\n",
      "Requirement already satisfied: tomli>=2.0.1 in ./venv/lib/python3.11/site-packages (from albucore>=0.0.11->albumentations) (2.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic>=2.7.0->albumentations) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in ./venv/lib/python3.11/site-packages (from pydantic>=2.7.0->albumentations) (2.18.2)\n",
      "Requirement already satisfied: networkx>=2.8 in ./venv/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in ./venv/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.33 in ./venv/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./venv/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (2024.5.3)\n",
      "Requirement already satisfied: packaging>=21 in ./venv/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./venv/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.11/site-packages (from scikit-learn>=1.3.2->albumentations) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.11/site-packages (from scikit-learn>=1.3.2->albumentations) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: split-folders in ./venv/lib/python3.11/site-packages (0.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U albumentations\n",
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:14:43.189456Z",
     "start_time": "2024-06-27T19:14:39.404127Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "e7310ded-f8e0-4409-856d-570280543fd0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import ResNet152_Weights, ResNet50_Weights\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import splitfolders\n",
    "import data_augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6CCfxseGNAtf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:14:43.194029Z",
     "start_time": "2024-06-27T19:14:43.190531Z"
    },
    "id": "6CCfxseGNAtf"
   },
   "outputs": [],
   "source": [
    "def plot_classes_preds(images, labels, preds, probs):\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx + 1, xticks=[], yticks=[])\n",
    "        norm_img = cv2.normalize(images[idx].cpu().numpy(), None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "        rgb_img = np.transpose(norm_img, (1, 2, 0)).astype(np.uint8)\n",
    "        plt.imshow(rgb_img)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            preds[idx],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[idx]),\n",
    "            color=(\"green\" if preds[idx] == labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ax_0x5Pn-MF",
   "metadata": {
    "id": "9ax_0x5Pn-MF"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba26bd6e55fb8bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:14:43.200194Z",
     "start_time": "2024-06-27T19:14:43.194904Z"
    },
    "id": "ba26bd6e55fb8bae"
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)  # for replication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a3582e4f42eab",
   "metadata": {
    "id": "fe6a3582e4f42eab"
   },
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc01ba7b79c1896f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:14:43.206639Z",
     "start_time": "2024-06-27T19:14:43.201856Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc01ba7b79c1896f",
    "outputId": "49b1ba35-3fdc-4b67-bff7-1ab2395cc55d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTSRB_Final_Training_Images.zip already exists.\n",
      "GTSRB_Final_Test_Images.zip already exists.\n",
      "GTSRB_Final_Test_GT.zip already exists.\n"
     ]
    }
   ],
   "source": [
    "def download_file(url, file_name):\n",
    "    if not os.path.exists('dataset/' + file_name):\n",
    "        with urllib.request.urlopen(url) as response, open('dataset/' + file_name, 'wb') as out_file:\n",
    "            content_length = int(response.headers['Content-Length'])\n",
    "            with tqdm(total=content_length, unit='B', unit_scale=True, desc=url.split('/')[-1]) as pbar:\n",
    "                while True:\n",
    "                    chunk = response.read(1024)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    out_file.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "    else:\n",
    "        print(f\"{file_name} already exists.\")\n",
    "\n",
    "\n",
    "os.makedirs(\"dataset/\", exist_ok=True)\n",
    "# Training\n",
    "download_file('https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip',\n",
    "              'GTSRB_Final_Training_Images.zip')\n",
    "# Testing\n",
    "download_file('https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip',\n",
    "              'GTSRB_Final_Test_Images.zip')\n",
    "# Ground truth\n",
    "download_file('https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip',\n",
    "              'GTSRB_Final_Test_GT.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905d089f305e5b7",
   "metadata": {
    "id": "f905d089f305e5b7"
   },
   "source": [
    "## Extract zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de5a631fc79d888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:14:50.977879Z",
     "start_time": "2024-06-27T19:14:43.207930Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3de5a631fc79d888",
    "outputId": "a47e1c83-caad-4385-c493-28c72f17ddb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|████████████████████████████████████████████| 39299/39299 [00:04<00:00, 8387.40it/s]\n",
      "Extracting: 100%|████████████████████████████████████████████| 12635/12635 [00:01<00:00, 8378.29it/s]\n",
      "Extracting: 100%|█████████████████████████████████████████████████████| 1/1 [00:00<00:00, 563.52it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_file(file_name):\n",
    "    with zipfile.ZipFile(f\"dataset/{file_name}\", 'r') as zip_ref:\n",
    "        file_list = zip_ref.namelist()\n",
    "        with tqdm(total=len(file_list), desc=\"Extracting\") as pbar:\n",
    "            for file in file_list:\n",
    "                zip_ref.extract(file, 'dataset/')\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "extract_file('GTSRB_Final_Training_Images.zip')\n",
    "extract_file('GTSRB_Final_Test_Images.zip')\n",
    "extract_file('GTSRB_Final_Test_GT.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d7c1bb67c1550",
   "metadata": {
    "id": "323d7c1bb67c1550"
   },
   "source": [
    "## Loading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "468db0ee5cdf9840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:14:50.999837Z",
     "start_time": "2024-06-27T19:14:50.978732Z"
    },
    "id": "468db0ee5cdf9840"
   },
   "outputs": [],
   "source": [
    "#IMAGES: './dataset/GTSRB/test_images'\n",
    "#CSV ANNOTATIONS: './dataset/GTSRB/test_images/GT-final_test.csv'\n",
    "def csv_loader(csv_path):\n",
    "    data = np.loadtxt(csv_path,\n",
    "                      delimiter=\";\", dtype=str, skiprows=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "#You should download the testset ('GTSRB_Final_Test_Images.zip') from the website which contains only the images\n",
    "#Then you have to download the ground truth csv ('GTSRB_Final_Test_GT.zip') from the website and paste it into the testset images folder\n",
    "annotations = csv_loader('./dataset/GT-final_test.csv')\n",
    "#sort the annotations\n",
    "annotations = annotations[:, [0, 7]]\n",
    "num_samples = len(annotations)\n",
    "#Column 0: filename - Column 1: classid\n",
    "annotations = annotations[annotations[:, 1].astype(int).argsort()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6074543013fbb",
   "metadata": {
    "id": "b8b6074543013fbb"
   },
   "source": [
    "## Making training data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a83a9b0d1825e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:14:51.044610Z",
     "start_time": "2024-06-27T19:14:51.000946Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61a83a9b0d1825e4",
    "outputId": "bb698c3b-ee90-4bdb-a9ec-7e91f0e0027b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 43/43 [00:00<00:00, 8622.83it/s]\n"
     ]
    }
   ],
   "source": [
    "def move_directories(source, destination):\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "    # Get a list of all directories in the source directory\n",
    "    directories = [d for d in os.listdir(source) if os.path.isdir(os.path.join(source, d))]\n",
    "\n",
    "    # Move each directory to the destination\n",
    "    for directory in tqdm(directories):\n",
    "        source_path = os.path.join(source, directory)\n",
    "        destination_path = os.path.join(destination, directory)\n",
    "        shutil.move(source_path, destination_path)\n",
    "\n",
    "\n",
    "# Move directories with contents\n",
    "move_directories(\"./dataset/GTSRB/Final_Training/Images\", \"./dataset/GTSRB/train\")\n",
    "shutil.rmtree(\"./dataset/GTSRB/Final_Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172c68f192d26ae",
   "metadata": {
    "id": "5172c68f192d26ae"
   },
   "source": [
    "## Making test data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df556df8aaf39e91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:14:51.464682Z",
     "start_time": "2024-06-27T19:14:51.045602Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df556df8aaf39e91",
    "outputId": "fb5ccd24-86c7-4c70-acff-be8f8cb0a4ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class_ID: 100%|█████████████████████████████████████████████████████| 43/43 [00:00<00:00, 119.33it/s]\n"
     ]
    }
   ],
   "source": [
    "for class_id in tqdm(np.unique(annotations[:, 1]), desc='Class_ID'):\n",
    "    newpath = './dataset/GTSRB/test/' + class_id.zfill(5)\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    for image_filename in annotations[annotations[:, 1] == class_id]:\n",
    "        shutil.move('./dataset/GTSRB/Final_Test/Images/' + image_filename[0], newpath + '/' + image_filename[0])\n",
    "\n",
    "shutil.rmtree(\"./dataset/GTSRB/Final_Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JWpVwjN6nUFH",
   "metadata": {
    "id": "JWpVwjN6nUFH"
   },
   "source": [
    "## Merge the dataset and then split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690Ap50knZxO",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:15:00.145363Z",
     "start_time": "2024-06-27T19:14:51.465608Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "690Ap50knZxO",
    "outputId": "f8edb2d3-28d1-4d0b-bf88-541ab4e04add"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving: ./dataset/GTSRB/train --> ./dataset/GTSRB/merged: 100%|█| 39295/39295 [00:01<00:00, 27737.95i\n",
      "Moving: ./dataset/GTSRB/test --> ./dataset/GTSRB/merged: 100%|█| 12673/12673 [00:00<00:00, 29920.86it\n",
      "Copying files: 51882 files [00:04, 10752.71 files/s]\n"
     ]
    }
   ],
   "source": [
    "def merge(source_folder, destination_folder):\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Get the total number of files and directories in the source folder\n",
    "    total_items = sum([len(files) + len(dirs) for root, dirs, files in os.walk(source_folder)])\n",
    "\n",
    "    # Initialize tqdm to show progress\n",
    "    progress = tqdm(total=total_items, desc='Moving: ' + source_folder + ' --> ' + destination_folder, position=0,\n",
    "                    leave=True)\n",
    "\n",
    "    # Iterate over all files and subdirectories in the source folder\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        for item in files + dirs:\n",
    "            source_item = os.path.join(root, item)\n",
    "            destination_item = os.path.join(destination_folder, os.path.relpath(source_item, source_folder))\n",
    "\n",
    "            # If the item is a file, copy it to the destination folder\n",
    "            if os.path.isfile(source_item):\n",
    "                shutil.move(source_item, destination_item)\n",
    "            # If the item is a directory, create it in the destination folder\n",
    "            elif os.path.isdir(source_item):\n",
    "                os.makedirs(destination_item, exist_ok=True)\n",
    "\n",
    "            progress.update(1)  # Update progress bar\n",
    "\n",
    "    progress.close()  # Close tqdm\n",
    "\n",
    "\n",
    "def merge_folders(source_folders, target_folder):\n",
    "    for sf in source_folders:\n",
    "        merge(sf, target_folder)\n",
    "        shutil.rmtree(sf)\n",
    "\n",
    "\n",
    "# Temporary directory to store the merged dataset\n",
    "merged_dir = \"./dataset/GTSRB/merged\"\n",
    "\n",
    "merge_folders(['./dataset/GTSRB/train', './dataset/GTSRB/test'], merged_dir)\n",
    "\n",
    "# Training 70\n",
    "# Testing 30\n",
    "splitfolders.ratio(merged_dir, output=\"./dataset/GTSRB/plain\", seed=123, ratio=(.7, 0, 0.3), move=False)\n",
    "\n",
    "# Clear temporary files\n",
    "shutil.rmtree('./dataset/GTSRB/plain/val')\n",
    "os.remove('./dataset/GTSRB/Readme-Images-Final-test.txt')\n",
    "os.remove('./dataset/GTSRB/Readme-Images.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5650b2ca72f0f486",
   "metadata": {
    "id": "5650b2ca72f0f486"
   },
   "source": [
    "## Add weather conditions to the merged dataset and then split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0fb0b549a431a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:15:39.070877Z",
     "start_time": "2024-06-27T19:15:00.146112Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0fb0b549a431a3d",
    "outputId": "0800184c-2b50-484c-ed37-7ff16d3fb9bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: , 00007, 00037, 00021, 00020, 00032, 00040, 00042, 00026, 00010, 00025, 00017, 00024, 00014, 00031, 00023, 00011, 00019, 00033, 00012, 00030, 00005, 00001, 00008, 00038, 00041, 00018, 00006, 00036, 00039, 00003, 00013, 00002, 00027, 00029, 00028, 00004, 00034, 00000, 00035, 00015, 00009, 00016, 00022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading classes: 100%|███████████████████████████████████████████████| 43/43 [00:02<00:00, 16.54it/s]\n",
      "Add weather effects with probability 0.5: 100%|██████████████████████| 43/43 [00:35<00:00,  1.21it/s]\n",
      "Copying files: 51882 files [00:02, 23135.12 files/s]\n"
     ]
    }
   ],
   "source": [
    "da = data_augmenter.DataAugmenter(dataset_path='./dataset/GTSRB/')\n",
    "da.load_images(folder_to_load='merged')\n",
    "da.add_weather_effects(prob_per_class=0.5)\n",
    "\n",
    "# Training 70\n",
    "# Testing 30\n",
    "splitfolders.ratio(merged_dir, output=\"./dataset/GTSRB/weather\", seed=123, ratio=(.7, 0, 0.3), move=True)\n",
    "\n",
    "# Clear temporary files\n",
    "shutil.rmtree('./dataset/GTSRB/weather/val')\n",
    "shutil.rmtree(merged_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd860b78a2678d",
   "metadata": {
    "id": "6dcd860b78a2678d"
   },
   "source": [
    "## Set dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f8c403f5b816ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:15:39.074374Z",
     "start_time": "2024-06-27T19:15:39.072049Z"
    },
    "id": "20f8c403f5b816ee"
   },
   "outputs": [],
   "source": [
    "plain_train_dir = './dataset/GTSRB/plain/train'\n",
    "plain_test_dir = './dataset/GTSRB/plain/test'\n",
    "\n",
    "weather_train_dir = './dataset/GTSRB/weather/train'\n",
    "weather_test_dir = './dataset/GTSRB/weather/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e92b663416be6f",
   "metadata": {
    "id": "d2e92b663416be6f"
   },
   "source": [
    "# Parameters setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9b3ab9f505b0242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:15:40.279179Z",
     "start_time": "2024-06-27T19:15:39.075161Z"
    },
    "id": "e9b3ab9f505b0242"
   },
   "outputs": [],
   "source": [
    "# Setting device for the computation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Change this to select between plain or weather dataset\n",
    "# train_dir = plain_train_dir/weather_train_dir\n",
    "# test_dir = plain_test_dir/weather_test_dir\n",
    "# train_dir = plain_train_dir\n",
    "# test_dir = plain_test_dir\n",
    "\n",
    "# Hyperparameters\n",
    "sgd_hyperparams = {\n",
    "    \"num_epochs\": 15,\n",
    "    \"batch_size\": 64,\n",
    "    #optimizer\n",
    "    \"opt\": \"sgd\",\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"beta_1\": 0.9,\n",
    "    \"beta_2\": 0.999,\n",
    "    \"eps\": 1e-8,\n",
    "    \"weight_decay\": 0,\n",
    "    \"momentum\": 0,\n",
    "    #scheduler\n",
    "    \"decay_rate\": 0.5,\n",
    "}\n",
    "adam_hyperparams = {\n",
    "    \"num_epochs\": 15,\n",
    "    \"batch_size\": 64,\n",
    "    #optimizer\n",
    "    \"opt\": \"adam\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"beta_1\": 0.9,\n",
    "    \"beta_2\": 0.999,\n",
    "    \"eps\": 1e-8,\n",
    "    \"weight_decay\": 0,\n",
    "    \"momentum\": 0,\n",
    "    #scheduler\n",
    "    \"decay_rate\": 0.5,\n",
    "}\n",
    "\n",
    "runs_arguments = [\n",
    "    {'type': 'P', 'cnn': 'CNN'},\n",
    "    {'type': 'P', 'cnn': 'CNN_ST'},\n",
    "    {'type': 'W', 'cnn': 'CNN'},\n",
    "    {'type': 'W', 'cnn': 'CNN_ST'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q-bE0596WTkR",
   "metadata": {
    "id": "q-bE0596WTkR"
   },
   "source": [
    "# Method for loading the training/testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f9bed2c473422e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:15:40.293590Z",
     "start_time": "2024-06-27T19:15:40.281179Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_train_test_dir(train_dir, test_dir):\n",
    "    \n",
    "    # Define your transformations\n",
    "    custom_cnn_transform = transforms.Compose([\n",
    "        transforms.Resize((48, 48)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Load the dataset using the torchvision.datasets.ImageFolder\n",
    "    train_dataset = datasets.ImageFolder(train_dir, transform=custom_cnn_transform)\n",
    "    \n",
    "    # Concatenate all images into a single tensor\n",
    "    images = torch.stack([img for img, _ in train_dataset], dim=0)\n",
    "    \n",
    "    # Calculate mean and std across all images and channels\n",
    "    mean = torch.mean(images, dim=(0, 2, 3))\n",
    "    std = torch.std(images, dim=(0, 2, 3))\n",
    "    \n",
    "    # Define your transformations\n",
    "    custom_cnn_transform = transforms.Compose([\n",
    "        transforms.Resize((48, 48)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "    \n",
    "    # Load the dataset using the torchvision.datasets.ImageFolder\n",
    "    train_dataset = datasets.ImageFolder(train_dir, transform=custom_cnn_transform)\n",
    "    test_dataset = datasets.ImageFolder(test_dir, transform=custom_cnn_transform)\n",
    "    \n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G7CE0M9SWeZj",
   "metadata": {
    "id": "G7CE0M9SWeZj"
   },
   "source": [
    "# Defining the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waE26jiDoZ32",
   "metadata": {
    "id": "waE26jiDoZ32"
   },
   "source": [
    "## CNN Plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "r56vEoqhogaG",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:15:40.302693Z",
     "start_time": "2024-06-27T19:15:40.294484Z"
    },
    "id": "r56vEoqhogaG"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Expected input as 48x48\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=200, kernel_size=7, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.local_norm = nn.LocalResponseNorm(size=5)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=200, out_channels=250, kernel_size=4, stride=1, padding=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=250, out_channels=350, kernel_size=4, stride=1, padding=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=350 * 6 * 6, out_features=400)\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=400, out_features=43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.local_norm(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.local_norm(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.local_norm(x)\n",
    "\n",
    "        # Flatten the output from conv1\n",
    "        x = x.view(-1, 350 * 6 * 6)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6jKXkY8lft6q",
   "metadata": {
    "id": "6jKXkY8lft6q"
   },
   "source": [
    "## CNN with 3 spatial transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eAwI5trgfxqg",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:15:40.315024Z",
     "start_time": "2024-06-27T19:15:40.303589Z"
    },
    "id": "eAwI5trgfxqg"
   },
   "outputs": [],
   "source": [
    "class CNN_ST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Expected input as 48x48\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=200, kernel_size=7, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=200, out_channels=250, kernel_size=4, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=250, out_channels=350, kernel_size=4, stride=1, padding=2)\n",
    "\n",
    "        self.local_norm = nn.LocalResponseNorm(size=5)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=350 * 6 * 6, out_features=400)\n",
    "        self.fc2 = nn.Linear(in_features=400, out_features=43)\n",
    "\n",
    "        # Spatial transformer block 1\n",
    "        self.loc1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=3, out_channels=250, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=250, out_channels=250, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_loc1 = nn.Sequential(\n",
    "            nn.Linear(250 * 6 * 6, 250),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(250, 6)\n",
    "        )\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc1[2].weight.data.zero_()\n",
    "        self.fc_loc1[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "        # Spatial transformer block 2\n",
    "        self.loc2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=200, out_channels=150, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=150, out_channels=200, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_loc2 = nn.Sequential(\n",
    "            nn.Linear(200 * 2 * 2, 300),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(300, 6)\n",
    "        )\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc2[2].weight.data.zero_()\n",
    "        self.fc_loc2[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "        # Spatial transformer block 3\n",
    "        self.loc3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=250, out_channels=150, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=150, out_channels=200, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_loc3 = nn.Sequential(\n",
    "            nn.Linear(200 * 1 * 1, 300),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(300, 6)\n",
    "        )\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc3[2].weight.data.zero_()\n",
    "        self.fc_loc3[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    def stn1(self, x):\n",
    "        xs = self.loc1(x)\n",
    "        xs = xs.view(-1, 250 * 6 * 6)\n",
    "        theta = self.fc_loc1(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "        x = F.grid_sample(x, grid, align_corners=False)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def stn2(self, x):\n",
    "        xs = self.loc2(x)\n",
    "        xs = xs.view(-1, 200 * 2 * 2)\n",
    "        theta = self.fc_loc2(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "        x = F.grid_sample(x, grid, align_corners=False)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def stn3(self, x):\n",
    "        xs = self.loc3(x)\n",
    "        xs = xs.view(-1, 200 * 1 * 1)\n",
    "        theta = self.fc_loc3(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "        x = F.grid_sample(x, grid, align_corners=False)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Spatial transformer 1\n",
    "        x = self.stn1(x)\n",
    "\n",
    "        # CNN block 1\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.local_norm(x)\n",
    "\n",
    "        # Spatial transformer 2\n",
    "        x = self.stn2(x)\n",
    "\n",
    "        # CNN block 2\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.local_norm(x)\n",
    "\n",
    "        # Spatial transformer 3\n",
    "        x = self.stn3(x)\n",
    "\n",
    "        # CNN block 3\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.local_norm(x)\n",
    "\n",
    "        # Flatten the output for dense layers\n",
    "        x = x.view(-1, 350 * 6 * 6)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cpZCj8mowXh",
   "metadata": {
    "id": "6cpZCj8mowXh"
   },
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "RIiC4t_jWeBV",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:15:40.326203Z",
     "start_time": "2024-06-27T19:15:40.316202Z"
    },
    "id": "RIiC4t_jWeBV"
   },
   "outputs": [],
   "source": [
    "def test_model(trained_model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        trained_model.eval()\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = trained_model(images)\n",
    "            softmax_outputs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(softmax_outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = float(correct / total)\n",
    "    print('{} Model accuracy: {:.4f}'.format('Test phase - ', test_accuracy))\n",
    "    writer.add_scalar('Training/Test Accuracy', test_accuracy)\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "def train_model(device, model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=25,\n",
    "                model_name='trained_model'):\n",
    "    since = time.time()\n",
    "    time_train = 0\n",
    "    time_val = 0\n",
    "\n",
    "    # Save the initial model\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Choose the appropriate data loader\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                data_total_steps = len(train_loader)\n",
    "                data_loader = train_loader\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "                data_total_steps = len(val_loader)\n",
    "                data_loader = val_loader\n",
    "\n",
    "            for i, (images, labels) in enumerate(data_loader):\n",
    "                # time_t = epoch * len(data_loader) * i + i\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images)\n",
    "                    softmax_outputs = F.softmax(outputs, dim=1)\n",
    "                    probs, preds = torch.max(softmax_outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                #prints the stats every 20 steps (20 batches performed)\n",
    "                if (i + 1) % int(data_total_steps / 8) == 0:\n",
    "                    print(\n",
    "                        f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{data_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "                    # Log image predictions\n",
    "                    selected_indices = random.sample(range(len(images)), 4)  # Select 4 random indices\n",
    "                    selected_images = images[selected_indices]\n",
    "                    selected_labels = labels[selected_indices]\n",
    "                    selected_preds = preds[selected_indices]\n",
    "                    selected_probs = probs[selected_indices]\n",
    "                    if phase == 'train':\n",
    "                        writer.add_figure('Training/Training Predictions',\n",
    "                                          plot_classes_preds(selected_images, selected_labels, selected_preds,\n",
    "                                                             selected_probs),\n",
    "                                          global_step=time_train)\n",
    "                    else:\n",
    "                        writer.add_figure('Training/Validation Predictions',\n",
    "                                          plot_classes_preds(selected_images, selected_labels, selected_preds,\n",
    "                                                             selected_probs),\n",
    "                                          global_step=time_val)\n",
    "\n",
    "                # Log scalars\n",
    "                if phase == 'train':\n",
    "                    writer.add_scalar('Training/Training Loss',\n",
    "                                      loss.item(),\n",
    "                                      time_train)\n",
    "                    writer.add_scalar('Policy/Learning Rate',\n",
    "                                      np.array(scheduler.get_last_lr()),\n",
    "                                      time_train)\n",
    "                    time_train += 1\n",
    "                else:\n",
    "                    writer.add_scalar('Training/Validation Loss',\n",
    "                                      loss.item(),\n",
    "                                      time_val)\n",
    "                    time_val += 1\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(data_loader.dataset)\n",
    "\n",
    "            if phase == 'train':\n",
    "                print('{} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    'Train phase - ', epoch + 1, epoch_loss, epoch_acc))\n",
    "                writer.add_scalar('Training/Training Accuracy',\n",
    "                                  epoch_acc,\n",
    "                                  epoch)\n",
    "                # if (epoch + 1) % max(int(num_epochs / 5), 1) == 0:  # checkpoint the model\n",
    "                #     print(\"----> model checkpoint...\")\n",
    "                #     torch.save(model, f'./models/trained_model_{model_name}_epoch_{epoch + 1}.pth')\n",
    "            else:\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('{} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    'Validation phase - ', epoch + 1, epoch_loss, epoch_acc))\n",
    "                writer.add_scalar('Training/Validation Accuracy',\n",
    "                                  epoch_acc,\n",
    "                                  epoch)\n",
    "                #scheduler.step(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc:{:.4f}'.format(best_acc))\n",
    "    # Return the model with the best accuracy in the validation\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trtHqdVcWrbV",
   "metadata": {
    "id": "trtHqdVcWrbV"
   },
   "source": [
    "## Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "SpS12uKCWvbE",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:17:53.887912Z",
     "start_time": "2024-06-27T19:16:58.035706Z"
    },
    "id": "SpS12uKCWvbE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/15\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toldo/Desktop/UniPD/VCS/Traffic-Sign-Recognition/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/toldo/Desktop/UniPD/VCS/Traffic-Sign-Recognition/venv/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Step [56/454], Loss: 3.7256\n",
      "Epoch [1/15], Step [112/454], Loss: 3.6410\n",
      "Epoch [1/15], Step [168/454], Loss: 3.5056\n",
      "Epoch [1/15], Step [224/454], Loss: 3.5359\n",
      "Epoch [1/15], Step [280/454], Loss: 3.5075\n",
      "Epoch [1/15], Step [336/454], Loss: 3.5605\n",
      "Epoch [1/15], Step [392/454], Loss: 3.1821\n",
      "Epoch [1/15], Step [448/454], Loss: 3.3483\n",
      "Train phase -  Epoch 1 Loss: 3.5085 Acc: 0.0857\n",
      "Epoch [1/15], Step [14/114], Loss: 3.3356\n",
      "Epoch [1/15], Step [28/114], Loss: 3.5528\n",
      "Epoch [1/15], Step [42/114], Loss: 3.6456\n",
      "Epoch [1/15], Step [56/114], Loss: 3.2859\n",
      "Epoch [1/15], Step [70/114], Loss: 3.1430\n",
      "Epoch [1/15], Step [84/114], Loss: 3.1479\n",
      "Epoch [1/15], Step [98/114], Loss: 3.1044\n",
      "Epoch [1/15], Step [112/114], Loss: 3.3072\n",
      "Validation phase -  Epoch 1 Loss: 3.3281 Acc: 0.1233\n",
      "----------\n",
      "Epoch 2/15\n",
      "----------\n",
      "Epoch [2/15], Step [56/454], Loss: 3.4785\n",
      "Epoch [2/15], Step [112/454], Loss: 3.1948\n",
      "Epoch [2/15], Step [168/454], Loss: 3.2446\n",
      "Epoch [2/15], Step [224/454], Loss: 3.1370\n",
      "Epoch [2/15], Step [280/454], Loss: 3.0880\n",
      "Epoch [2/15], Step [336/454], Loss: 3.2102\n",
      "Epoch [2/15], Step [392/454], Loss: 2.9694\n",
      "Epoch [2/15], Step [448/454], Loss: 2.9543\n",
      "Train phase -  Epoch 2 Loss: 3.1746 Acc: 0.1700\n",
      "Epoch [2/15], Step [14/114], Loss: 2.9869\n",
      "Epoch [2/15], Step [28/114], Loss: 2.9913\n",
      "Epoch [2/15], Step [42/114], Loss: 2.9495\n",
      "Epoch [2/15], Step [56/114], Loss: 2.8555\n",
      "Epoch [2/15], Step [70/114], Loss: 2.8742\n",
      "Epoch [2/15], Step [84/114], Loss: 2.7386\n",
      "Epoch [2/15], Step [98/114], Loss: 2.9082\n",
      "Epoch [2/15], Step [112/114], Loss: 3.1173\n",
      "Validation phase -  Epoch 2 Loss: 2.8967 Acc: 0.2463\n",
      "----------\n",
      "Epoch 3/15\n",
      "----------\n",
      "Epoch [3/15], Step [56/454], Loss: 2.8882\n",
      "Epoch [3/15], Step [112/454], Loss: 2.8851\n",
      "Epoch [3/15], Step [168/454], Loss: 2.6565\n",
      "Epoch [3/15], Step [224/454], Loss: 2.6154\n",
      "Epoch [3/15], Step [280/454], Loss: 2.6536\n",
      "Epoch [3/15], Step [336/454], Loss: 2.4010\n",
      "Epoch [3/15], Step [392/454], Loss: 2.1542\n",
      "Epoch [3/15], Step [448/454], Loss: 2.1514\n",
      "Train phase -  Epoch 3 Loss: 2.5237 Acc: 0.3086\n",
      "Epoch [3/15], Step [14/114], Loss: 2.3885\n",
      "Epoch [3/15], Step [28/114], Loss: 2.4002\n",
      "Epoch [3/15], Step [42/114], Loss: 1.9115\n",
      "Epoch [3/15], Step [56/114], Loss: 2.3542\n",
      "Epoch [3/15], Step [70/114], Loss: 2.3355\n",
      "Epoch [3/15], Step [84/114], Loss: 1.9701\n",
      "Epoch [3/15], Step [98/114], Loss: 2.2992\n",
      "Epoch [3/15], Step [112/114], Loss: 2.0069\n",
      "Validation phase -  Epoch 3 Loss: 2.2239 Acc: 0.3517\n",
      "----------\n",
      "Epoch 4/15\n",
      "----------\n",
      "Epoch [4/15], Step [56/454], Loss: 2.1728\n",
      "Epoch [4/15], Step [112/454], Loss: 2.0248\n",
      "Epoch [4/15], Step [168/454], Loss: 2.1164\n",
      "Epoch [4/15], Step [224/454], Loss: 2.1280\n",
      "Epoch [4/15], Step [280/454], Loss: 2.0334\n",
      "Epoch [4/15], Step [336/454], Loss: 1.8223\n",
      "Epoch [4/15], Step [392/454], Loss: 1.8494\n",
      "Epoch [4/15], Step [448/454], Loss: 1.5534\n",
      "Train phase -  Epoch 4 Loss: 1.8257 Acc: 0.4674\n",
      "Epoch [4/15], Step [14/114], Loss: 1.3638\n",
      "Epoch [4/15], Step [28/114], Loss: 1.6024\n",
      "Epoch [4/15], Step [42/114], Loss: 1.7910\n",
      "Epoch [4/15], Step [56/114], Loss: 1.8251\n",
      "Epoch [4/15], Step [70/114], Loss: 1.4419\n",
      "Epoch [4/15], Step [84/114], Loss: 1.5261\n",
      "Epoch [4/15], Step [98/114], Loss: 1.1648\n",
      "Epoch [4/15], Step [112/114], Loss: 1.5631\n",
      "Validation phase -  Epoch 4 Loss: 1.6019 Acc: 0.5214\n",
      "----------\n",
      "Epoch 5/15\n",
      "----------\n",
      "Epoch [5/15], Step [56/454], Loss: 1.7342\n",
      "Epoch [5/15], Step [112/454], Loss: 1.3359\n",
      "Epoch [5/15], Step [168/454], Loss: 1.4131\n",
      "Epoch [5/15], Step [224/454], Loss: 1.3080\n",
      "Epoch [5/15], Step [280/454], Loss: 1.1643\n",
      "Epoch [5/15], Step [336/454], Loss: 1.0642\n",
      "Epoch [5/15], Step [392/454], Loss: 1.1606\n",
      "Epoch [5/15], Step [448/454], Loss: 1.1651\n",
      "Train phase -  Epoch 5 Loss: 1.2883 Acc: 0.6171\n",
      "Epoch [5/15], Step [14/114], Loss: 1.2694\n",
      "Epoch [5/15], Step [28/114], Loss: 1.0701\n",
      "Epoch [5/15], Step [42/114], Loss: 1.2170\n",
      "Epoch [5/15], Step [56/114], Loss: 1.3224\n",
      "Epoch [5/15], Step [70/114], Loss: 1.3970\n",
      "Epoch [5/15], Step [84/114], Loss: 1.2568\n",
      "Epoch [5/15], Step [98/114], Loss: 1.0613\n",
      "Epoch [5/15], Step [112/114], Loss: 1.0386\n",
      "Validation phase -  Epoch 5 Loss: 1.1181 Acc: 0.6660\n",
      "----------\n",
      "Epoch 6/15\n",
      "----------\n",
      "Epoch [6/15], Step [56/454], Loss: 1.0393\n",
      "Epoch [6/15], Step [112/454], Loss: 1.1153\n",
      "Epoch [6/15], Step [168/454], Loss: 1.0218\n",
      "Epoch [6/15], Step [224/454], Loss: 0.9161\n",
      "Epoch [6/15], Step [280/454], Loss: 0.9672\n",
      "Epoch [6/15], Step [336/454], Loss: 0.8546\n",
      "Epoch [6/15], Step [392/454], Loss: 1.1026\n",
      "Epoch [6/15], Step [448/454], Loss: 0.7025\n",
      "Train phase -  Epoch 6 Loss: 0.9213 Acc: 0.7200\n",
      "Epoch [6/15], Step [14/114], Loss: 0.7084\n",
      "Epoch [6/15], Step [28/114], Loss: 1.0942\n",
      "Epoch [6/15], Step [42/114], Loss: 1.1327\n",
      "Epoch [6/15], Step [56/114], Loss: 1.0043\n",
      "Epoch [6/15], Step [70/114], Loss: 1.0985\n",
      "Epoch [6/15], Step [84/114], Loss: 0.6930\n",
      "Epoch [6/15], Step [98/114], Loss: 1.2708\n",
      "Epoch [6/15], Step [112/114], Loss: 1.3406\n",
      "Validation phase -  Epoch 6 Loss: 1.0017 Acc: 0.7009\n",
      "----------\n",
      "Epoch 7/15\n",
      "----------\n",
      "Epoch [7/15], Step [56/454], Loss: 0.7998\n",
      "Epoch [7/15], Step [112/454], Loss: 0.7174\n",
      "Epoch [7/15], Step [168/454], Loss: 0.7079\n",
      "Epoch [7/15], Step [224/454], Loss: 0.5473\n",
      "Epoch [7/15], Step [280/454], Loss: 0.7515\n",
      "Epoch [7/15], Step [336/454], Loss: 0.7020\n",
      "Epoch [7/15], Step [392/454], Loss: 0.6929\n",
      "Epoch [7/15], Step [448/454], Loss: 0.6652\n",
      "Train phase -  Epoch 7 Loss: 0.6771 Acc: 0.7989\n",
      "Epoch [7/15], Step [14/114], Loss: 0.5189\n",
      "Epoch [7/15], Step [28/114], Loss: 0.5910\n",
      "Epoch [7/15], Step [42/114], Loss: 0.4755\n",
      "Epoch [7/15], Step [56/114], Loss: 0.6173\n",
      "Epoch [7/15], Step [70/114], Loss: 0.5895\n",
      "Epoch [7/15], Step [84/114], Loss: 0.4898\n",
      "Epoch [7/15], Step [98/114], Loss: 0.4377\n",
      "Epoch [7/15], Step [112/114], Loss: 0.6612\n",
      "Validation phase -  Epoch 7 Loss: 0.6130 Acc: 0.8064\n",
      "----------\n",
      "Epoch 8/15\n",
      "----------\n",
      "Epoch [8/15], Step [56/454], Loss: 0.5405\n",
      "Epoch [8/15], Step [112/454], Loss: 0.6882\n",
      "Epoch [8/15], Step [168/454], Loss: 0.3708\n",
      "Epoch [8/15], Step [224/454], Loss: 0.6277\n",
      "Epoch [8/15], Step [280/454], Loss: 0.4340\n",
      "Epoch [8/15], Step [336/454], Loss: 0.5146\n",
      "Epoch [8/15], Step [392/454], Loss: 0.3156\n",
      "Epoch [8/15], Step [448/454], Loss: 0.3570\n",
      "Train phase -  Epoch 8 Loss: 0.5085 Acc: 0.8512\n",
      "Epoch [8/15], Step [14/114], Loss: 0.4576\n",
      "Epoch [8/15], Step [28/114], Loss: 0.4637\n",
      "Epoch [8/15], Step [42/114], Loss: 0.6644\n",
      "Epoch [8/15], Step [56/114], Loss: 0.4472\n",
      "Epoch [8/15], Step [70/114], Loss: 0.7614\n",
      "Epoch [8/15], Step [84/114], Loss: 0.5516\n",
      "Epoch [8/15], Step [98/114], Loss: 0.7817\n",
      "Epoch [8/15], Step [112/114], Loss: 0.7810\n",
      "Validation phase -  Epoch 8 Loss: 0.5139 Acc: 0.8348\n",
      "----------\n",
      "Epoch 9/15\n",
      "----------\n",
      "Epoch [9/15], Step [56/454], Loss: 0.3461\n",
      "Epoch [9/15], Step [112/454], Loss: 0.4562\n",
      "Epoch [9/15], Step [168/454], Loss: 0.3265\n",
      "Epoch [9/15], Step [224/454], Loss: 0.3393\n",
      "Epoch [9/15], Step [280/454], Loss: 0.3819\n",
      "Epoch [9/15], Step [336/454], Loss: 0.2853\n",
      "Epoch [9/15], Step [392/454], Loss: 0.3394\n",
      "Epoch [9/15], Step [448/454], Loss: 0.1950\n",
      "Train phase -  Epoch 9 Loss: 0.3945 Acc: 0.8873\n",
      "Epoch [9/15], Step [14/114], Loss: 0.5109\n",
      "Epoch [9/15], Step [28/114], Loss: 0.4880\n",
      "Epoch [9/15], Step [42/114], Loss: 0.3917\n",
      "Epoch [9/15], Step [56/114], Loss: 0.3102\n",
      "Epoch [9/15], Step [70/114], Loss: 0.3219\n",
      "Epoch [9/15], Step [84/114], Loss: 0.2926\n",
      "Epoch [9/15], Step [98/114], Loss: 0.3847\n",
      "Epoch [9/15], Step [112/114], Loss: 0.4561\n",
      "Validation phase -  Epoch 9 Loss: 0.3761 Acc: 0.8902\n",
      "----------\n",
      "Epoch 10/15\n",
      "----------\n",
      "Epoch [10/15], Step [56/454], Loss: 0.5370\n",
      "Epoch [10/15], Step [112/454], Loss: 0.3108\n",
      "Epoch [10/15], Step [168/454], Loss: 0.3061\n",
      "Epoch [10/15], Step [224/454], Loss: 0.3659\n",
      "Epoch [10/15], Step [280/454], Loss: 0.3836\n",
      "Epoch [10/15], Step [336/454], Loss: 0.3002\n",
      "Epoch [10/15], Step [392/454], Loss: 0.3140\n",
      "Epoch [10/15], Step [448/454], Loss: 0.3017\n",
      "Train phase -  Epoch 10 Loss: 0.3129 Acc: 0.9133\n",
      "Epoch [10/15], Step [14/114], Loss: 0.4129\n",
      "Epoch [10/15], Step [28/114], Loss: 0.3531\n",
      "Epoch [10/15], Step [42/114], Loss: 0.3325\n",
      "Epoch [10/15], Step [56/114], Loss: 0.2105\n",
      "Epoch [10/15], Step [70/114], Loss: 0.3025\n",
      "Epoch [10/15], Step [84/114], Loss: 0.3227\n",
      "Epoch [10/15], Step [98/114], Loss: 0.3661\n",
      "Epoch [10/15], Step [112/114], Loss: 0.3096\n",
      "Validation phase -  Epoch 10 Loss: 0.3197 Acc: 0.9023\n",
      "----------\n",
      "Epoch 11/15\n",
      "----------\n",
      "Epoch [11/15], Step [56/454], Loss: 0.2990\n",
      "Epoch [11/15], Step [112/454], Loss: 0.1421\n",
      "Epoch [11/15], Step [168/454], Loss: 0.3663\n",
      "Epoch [11/15], Step [224/454], Loss: 0.1594\n",
      "Epoch [11/15], Step [280/454], Loss: 0.2516\n",
      "Epoch [11/15], Step [336/454], Loss: 0.2164\n",
      "Epoch [11/15], Step [392/454], Loss: 0.1150\n",
      "Epoch [11/15], Step [448/454], Loss: 0.1955\n",
      "Train phase -  Epoch 11 Loss: 0.2557 Acc: 0.9310\n",
      "Epoch [11/15], Step [14/114], Loss: 0.2022\n",
      "Epoch [11/15], Step [28/114], Loss: 0.5171\n",
      "Epoch [11/15], Step [42/114], Loss: 0.3423\n",
      "Epoch [11/15], Step [56/114], Loss: 0.4042\n",
      "Epoch [11/15], Step [70/114], Loss: 0.3740\n",
      "Epoch [11/15], Step [84/114], Loss: 0.3126\n",
      "Epoch [11/15], Step [98/114], Loss: 0.2307\n",
      "Epoch [11/15], Step [112/114], Loss: 0.1717\n",
      "Validation phase -  Epoch 11 Loss: 0.3006 Acc: 0.9114\n",
      "----------\n",
      "Epoch 12/15\n",
      "----------\n",
      "Epoch [12/15], Step [56/454], Loss: 0.2128\n",
      "Epoch [12/15], Step [112/454], Loss: 0.1842\n",
      "Epoch [12/15], Step [168/454], Loss: 0.1383\n",
      "Epoch [12/15], Step [224/454], Loss: 0.0784\n",
      "Epoch [12/15], Step [280/454], Loss: 0.2483\n",
      "Epoch [12/15], Step [336/454], Loss: 0.1749\n",
      "Epoch [12/15], Step [392/454], Loss: 0.1007\n",
      "Epoch [12/15], Step [448/454], Loss: 0.1940\n",
      "Train phase -  Epoch 12 Loss: 0.2132 Acc: 0.9446\n",
      "Epoch [12/15], Step [14/114], Loss: 0.1110\n",
      "Epoch [12/15], Step [28/114], Loss: 0.4343\n",
      "Epoch [12/15], Step [42/114], Loss: 0.3440\n",
      "Epoch [12/15], Step [56/114], Loss: 0.2238\n",
      "Epoch [12/15], Step [70/114], Loss: 0.2220\n",
      "Epoch [12/15], Step [84/114], Loss: 0.1470\n",
      "Epoch [12/15], Step [98/114], Loss: 0.2402\n",
      "Epoch [12/15], Step [112/114], Loss: 0.1953\n",
      "Validation phase -  Epoch 12 Loss: 0.2311 Acc: 0.9370\n",
      "----------\n",
      "Epoch 13/15\n",
      "----------\n",
      "Epoch [13/15], Step [56/454], Loss: 0.0930\n",
      "Epoch [13/15], Step [112/454], Loss: 0.2265\n",
      "Epoch [13/15], Step [168/454], Loss: 0.1590\n",
      "Epoch [13/15], Step [224/454], Loss: 0.1666\n",
      "Epoch [13/15], Step [280/454], Loss: 0.1419\n",
      "Epoch [13/15], Step [336/454], Loss: 0.1438\n",
      "Epoch [13/15], Step [392/454], Loss: 0.1243\n",
      "Epoch [13/15], Step [448/454], Loss: 0.1672\n",
      "Train phase -  Epoch 13 Loss: 0.1784 Acc: 0.9541\n",
      "Epoch [13/15], Step [14/114], Loss: 0.1392\n",
      "Epoch [13/15], Step [28/114], Loss: 0.2552\n",
      "Epoch [13/15], Step [42/114], Loss: 0.2178\n",
      "Epoch [13/15], Step [56/114], Loss: 0.2825\n",
      "Epoch [13/15], Step [70/114], Loss: 0.1334\n",
      "Epoch [13/15], Step [84/114], Loss: 0.2177\n",
      "Epoch [13/15], Step [98/114], Loss: 0.2172\n",
      "Epoch [13/15], Step [112/114], Loss: 0.2888\n",
      "Validation phase -  Epoch 13 Loss: 0.1991 Acc: 0.9501\n",
      "----------\n",
      "Epoch 14/15\n",
      "----------\n",
      "Epoch [14/15], Step [56/454], Loss: 0.0523\n",
      "Epoch [14/15], Step [112/454], Loss: 0.1245\n",
      "Epoch [14/15], Step [168/454], Loss: 0.1160\n",
      "Epoch [14/15], Step [224/454], Loss: 0.1387\n",
      "Epoch [14/15], Step [280/454], Loss: 0.0844\n",
      "Epoch [14/15], Step [336/454], Loss: 0.2696\n",
      "Epoch [14/15], Step [392/454], Loss: 0.1048\n",
      "Epoch [14/15], Step [448/454], Loss: 0.2399\n",
      "Train phase -  Epoch 14 Loss: 0.1510 Acc: 0.9617\n",
      "Epoch [14/15], Step [14/114], Loss: 0.1089\n",
      "Epoch [14/15], Step [28/114], Loss: 0.2819\n",
      "Epoch [14/15], Step [42/114], Loss: 0.6558\n",
      "Epoch [14/15], Step [56/114], Loss: 0.2111\n",
      "Epoch [14/15], Step [70/114], Loss: 0.1282\n",
      "Epoch [14/15], Step [84/114], Loss: 0.3065\n",
      "Epoch [14/15], Step [98/114], Loss: 0.3772\n",
      "Epoch [14/15], Step [112/114], Loss: 0.3094\n",
      "Validation phase -  Epoch 14 Loss: 0.2255 Acc: 0.9332\n",
      "----------\n",
      "Epoch 15/15\n",
      "----------\n",
      "Epoch [15/15], Step [56/454], Loss: 0.0932\n",
      "Epoch [15/15], Step [112/454], Loss: 0.1489\n",
      "Epoch [15/15], Step [168/454], Loss: 0.1478\n",
      "Epoch [15/15], Step [224/454], Loss: 0.2232\n",
      "Epoch [15/15], Step [280/454], Loss: 0.0916\n",
      "Epoch [15/15], Step [336/454], Loss: 0.1214\n",
      "Epoch [15/15], Step [392/454], Loss: 0.0575\n",
      "Epoch [15/15], Step [448/454], Loss: 0.1242\n",
      "Train phase -  Epoch 15 Loss: 0.1328 Acc: 0.9674\n",
      "Epoch [15/15], Step [14/114], Loss: 0.1241\n",
      "Epoch [15/15], Step [28/114], Loss: 0.1731\n",
      "Epoch [15/15], Step [42/114], Loss: 0.0808\n",
      "Epoch [15/15], Step [56/114], Loss: 0.1691\n",
      "Epoch [15/15], Step [70/114], Loss: 0.2712\n",
      "Epoch [15/15], Step [84/114], Loss: 0.2441\n",
      "Epoch [15/15], Step [98/114], Loss: 0.1707\n",
      "Epoch [15/15], Step [112/114], Loss: 0.1355\n",
      "Validation phase -  Epoch 15 Loss: 0.2023 Acc: 0.9419\n",
      "Training complete in 10m 37s\n",
      "Best val Acc:0.9501\n",
      "Test phase -  Model accuracy: 0.9513\n",
      "Finished Training no-loss-weight_P_CNN_sgd\n",
      "----------\n",
      "Epoch 1/15\n",
      "----------\n",
      "Epoch [1/15], Step [56/454], Loss: 3.4352\n",
      "Epoch [1/15], Step [112/454], Loss: 2.8741\n",
      "Epoch [1/15], Step [168/454], Loss: 2.0339\n",
      "Epoch [1/15], Step [224/454], Loss: 2.2400\n",
      "Epoch [1/15], Step [280/454], Loss: 1.4916\n",
      "Epoch [1/15], Step [336/454], Loss: 1.4712\n",
      "Epoch [1/15], Step [392/454], Loss: 1.0717\n",
      "Epoch [1/15], Step [448/454], Loss: 0.9294\n",
      "Train phase -  Epoch 1 Loss: 2.1056 Acc: 0.4199\n",
      "Epoch [1/15], Step [14/114], Loss: 1.0555\n",
      "Epoch [1/15], Step [28/114], Loss: 0.9224\n",
      "Epoch [1/15], Step [42/114], Loss: 1.2311\n",
      "Epoch [1/15], Step [56/114], Loss: 1.2020\n",
      "Epoch [1/15], Step [70/114], Loss: 1.2519\n",
      "Epoch [1/15], Step [84/114], Loss: 0.9068\n",
      "Epoch [1/15], Step [98/114], Loss: 0.8589\n",
      "Epoch [1/15], Step [112/114], Loss: 0.9707\n",
      "Validation phase -  Epoch 1 Loss: 1.0377 Acc: 0.6954\n",
      "----------\n",
      "Epoch 2/15\n",
      "----------\n",
      "Epoch [2/15], Step [56/454], Loss: 1.0124\n",
      "Epoch [2/15], Step [112/454], Loss: 0.7617\n",
      "Epoch [2/15], Step [168/454], Loss: 0.7720\n",
      "Epoch [2/15], Step [224/454], Loss: 0.4919\n",
      "Epoch [2/15], Step [280/454], Loss: 0.4418\n",
      "Epoch [2/15], Step [336/454], Loss: 0.3091\n",
      "Epoch [2/15], Step [392/454], Loss: 0.3915\n",
      "Epoch [2/15], Step [448/454], Loss: 0.4049\n",
      "Train phase -  Epoch 2 Loss: 0.6175 Acc: 0.8240\n",
      "Epoch [2/15], Step [14/114], Loss: 0.6023\n",
      "Epoch [2/15], Step [28/114], Loss: 0.3452\n",
      "Epoch [2/15], Step [42/114], Loss: 0.4647\n",
      "Epoch [2/15], Step [56/114], Loss: 0.4231\n",
      "Epoch [2/15], Step [70/114], Loss: 0.4607\n",
      "Epoch [2/15], Step [84/114], Loss: 0.1769\n",
      "Epoch [2/15], Step [98/114], Loss: 0.5396\n",
      "Epoch [2/15], Step [112/114], Loss: 0.5093\n",
      "Validation phase -  Epoch 2 Loss: 0.3907 Acc: 0.8961\n",
      "----------\n",
      "Epoch 3/15\n",
      "----------\n",
      "Epoch [3/15], Step [56/454], Loss: 0.2268\n",
      "Epoch [3/15], Step [112/454], Loss: 0.1139\n",
      "Epoch [3/15], Step [168/454], Loss: 0.2432\n",
      "Epoch [3/15], Step [224/454], Loss: 0.2651\n",
      "Epoch [3/15], Step [280/454], Loss: 0.3379\n",
      "Epoch [3/15], Step [336/454], Loss: 0.2041\n",
      "Epoch [3/15], Step [392/454], Loss: 0.2585\n",
      "Epoch [3/15], Step [448/454], Loss: 0.1871\n",
      "Train phase -  Epoch 3 Loss: 0.2686 Acc: 0.9268\n",
      "Epoch [3/15], Step [14/114], Loss: 0.2311\n",
      "Epoch [3/15], Step [28/114], Loss: 0.3075\n",
      "Epoch [3/15], Step [42/114], Loss: 0.1910\n",
      "Epoch [3/15], Step [56/114], Loss: 0.1787\n",
      "Epoch [3/15], Step [70/114], Loss: 0.3599\n",
      "Epoch [3/15], Step [84/114], Loss: 0.2166\n",
      "Epoch [3/15], Step [98/114], Loss: 0.1825\n",
      "Epoch [3/15], Step [112/114], Loss: 0.1927\n",
      "Validation phase -  Epoch 3 Loss: 0.2645 Acc: 0.9315\n",
      "----------\n",
      "Epoch 4/15\n",
      "----------\n",
      "Epoch [4/15], Step [56/454], Loss: 0.0604\n",
      "Epoch [4/15], Step [112/454], Loss: 0.1525\n",
      "Epoch [4/15], Step [168/454], Loss: 0.2439\n",
      "Epoch [4/15], Step [224/454], Loss: 0.1710\n",
      "Epoch [4/15], Step [280/454], Loss: 0.0771\n",
      "Epoch [4/15], Step [336/454], Loss: 0.0684\n",
      "Epoch [4/15], Step [392/454], Loss: 0.1476\n",
      "Epoch [4/15], Step [448/454], Loss: 0.2216\n",
      "Train phase -  Epoch 4 Loss: 0.1565 Acc: 0.9599\n",
      "Epoch [4/15], Step [14/114], Loss: 0.0706\n",
      "Epoch [4/15], Step [28/114], Loss: 0.1268\n",
      "Epoch [4/15], Step [42/114], Loss: 0.1576\n",
      "Epoch [4/15], Step [56/114], Loss: 0.0941\n",
      "Epoch [4/15], Step [70/114], Loss: 0.3277\n",
      "Epoch [4/15], Step [84/114], Loss: 0.2176\n",
      "Epoch [4/15], Step [98/114], Loss: 0.1031\n",
      "Epoch [4/15], Step [112/114], Loss: 0.1841\n",
      "Validation phase -  Epoch 4 Loss: 0.1626 Acc: 0.9529\n",
      "----------\n",
      "Epoch 5/15\n",
      "----------\n",
      "Epoch [5/15], Step [56/454], Loss: 0.0418\n",
      "Epoch [5/15], Step [112/454], Loss: 0.0493\n",
      "Epoch [5/15], Step [168/454], Loss: 0.1180\n",
      "Epoch [5/15], Step [224/454], Loss: 0.0694\n",
      "Epoch [5/15], Step [280/454], Loss: 0.1813\n",
      "Epoch [5/15], Step [336/454], Loss: 0.0884\n",
      "Epoch [5/15], Step [392/454], Loss: 0.1158\n",
      "Epoch [5/15], Step [448/454], Loss: 0.0644\n",
      "Train phase -  Epoch 5 Loss: 0.0969 Acc: 0.9767\n",
      "Epoch [5/15], Step [14/114], Loss: 0.0729\n",
      "Epoch [5/15], Step [28/114], Loss: 0.0992\n",
      "Epoch [5/15], Step [42/114], Loss: 0.1339\n",
      "Epoch [5/15], Step [56/114], Loss: 0.1388\n",
      "Epoch [5/15], Step [70/114], Loss: 0.0874\n",
      "Epoch [5/15], Step [84/114], Loss: 0.0267\n",
      "Epoch [5/15], Step [98/114], Loss: 0.0330\n",
      "Epoch [5/15], Step [112/114], Loss: 0.0976\n",
      "Validation phase -  Epoch 5 Loss: 0.1106 Acc: 0.9740\n",
      "----------\n",
      "Epoch 6/15\n",
      "----------\n",
      "Epoch [6/15], Step [56/454], Loss: 0.0549\n",
      "Epoch [6/15], Step [112/454], Loss: 0.0594\n",
      "Epoch [6/15], Step [168/454], Loss: 0.0505\n",
      "Epoch [6/15], Step [224/454], Loss: 0.0435\n",
      "Epoch [6/15], Step [280/454], Loss: 0.0594\n",
      "Epoch [6/15], Step [336/454], Loss: 0.0563\n",
      "Epoch [6/15], Step [392/454], Loss: 0.0670\n",
      "Epoch [6/15], Step [448/454], Loss: 0.0683\n",
      "Train phase -  Epoch 6 Loss: 0.0690 Acc: 0.9828\n",
      "Epoch [6/15], Step [14/114], Loss: 0.0332\n",
      "Epoch [6/15], Step [28/114], Loss: 0.0576\n",
      "Epoch [6/15], Step [42/114], Loss: 0.0869\n",
      "Epoch [6/15], Step [56/114], Loss: 0.0452\n",
      "Epoch [6/15], Step [70/114], Loss: 0.1905\n",
      "Epoch [6/15], Step [84/114], Loss: 0.0884\n",
      "Epoch [6/15], Step [98/114], Loss: 0.0489\n",
      "Epoch [6/15], Step [112/114], Loss: 0.0265\n",
      "Validation phase -  Epoch 6 Loss: 0.0837 Acc: 0.9788\n",
      "----------\n",
      "Epoch 7/15\n",
      "----------\n",
      "Epoch [7/15], Step [56/454], Loss: 0.0102\n",
      "Epoch [7/15], Step [112/454], Loss: 0.0315\n",
      "Epoch [7/15], Step [168/454], Loss: 0.0166\n",
      "Epoch [7/15], Step [224/454], Loss: 0.0272\n",
      "Epoch [7/15], Step [280/454], Loss: 0.0335\n",
      "Epoch [7/15], Step [336/454], Loss: 0.0137\n",
      "Epoch [7/15], Step [392/454], Loss: 0.0662\n",
      "Epoch [7/15], Step [448/454], Loss: 0.0641\n",
      "Train phase -  Epoch 7 Loss: 0.0481 Acc: 0.9889\n",
      "Epoch [7/15], Step [14/114], Loss: 0.0900\n",
      "Epoch [7/15], Step [28/114], Loss: 0.0809\n",
      "Epoch [7/15], Step [42/114], Loss: 0.0056\n",
      "Epoch [7/15], Step [56/114], Loss: 0.0763\n",
      "Epoch [7/15], Step [70/114], Loss: 0.0379\n",
      "Epoch [7/15], Step [84/114], Loss: 0.0215\n",
      "Epoch [7/15], Step [98/114], Loss: 0.1785\n",
      "Epoch [7/15], Step [112/114], Loss: 0.0307\n",
      "Validation phase -  Epoch 7 Loss: 0.0727 Acc: 0.9832\n",
      "----------\n",
      "Epoch 8/15\n",
      "----------\n",
      "Epoch [8/15], Step [56/454], Loss: 0.0225\n",
      "Epoch [8/15], Step [112/454], Loss: 0.0234\n",
      "Epoch [8/15], Step [168/454], Loss: 0.1450\n",
      "Epoch [8/15], Step [224/454], Loss: 0.0401\n",
      "Epoch [8/15], Step [280/454], Loss: 0.0078\n",
      "Epoch [8/15], Step [336/454], Loss: 0.0370\n",
      "Epoch [8/15], Step [392/454], Loss: 0.0224\n",
      "Epoch [8/15], Step [448/454], Loss: 0.0201\n",
      "Train phase -  Epoch 8 Loss: 0.0385 Acc: 0.9915\n",
      "Epoch [8/15], Step [14/114], Loss: 0.0204\n",
      "Epoch [8/15], Step [28/114], Loss: 0.2501\n",
      "Epoch [8/15], Step [42/114], Loss: 0.0474\n",
      "Epoch [8/15], Step [56/114], Loss: 0.0276\n",
      "Epoch [8/15], Step [70/114], Loss: 0.0787\n",
      "Epoch [8/15], Step [84/114], Loss: 0.0248\n",
      "Epoch [8/15], Step [98/114], Loss: 0.0421\n",
      "Epoch [8/15], Step [112/114], Loss: 0.0216\n",
      "Validation phase -  Epoch 8 Loss: 0.0623 Acc: 0.9875\n",
      "----------\n",
      "Epoch 9/15\n",
      "----------\n",
      "Epoch [9/15], Step [56/454], Loss: 0.0129\n",
      "Epoch [9/15], Step [112/454], Loss: 0.0044\n",
      "Epoch [9/15], Step [168/454], Loss: 0.0128\n",
      "Epoch [9/15], Step [224/454], Loss: 0.1051\n",
      "Epoch [9/15], Step [280/454], Loss: 0.0181\n",
      "Epoch [9/15], Step [336/454], Loss: 0.0330\n",
      "Epoch [9/15], Step [392/454], Loss: 0.0057\n",
      "Epoch [9/15], Step [448/454], Loss: 0.0102\n",
      "Train phase -  Epoch 9 Loss: 0.0278 Acc: 0.9940\n",
      "Epoch [9/15], Step [14/114], Loss: 0.0274\n",
      "Epoch [9/15], Step [28/114], Loss: 0.0532\n",
      "Epoch [9/15], Step [42/114], Loss: 0.0667\n",
      "Epoch [9/15], Step [56/114], Loss: 0.1261\n",
      "Epoch [9/15], Step [70/114], Loss: 0.0521\n",
      "Epoch [9/15], Step [84/114], Loss: 0.0333\n",
      "Epoch [9/15], Step [98/114], Loss: 0.0462\n",
      "Epoch [9/15], Step [112/114], Loss: 0.2902\n",
      "Validation phase -  Epoch 9 Loss: 0.0657 Acc: 0.9850\n",
      "----------\n",
      "Epoch 10/15\n",
      "----------\n",
      "Epoch [10/15], Step [56/454], Loss: 0.0120\n",
      "Epoch [10/15], Step [112/454], Loss: 0.0146\n",
      "Epoch [10/15], Step [168/454], Loss: 0.0084\n",
      "Epoch [10/15], Step [224/454], Loss: 0.0050\n",
      "Epoch [10/15], Step [280/454], Loss: 0.0068\n",
      "Epoch [10/15], Step [336/454], Loss: 0.0079\n",
      "Epoch [10/15], Step [392/454], Loss: 0.0250\n",
      "Epoch [10/15], Step [448/454], Loss: 0.0243\n",
      "Train phase -  Epoch 10 Loss: 0.0210 Acc: 0.9954\n",
      "Epoch [10/15], Step [14/114], Loss: 0.0095\n",
      "Epoch [10/15], Step [28/114], Loss: 0.1476\n",
      "Epoch [10/15], Step [42/114], Loss: 0.0581\n",
      "Epoch [10/15], Step [56/114], Loss: 0.0908\n",
      "Epoch [10/15], Step [70/114], Loss: 0.1176\n",
      "Epoch [10/15], Step [84/114], Loss: 0.1976\n",
      "Epoch [10/15], Step [98/114], Loss: 0.1724\n",
      "Epoch [10/15], Step [112/114], Loss: 0.0310\n",
      "Validation phase -  Epoch 10 Loss: 0.0791 Acc: 0.9807\n",
      "----------\n",
      "Epoch 11/15\n",
      "----------\n",
      "Epoch [11/15], Step [56/454], Loss: 0.0212\n",
      "Epoch [11/15], Step [112/454], Loss: 0.0050\n",
      "Epoch [11/15], Step [168/454], Loss: 0.0142\n",
      "Epoch [11/15], Step [224/454], Loss: 0.0147\n",
      "Epoch [11/15], Step [280/454], Loss: 0.0122\n",
      "Epoch [11/15], Step [336/454], Loss: 0.0548\n",
      "Epoch [11/15], Step [392/454], Loss: 0.0156\n",
      "Epoch [11/15], Step [448/454], Loss: 0.0124\n",
      "Train phase -  Epoch 11 Loss: 0.0265 Acc: 0.9940\n",
      "Epoch [11/15], Step [14/114], Loss: 0.0227\n",
      "Epoch [11/15], Step [28/114], Loss: 0.0559\n",
      "Epoch [11/15], Step [42/114], Loss: 0.2416\n",
      "Epoch [11/15], Step [56/114], Loss: 0.0856\n",
      "Epoch [11/15], Step [70/114], Loss: 0.1424\n",
      "Epoch [11/15], Step [84/114], Loss: 0.0029\n",
      "Epoch [11/15], Step [98/114], Loss: 0.0031\n",
      "Epoch [11/15], Step [112/114], Loss: 0.0426\n",
      "Validation phase -  Epoch 11 Loss: 0.0474 Acc: 0.9893\n",
      "----------\n",
      "Epoch 12/15\n",
      "----------\n",
      "Epoch [12/15], Step [56/454], Loss: 0.0030\n",
      "Epoch [12/15], Step [112/454], Loss: 0.0029\n",
      "Epoch [12/15], Step [168/454], Loss: 0.0074\n",
      "Epoch [12/15], Step [224/454], Loss: 0.0116\n",
      "Epoch [12/15], Step [280/454], Loss: 0.0148\n",
      "Epoch [12/15], Step [336/454], Loss: 0.0013\n",
      "Epoch [12/15], Step [392/454], Loss: 0.0266\n",
      "Epoch [12/15], Step [448/454], Loss: 0.0266\n",
      "Train phase -  Epoch 12 Loss: 0.0104 Acc: 0.9982\n",
      "Epoch [12/15], Step [14/114], Loss: 0.1100\n",
      "Epoch [12/15], Step [28/114], Loss: 0.2225\n",
      "Epoch [12/15], Step [42/114], Loss: 0.0212\n",
      "Epoch [12/15], Step [56/114], Loss: 0.0822\n",
      "Epoch [12/15], Step [70/114], Loss: 0.0480\n",
      "Epoch [12/15], Step [84/114], Loss: 0.0252\n",
      "Epoch [12/15], Step [98/114], Loss: 0.0181\n",
      "Epoch [12/15], Step [112/114], Loss: 0.0491\n",
      "Validation phase -  Epoch 12 Loss: 0.0634 Acc: 0.9853\n",
      "----------\n",
      "Epoch 13/15\n",
      "----------\n",
      "Epoch [13/15], Step [56/454], Loss: 0.0106\n",
      "Epoch [13/15], Step [112/454], Loss: 0.0060\n",
      "Epoch [13/15], Step [168/454], Loss: 0.0096\n",
      "Epoch [13/15], Step [224/454], Loss: 0.0063\n",
      "Epoch [13/15], Step [280/454], Loss: 0.0090\n",
      "Epoch [13/15], Step [336/454], Loss: 0.0320\n",
      "Epoch [13/15], Step [392/454], Loss: 0.0034\n",
      "Epoch [13/15], Step [448/454], Loss: 0.0019\n",
      "Train phase -  Epoch 13 Loss: 0.0110 Acc: 0.9979\n",
      "Epoch [13/15], Step [14/114], Loss: 0.0122\n",
      "Epoch [13/15], Step [28/114], Loss: 0.0468\n",
      "Epoch [13/15], Step [42/114], Loss: 0.0173\n",
      "Epoch [13/15], Step [56/114], Loss: 0.1103\n",
      "Epoch [13/15], Step [70/114], Loss: 0.3089\n",
      "Epoch [13/15], Step [84/114], Loss: 0.0305\n",
      "Epoch [13/15], Step [98/114], Loss: 0.0941\n",
      "Epoch [13/15], Step [112/114], Loss: 0.0020\n",
      "Validation phase -  Epoch 13 Loss: 0.0536 Acc: 0.9872\n",
      "----------\n",
      "Epoch 14/15\n",
      "----------\n",
      "Epoch [14/15], Step [56/454], Loss: 0.0055\n",
      "Epoch [14/15], Step [112/454], Loss: 0.0049\n",
      "Epoch [14/15], Step [168/454], Loss: 0.0020\n",
      "Epoch [14/15], Step [224/454], Loss: 0.0040\n",
      "Epoch [14/15], Step [280/454], Loss: 0.0019\n",
      "Epoch [14/15], Step [336/454], Loss: 0.0018\n",
      "Epoch [14/15], Step [392/454], Loss: 0.0024\n",
      "Epoch [14/15], Step [448/454], Loss: 0.0130\n",
      "Train phase -  Epoch 14 Loss: 0.0042 Acc: 0.9996\n",
      "Epoch [14/15], Step [14/114], Loss: 0.0158\n",
      "Epoch [14/15], Step [28/114], Loss: 0.0037\n",
      "Epoch [14/15], Step [42/114], Loss: 0.0312\n",
      "Epoch [14/15], Step [56/114], Loss: 0.1561\n",
      "Epoch [14/15], Step [70/114], Loss: 0.0376\n",
      "Epoch [14/15], Step [84/114], Loss: 0.0051\n",
      "Epoch [14/15], Step [98/114], Loss: 0.0334\n",
      "Epoch [14/15], Step [112/114], Loss: 0.0024\n",
      "Validation phase -  Epoch 14 Loss: 0.0499 Acc: 0.9882\n",
      "----------\n",
      "Epoch 15/15\n",
      "----------\n",
      "Epoch [15/15], Step [56/454], Loss: 0.0167\n",
      "Epoch [15/15], Step [112/454], Loss: 0.0255\n",
      "Epoch [15/15], Step [168/454], Loss: 0.0034\n",
      "Epoch [15/15], Step [224/454], Loss: 0.0038\n",
      "Epoch [15/15], Step [280/454], Loss: 0.0003\n",
      "Epoch [15/15], Step [336/454], Loss: 0.2047\n",
      "Epoch [15/15], Step [392/454], Loss: 0.0117\n",
      "Epoch [15/15], Step [448/454], Loss: 0.0254\n",
      "Train phase -  Epoch 15 Loss: 0.0185 Acc: 0.9957\n",
      "Epoch [15/15], Step [14/114], Loss: 0.0597\n",
      "Epoch [15/15], Step [28/114], Loss: 0.0744\n",
      "Epoch [15/15], Step [42/114], Loss: 0.1145\n",
      "Epoch [15/15], Step [56/114], Loss: 0.0696\n",
      "Epoch [15/15], Step [70/114], Loss: 0.0832\n",
      "Epoch [15/15], Step [84/114], Loss: 0.1319\n",
      "Epoch [15/15], Step [98/114], Loss: 0.0922\n",
      "Epoch [15/15], Step [112/114], Loss: 0.0332\n",
      "Validation phase -  Epoch 15 Loss: 0.0952 Acc: 0.9751\n",
      "Training complete in 10m 42s\n",
      "Best val Acc:0.9893\n",
      "Test phase -  Model accuracy: 0.9890\n",
      "Finished Training no-loss-weight_P_CNN_adam\n",
      "----------\n",
      "Epoch 1/15\n",
      "----------\n",
      "Epoch [1/15], Step [56/454], Loss: 3.7020\n",
      "Epoch [1/15], Step [112/454], Loss: 3.5549\n",
      "Epoch [1/15], Step [168/454], Loss: 3.4548\n",
      "Epoch [1/15], Step [224/454], Loss: 3.5750\n",
      "Epoch [1/15], Step [280/454], Loss: 3.4243\n",
      "Epoch [1/15], Step [336/454], Loss: 3.3450\n",
      "Epoch [1/15], Step [392/454], Loss: 3.3766\n",
      "Epoch [1/15], Step [448/454], Loss: 3.2692\n",
      "Train phase -  Epoch 1 Loss: 3.4937 Acc: 0.0820\n",
      "Epoch [1/15], Step [14/114], Loss: 3.2431\n",
      "Epoch [1/15], Step [28/114], Loss: 3.2421\n",
      "Epoch [1/15], Step [42/114], Loss: 3.2340\n",
      "Epoch [1/15], Step [56/114], Loss: 3.3556\n",
      "Epoch [1/15], Step [70/114], Loss: 3.3898\n",
      "Epoch [1/15], Step [84/114], Loss: 3.3180\n",
      "Epoch [1/15], Step [98/114], Loss: 3.4063\n",
      "Epoch [1/15], Step [112/114], Loss: 3.2831\n",
      "Validation phase -  Epoch 1 Loss: 3.3179 Acc: 0.1099\n",
      "----------\n",
      "Epoch 2/15\n",
      "----------\n",
      "Epoch [2/15], Step [56/454], Loss: 3.2911\n",
      "Epoch [2/15], Step [112/454], Loss: 3.1460\n",
      "Epoch [2/15], Step [168/454], Loss: 3.0402\n",
      "Epoch [2/15], Step [224/454], Loss: 3.1342\n",
      "Epoch [2/15], Step [280/454], Loss: 3.3403\n",
      "Epoch [2/15], Step [336/454], Loss: 2.9024\n",
      "Epoch [2/15], Step [392/454], Loss: 3.2971\n",
      "Epoch [2/15], Step [448/454], Loss: 2.7541\n",
      "Train phase -  Epoch 2 Loss: 3.1298 Acc: 0.1826\n",
      "Epoch [2/15], Step [14/114], Loss: 2.7986\n",
      "Epoch [2/15], Step [28/114], Loss: 2.8586\n",
      "Epoch [2/15], Step [42/114], Loss: 2.5006\n",
      "Epoch [2/15], Step [56/114], Loss: 2.9200\n",
      "Epoch [2/15], Step [70/114], Loss: 2.6284\n",
      "Epoch [2/15], Step [84/114], Loss: 2.7924\n",
      "Epoch [2/15], Step [98/114], Loss: 2.8895\n",
      "Epoch [2/15], Step [112/114], Loss: 2.8238\n",
      "Validation phase -  Epoch 2 Loss: 2.7344 Acc: 0.2698\n",
      "----------\n",
      "Epoch 3/15\n",
      "----------\n",
      "Epoch [3/15], Step [56/454], Loss: 2.5629\n",
      "Epoch [3/15], Step [112/454], Loss: 2.8544\n",
      "Epoch [3/15], Step [168/454], Loss: 2.5033\n",
      "Epoch [3/15], Step [224/454], Loss: 1.7266\n",
      "Epoch [3/15], Step [280/454], Loss: 2.1021\n",
      "Epoch [3/15], Step [336/454], Loss: 1.9294\n",
      "Epoch [3/15], Step [392/454], Loss: 1.8846\n",
      "Epoch [3/15], Step [448/454], Loss: 1.4741\n",
      "Train phase -  Epoch 3 Loss: 2.1349 Acc: 0.4116\n",
      "Epoch [3/15], Step [14/114], Loss: 1.5574\n",
      "Epoch [3/15], Step [28/114], Loss: 1.8033\n",
      "Epoch [3/15], Step [42/114], Loss: 1.6183\n",
      "Epoch [3/15], Step [56/114], Loss: 1.5131\n",
      "Epoch [3/15], Step [70/114], Loss: 1.4691\n",
      "Epoch [3/15], Step [84/114], Loss: 1.3484\n",
      "Epoch [3/15], Step [98/114], Loss: 1.6923\n",
      "Epoch [3/15], Step [112/114], Loss: 1.4194\n",
      "Validation phase -  Epoch 3 Loss: 1.5427 Acc: 0.5401\n",
      "----------\n",
      "Epoch 4/15\n",
      "----------\n",
      "Epoch [4/15], Step [56/454], Loss: 1.4689\n",
      "Epoch [4/15], Step [112/454], Loss: 0.9683\n",
      "Epoch [4/15], Step [168/454], Loss: 1.1881\n",
      "Epoch [4/15], Step [224/454], Loss: 1.1093\n",
      "Epoch [4/15], Step [280/454], Loss: 1.0505\n",
      "Epoch [4/15], Step [336/454], Loss: 0.9318\n",
      "Epoch [4/15], Step [392/454], Loss: 0.7873\n",
      "Epoch [4/15], Step [448/454], Loss: 0.8856\n",
      "Train phase -  Epoch 4 Loss: 1.1533 Acc: 0.6618\n",
      "Epoch [4/15], Step [14/114], Loss: 0.8566\n",
      "Epoch [4/15], Step [28/114], Loss: 0.4381\n",
      "Epoch [4/15], Step [42/114], Loss: 0.9958\n",
      "Epoch [4/15], Step [56/114], Loss: 0.8022\n",
      "Epoch [4/15], Step [70/114], Loss: 0.9714\n",
      "Epoch [4/15], Step [84/114], Loss: 0.6938\n",
      "Epoch [4/15], Step [98/114], Loss: 0.6894\n",
      "Epoch [4/15], Step [112/114], Loss: 1.0852\n",
      "Validation phase -  Epoch 4 Loss: 0.8228 Acc: 0.7661\n",
      "----------\n",
      "Epoch 5/15\n",
      "----------\n",
      "Epoch [5/15], Step [56/454], Loss: 0.7348\n",
      "Epoch [5/15], Step [112/454], Loss: 0.5630\n",
      "Epoch [5/15], Step [168/454], Loss: 0.5692\n",
      "Epoch [5/15], Step [224/454], Loss: 0.7597\n",
      "Epoch [5/15], Step [280/454], Loss: 1.1706\n",
      "Epoch [5/15], Step [336/454], Loss: 0.4100\n",
      "Epoch [5/15], Step [392/454], Loss: 0.6149\n",
      "Epoch [5/15], Step [448/454], Loss: 0.4785\n",
      "Train phase -  Epoch 5 Loss: 0.6326 Acc: 0.8195\n",
      "Epoch [5/15], Step [14/114], Loss: 0.5519\n",
      "Epoch [5/15], Step [28/114], Loss: 0.6356\n",
      "Epoch [5/15], Step [42/114], Loss: 0.4684\n",
      "Epoch [5/15], Step [56/114], Loss: 0.9130\n",
      "Epoch [5/15], Step [70/114], Loss: 0.8329\n",
      "Epoch [5/15], Step [84/114], Loss: 0.5212\n",
      "Epoch [5/15], Step [98/114], Loss: 0.6767\n",
      "Epoch [5/15], Step [112/114], Loss: 0.7299\n",
      "Validation phase -  Epoch 5 Loss: 0.5989 Acc: 0.8212\n",
      "----------\n",
      "Epoch 6/15\n",
      "----------\n",
      "Epoch [6/15], Step [56/454], Loss: 0.3178\n",
      "Epoch [6/15], Step [112/454], Loss: 0.7022\n",
      "Epoch [6/15], Step [168/454], Loss: 0.3016\n",
      "Epoch [6/15], Step [224/454], Loss: 0.2303\n",
      "Epoch [6/15], Step [280/454], Loss: 0.4828\n",
      "Epoch [6/15], Step [336/454], Loss: 0.5660\n",
      "Epoch [6/15], Step [392/454], Loss: 0.1953\n",
      "Epoch [6/15], Step [448/454], Loss: 0.1695\n",
      "Train phase -  Epoch 6 Loss: 0.4253 Acc: 0.8956\n",
      "Epoch [6/15], Step [14/114], Loss: 0.2785\n",
      "Epoch [6/15], Step [28/114], Loss: 0.1740\n",
      "Epoch [6/15], Step [42/114], Loss: 0.2347\n",
      "Epoch [6/15], Step [56/114], Loss: 0.3065\n",
      "Epoch [6/15], Step [70/114], Loss: 0.1998\n",
      "Epoch [6/15], Step [84/114], Loss: 0.4157\n",
      "Epoch [6/15], Step [98/114], Loss: 0.2104\n",
      "Epoch [6/15], Step [112/114], Loss: 0.2181\n",
      "Validation phase -  Epoch 6 Loss: 0.2642 Acc: 0.9311\n",
      "----------\n",
      "Epoch 7/15\n",
      "----------\n",
      "Epoch [7/15], Step [56/454], Loss: 0.2733\n",
      "Epoch [7/15], Step [112/454], Loss: 0.1346\n",
      "Epoch [7/15], Step [168/454], Loss: 0.1179\n",
      "Epoch [7/15], Step [224/454], Loss: 0.1262\n",
      "Epoch [7/15], Step [280/454], Loss: 0.3239\n",
      "Epoch [7/15], Step [336/454], Loss: 0.2432\n",
      "Epoch [7/15], Step [392/454], Loss: 0.0806\n",
      "Epoch [7/15], Step [448/454], Loss: 0.1897\n",
      "Train phase -  Epoch 7 Loss: 0.2832 Acc: 0.9366\n",
      "Epoch [7/15], Step [14/114], Loss: 0.2242\n",
      "Epoch [7/15], Step [28/114], Loss: 0.2976\n",
      "Epoch [7/15], Step [42/114], Loss: 0.2649\n",
      "Epoch [7/15], Step [56/114], Loss: 0.1194\n",
      "Epoch [7/15], Step [70/114], Loss: 0.0915\n",
      "Epoch [7/15], Step [84/114], Loss: 0.1862\n",
      "Epoch [7/15], Step [98/114], Loss: 0.0957\n",
      "Epoch [7/15], Step [112/114], Loss: 0.1308\n",
      "Validation phase -  Epoch 7 Loss: 0.1875 Acc: 0.9599\n",
      "----------\n",
      "Epoch 8/15\n",
      "----------\n",
      "Epoch [8/15], Step [56/454], Loss: 0.1573\n",
      "Epoch [8/15], Step [112/454], Loss: 0.0945\n",
      "Epoch [8/15], Step [168/454], Loss: 0.2622\n",
      "Epoch [8/15], Step [224/454], Loss: 0.2368\n",
      "Epoch [8/15], Step [280/454], Loss: 0.1970\n",
      "Epoch [8/15], Step [336/454], Loss: 0.0928\n",
      "Epoch [8/15], Step [392/454], Loss: 0.2023\n",
      "Epoch [8/15], Step [448/454], Loss: 0.0800\n",
      "Train phase -  Epoch 8 Loss: 0.1618 Acc: 0.9606\n",
      "Epoch [8/15], Step [14/114], Loss: 0.1299\n",
      "Epoch [8/15], Step [28/114], Loss: 0.0497\n",
      "Epoch [8/15], Step [42/114], Loss: 0.1804\n",
      "Epoch [8/15], Step [56/114], Loss: 0.1119\n",
      "Epoch [8/15], Step [70/114], Loss: 0.1150\n",
      "Epoch [8/15], Step [84/114], Loss: 0.2094\n",
      "Epoch [8/15], Step [98/114], Loss: 0.1479\n",
      "Epoch [8/15], Step [112/114], Loss: 0.1619\n",
      "Validation phase -  Epoch 8 Loss: 0.1785 Acc: 0.9538\n",
      "----------\n",
      "Epoch 9/15\n",
      "----------\n",
      "Epoch [9/15], Step [56/454], Loss: 0.1098\n",
      "Epoch [9/15], Step [112/454], Loss: 0.1002\n",
      "Epoch [9/15], Step [168/454], Loss: 0.1190\n",
      "Epoch [9/15], Step [224/454], Loss: 0.0653\n",
      "Epoch [9/15], Step [280/454], Loss: 0.1307\n",
      "Epoch [9/15], Step [336/454], Loss: 0.0168\n",
      "Epoch [9/15], Step [392/454], Loss: 0.2213\n",
      "Epoch [9/15], Step [448/454], Loss: 0.1453\n",
      "Train phase -  Epoch 9 Loss: 0.1916 Acc: 0.9627\n",
      "Epoch [9/15], Step [14/114], Loss: 0.0934\n",
      "Epoch [9/15], Step [28/114], Loss: 0.2476\n",
      "Epoch [9/15], Step [42/114], Loss: 0.0689\n",
      "Epoch [9/15], Step [56/114], Loss: 0.0504\n",
      "Epoch [9/15], Step [70/114], Loss: 0.0886\n",
      "Epoch [9/15], Step [84/114], Loss: 0.2479\n",
      "Epoch [9/15], Step [98/114], Loss: 0.1562\n",
      "Epoch [9/15], Step [112/114], Loss: 0.3066\n",
      "Validation phase -  Epoch 9 Loss: 0.1485 Acc: 0.9671\n",
      "----------\n",
      "Epoch 10/15\n",
      "----------\n",
      "Epoch [10/15], Step [56/454], Loss: 0.1107\n",
      "Epoch [10/15], Step [112/454], Loss: 0.1429\n",
      "Epoch [10/15], Step [168/454], Loss: 0.0960\n",
      "Epoch [10/15], Step [224/454], Loss: 0.1500\n",
      "Epoch [10/15], Step [280/454], Loss: 0.0417\n",
      "Epoch [10/15], Step [336/454], Loss: 0.0668\n",
      "Epoch [10/15], Step [392/454], Loss: 0.0680\n",
      "Epoch [10/15], Step [448/454], Loss: 0.1358\n",
      "Train phase -  Epoch 10 Loss: 0.1045 Acc: 0.9761\n",
      "Epoch [10/15], Step [14/114], Loss: 0.0318\n",
      "Epoch [10/15], Step [28/114], Loss: 0.0769\n",
      "Epoch [10/15], Step [42/114], Loss: 0.0801\n",
      "Epoch [10/15], Step [56/114], Loss: 0.0462\n",
      "Epoch [10/15], Step [70/114], Loss: 0.1041\n",
      "Epoch [10/15], Step [84/114], Loss: 0.1364\n",
      "Epoch [10/15], Step [98/114], Loss: 0.1405\n",
      "Epoch [10/15], Step [112/114], Loss: 0.0661\n",
      "Validation phase -  Epoch 10 Loss: 0.1274 Acc: 0.9682\n",
      "----------\n",
      "Epoch 11/15\n",
      "----------\n",
      "Epoch [11/15], Step [56/454], Loss: 0.0453\n",
      "Epoch [11/15], Step [112/454], Loss: 0.0438\n",
      "Epoch [11/15], Step [168/454], Loss: 0.0233\n",
      "Epoch [11/15], Step [224/454], Loss: 0.0422\n",
      "Epoch [11/15], Step [280/454], Loss: 0.0733\n",
      "Epoch [11/15], Step [336/454], Loss: 0.1319\n",
      "Epoch [11/15], Step [392/454], Loss: 0.0529\n",
      "Epoch [11/15], Step [448/454], Loss: 0.0785\n",
      "Train phase -  Epoch 11 Loss: 0.0795 Acc: 0.9815\n",
      "Epoch [11/15], Step [14/114], Loss: 0.1192\n",
      "Epoch [11/15], Step [28/114], Loss: 0.2413\n",
      "Epoch [11/15], Step [42/114], Loss: 0.0822\n",
      "Epoch [11/15], Step [56/114], Loss: 0.1959\n",
      "Epoch [11/15], Step [70/114], Loss: 0.0538\n",
      "Epoch [11/15], Step [84/114], Loss: 0.0289\n",
      "Epoch [11/15], Step [98/114], Loss: 0.0683\n",
      "Epoch [11/15], Step [112/114], Loss: 0.0613\n",
      "Validation phase -  Epoch 11 Loss: 0.1052 Acc: 0.9751\n",
      "----------\n",
      "Epoch 12/15\n",
      "----------\n",
      "Epoch [12/15], Step [56/454], Loss: 0.0403\n",
      "Epoch [12/15], Step [112/454], Loss: 0.0750\n",
      "Epoch [12/15], Step [168/454], Loss: 0.0890\n",
      "Epoch [12/15], Step [224/454], Loss: 0.0318\n",
      "Epoch [12/15], Step [280/454], Loss: 0.0792\n",
      "Epoch [12/15], Step [336/454], Loss: 0.0446\n",
      "Epoch [12/15], Step [392/454], Loss: 0.0627\n",
      "Epoch [12/15], Step [448/454], Loss: 0.3141\n",
      "Train phase -  Epoch 12 Loss: 0.0658 Acc: 0.9853\n",
      "Epoch [12/15], Step [14/114], Loss: 0.0341\n",
      "Epoch [12/15], Step [28/114], Loss: 0.0270\n",
      "Epoch [12/15], Step [42/114], Loss: 0.1764\n",
      "Epoch [12/15], Step [56/114], Loss: 0.0246\n",
      "Epoch [12/15], Step [70/114], Loss: 0.0939\n",
      "Epoch [12/15], Step [84/114], Loss: 0.0162\n",
      "Epoch [12/15], Step [98/114], Loss: 0.2182\n",
      "Epoch [12/15], Step [112/114], Loss: 0.0199\n",
      "Validation phase -  Epoch 12 Loss: 0.0827 Acc: 0.9832\n",
      "----------\n",
      "Epoch 13/15\n",
      "----------\n",
      "Epoch [13/15], Step [56/454], Loss: 0.0538\n",
      "Epoch [13/15], Step [112/454], Loss: 0.0480\n",
      "Epoch [13/15], Step [168/454], Loss: 0.1261\n",
      "Epoch [13/15], Step [224/454], Loss: 0.0280\n",
      "Epoch [13/15], Step [280/454], Loss: 0.0612\n",
      "Epoch [13/15], Step [336/454], Loss: 0.0906\n",
      "Epoch [13/15], Step [392/454], Loss: 0.0414\n",
      "Epoch [13/15], Step [448/454], Loss: 0.1012\n",
      "Train phase -  Epoch 13 Loss: 0.0649 Acc: 0.9854\n",
      "Epoch [13/15], Step [14/114], Loss: 0.0271\n",
      "Epoch [13/15], Step [28/114], Loss: 0.0427\n",
      "Epoch [13/15], Step [42/114], Loss: 0.0280\n",
      "Epoch [13/15], Step [56/114], Loss: 0.0981\n",
      "Epoch [13/15], Step [70/114], Loss: 0.0394\n",
      "Epoch [13/15], Step [84/114], Loss: 0.2984\n",
      "Epoch [13/15], Step [98/114], Loss: 0.0197\n",
      "Epoch [13/15], Step [112/114], Loss: 0.0106\n",
      "Validation phase -  Epoch 13 Loss: 0.0923 Acc: 0.9792\n",
      "----------\n",
      "Epoch 14/15\n",
      "----------\n",
      "Epoch [14/15], Step [56/454], Loss: 0.1821\n",
      "Epoch [14/15], Step [112/454], Loss: 0.0700\n",
      "Epoch [14/15], Step [168/454], Loss: 0.0075\n",
      "Epoch [14/15], Step [224/454], Loss: 0.0250\n",
      "Epoch [14/15], Step [280/454], Loss: 0.0241\n",
      "Epoch [14/15], Step [336/454], Loss: 0.0874\n",
      "Epoch [14/15], Step [392/454], Loss: 0.0348\n",
      "Epoch [14/15], Step [448/454], Loss: 0.0307\n",
      "Train phase -  Epoch 14 Loss: 0.0497 Acc: 0.9892\n",
      "Epoch [14/15], Step [14/114], Loss: 0.1610\n",
      "Epoch [14/15], Step [28/114], Loss: 0.1178\n",
      "Epoch [14/15], Step [42/114], Loss: 0.0892\n",
      "Epoch [14/15], Step [56/114], Loss: 0.0941\n",
      "Epoch [14/15], Step [70/114], Loss: 0.0699\n",
      "Epoch [14/15], Step [84/114], Loss: 0.0170\n",
      "Epoch [14/15], Step [98/114], Loss: 0.0445\n",
      "Epoch [14/15], Step [112/114], Loss: 0.0652\n",
      "Validation phase -  Epoch 14 Loss: 0.1282 Acc: 0.9672\n",
      "----------\n",
      "Epoch 15/15\n",
      "----------\n",
      "Epoch [15/15], Step [56/454], Loss: 0.0679\n",
      "Epoch [15/15], Step [112/454], Loss: 0.1041\n",
      "Epoch [15/15], Step [168/454], Loss: 0.0509\n",
      "Epoch [15/15], Step [224/454], Loss: 0.1481\n",
      "Epoch [15/15], Step [280/454], Loss: 0.1299\n",
      "Epoch [15/15], Step [336/454], Loss: 0.0234\n",
      "Epoch [15/15], Step [392/454], Loss: 0.0313\n",
      "Epoch [15/15], Step [448/454], Loss: 0.0486\n",
      "Train phase -  Epoch 15 Loss: 0.1625 Acc: 0.9757\n",
      "Epoch [15/15], Step [14/114], Loss: 0.0470\n",
      "Epoch [15/15], Step [28/114], Loss: 0.1066\n",
      "Epoch [15/15], Step [42/114], Loss: 0.0973\n",
      "Epoch [15/15], Step [56/114], Loss: 0.0296\n",
      "Epoch [15/15], Step [70/114], Loss: 0.0311\n",
      "Epoch [15/15], Step [84/114], Loss: 0.0137\n",
      "Epoch [15/15], Step [98/114], Loss: 0.0238\n",
      "Epoch [15/15], Step [112/114], Loss: 0.0889\n",
      "Validation phase -  Epoch 15 Loss: 0.0771 Acc: 0.9843\n",
      "Training complete in 14m 39s\n",
      "Best val Acc:0.9843\n",
      "Test phase -  Model accuracy: 0.9853\n",
      "Finished Training no-loss-weight_P_CNN_ST_sgd\n",
      "----------\n",
      "Epoch 1/15\n",
      "----------\n",
      "Epoch [1/15], Step [56/454], Loss: 3.0327\n",
      "Epoch [1/15], Step [112/454], Loss: 3.0690\n",
      "Epoch [1/15], Step [168/454], Loss: 2.0232\n",
      "Epoch [1/15], Step [224/454], Loss: 1.6660\n",
      "Epoch [1/15], Step [280/454], Loss: 1.5077\n",
      "Epoch [1/15], Step [336/454], Loss: 0.8751\n",
      "Epoch [1/15], Step [392/454], Loss: 0.5248\n",
      "Epoch [1/15], Step [448/454], Loss: 0.5690\n",
      "Train phase -  Epoch 1 Loss: 1.8442 Acc: 0.4971\n",
      "Epoch [1/15], Step [14/114], Loss: 0.6759\n",
      "Epoch [1/15], Step [28/114], Loss: 0.6448\n",
      "Epoch [1/15], Step [42/114], Loss: 0.3378\n",
      "Epoch [1/15], Step [56/114], Loss: 0.7533\n",
      "Epoch [1/15], Step [70/114], Loss: 0.3260\n",
      "Epoch [1/15], Step [84/114], Loss: 0.5085\n",
      "Epoch [1/15], Step [98/114], Loss: 0.4899\n",
      "Epoch [1/15], Step [112/114], Loss: 0.4340\n",
      "Validation phase -  Epoch 1 Loss: 0.5237 Acc: 0.8619\n",
      "----------\n",
      "Epoch 2/15\n",
      "----------\n",
      "Epoch [2/15], Step [56/454], Loss: 0.3843\n",
      "Epoch [2/15], Step [112/454], Loss: 0.4043\n",
      "Epoch [2/15], Step [168/454], Loss: 0.1658\n",
      "Epoch [2/15], Step [224/454], Loss: 0.2470\n",
      "Epoch [2/15], Step [280/454], Loss: 0.1342\n",
      "Epoch [2/15], Step [336/454], Loss: 0.1742\n",
      "Epoch [2/15], Step [392/454], Loss: 0.1314\n",
      "Epoch [2/15], Step [448/454], Loss: 0.1856\n",
      "Train phase -  Epoch 2 Loss: 0.2668 Acc: 0.9312\n",
      "Epoch [2/15], Step [14/114], Loss: 0.2609\n",
      "Epoch [2/15], Step [28/114], Loss: 0.4991\n",
      "Epoch [2/15], Step [42/114], Loss: 0.2160\n",
      "Epoch [2/15], Step [56/114], Loss: 0.2214\n",
      "Epoch [2/15], Step [70/114], Loss: 0.2783\n",
      "Epoch [2/15], Step [84/114], Loss: 0.2342\n",
      "Epoch [2/15], Step [98/114], Loss: 0.2070\n",
      "Epoch [2/15], Step [112/114], Loss: 0.0907\n",
      "Validation phase -  Epoch 2 Loss: 0.2037 Acc: 0.9510\n",
      "----------\n",
      "Epoch 3/15\n",
      "----------\n",
      "Epoch [3/15], Step [56/454], Loss: 0.0504\n",
      "Epoch [3/15], Step [112/454], Loss: 0.1502\n",
      "Epoch [3/15], Step [168/454], Loss: 0.0995\n",
      "Epoch [3/15], Step [224/454], Loss: 0.0720\n",
      "Epoch [3/15], Step [280/454], Loss: 0.3038\n",
      "Epoch [3/15], Step [336/454], Loss: 0.0841\n",
      "Epoch [3/15], Step [392/454], Loss: 0.0340\n",
      "Epoch [3/15], Step [448/454], Loss: 0.0441\n",
      "Train phase -  Epoch 3 Loss: 0.0991 Acc: 0.9775\n",
      "Epoch [3/15], Step [14/114], Loss: 0.1360\n",
      "Epoch [3/15], Step [28/114], Loss: 0.0634\n",
      "Epoch [3/15], Step [42/114], Loss: 0.3069\n",
      "Epoch [3/15], Step [56/114], Loss: 0.1428\n",
      "Epoch [3/15], Step [70/114], Loss: 0.0562\n",
      "Epoch [3/15], Step [84/114], Loss: 0.1634\n",
      "Epoch [3/15], Step [98/114], Loss: 0.0853\n",
      "Epoch [3/15], Step [112/114], Loss: 0.2958\n",
      "Validation phase -  Epoch 3 Loss: 0.1214 Acc: 0.9746\n",
      "----------\n",
      "Epoch 4/15\n",
      "----------\n",
      "Epoch [4/15], Step [56/454], Loss: 0.0935\n",
      "Epoch [4/15], Step [112/454], Loss: 0.0332\n",
      "Epoch [4/15], Step [168/454], Loss: 0.0258\n",
      "Epoch [4/15], Step [224/454], Loss: 0.0446\n",
      "Epoch [4/15], Step [280/454], Loss: 0.0304\n",
      "Epoch [4/15], Step [336/454], Loss: 0.1019\n",
      "Epoch [4/15], Step [392/454], Loss: 0.0261\n",
      "Epoch [4/15], Step [448/454], Loss: 0.0904\n",
      "Train phase -  Epoch 4 Loss: 0.0605 Acc: 0.9848\n",
      "Epoch [4/15], Step [14/114], Loss: 0.0420\n",
      "Epoch [4/15], Step [28/114], Loss: 0.0641\n",
      "Epoch [4/15], Step [42/114], Loss: 0.1122\n",
      "Epoch [4/15], Step [56/114], Loss: 0.1330\n",
      "Epoch [4/15], Step [70/114], Loss: 0.0109\n",
      "Epoch [4/15], Step [84/114], Loss: 0.6305\n",
      "Epoch [4/15], Step [98/114], Loss: 0.0129\n",
      "Epoch [4/15], Step [112/114], Loss: 0.0166\n",
      "Validation phase -  Epoch 4 Loss: 0.0805 Acc: 0.9873\n",
      "----------\n",
      "Epoch 5/15\n",
      "----------\n",
      "Epoch [5/15], Step [56/454], Loss: 0.0842\n",
      "Epoch [5/15], Step [112/454], Loss: 0.0143\n",
      "Epoch [5/15], Step [168/454], Loss: 0.0480\n",
      "Epoch [5/15], Step [224/454], Loss: 0.1836\n",
      "Epoch [5/15], Step [280/454], Loss: 0.0176\n",
      "Epoch [5/15], Step [336/454], Loss: 0.0251\n",
      "Epoch [5/15], Step [392/454], Loss: 0.0961\n",
      "Epoch [5/15], Step [448/454], Loss: 0.0176\n",
      "Train phase -  Epoch 5 Loss: 0.0410 Acc: 0.9906\n",
      "Epoch [5/15], Step [14/114], Loss: 0.3767\n",
      "Epoch [5/15], Step [28/114], Loss: 0.0765\n",
      "Epoch [5/15], Step [42/114], Loss: 0.0421\n",
      "Epoch [5/15], Step [56/114], Loss: 0.1145\n",
      "Epoch [5/15], Step [70/114], Loss: 0.0082\n",
      "Epoch [5/15], Step [84/114], Loss: 0.0940\n",
      "Epoch [5/15], Step [98/114], Loss: 0.2529\n",
      "Epoch [5/15], Step [112/114], Loss: 0.0167\n",
      "Validation phase -  Epoch 5 Loss: 0.0760 Acc: 0.9850\n",
      "----------\n",
      "Epoch 6/15\n",
      "----------\n",
      "Epoch [6/15], Step [56/454], Loss: 0.0370\n",
      "Epoch [6/15], Step [112/454], Loss: 0.0171\n",
      "Epoch [6/15], Step [168/454], Loss: 0.0104\n",
      "Epoch [6/15], Step [224/454], Loss: 0.0111\n",
      "Epoch [6/15], Step [280/454], Loss: 0.0078\n",
      "Epoch [6/15], Step [336/454], Loss: 0.1056\n",
      "Epoch [6/15], Step [392/454], Loss: 0.0102\n",
      "Epoch [6/15], Step [448/454], Loss: 0.0033\n",
      "Train phase -  Epoch 6 Loss: 0.0303 Acc: 0.9930\n",
      "Epoch [6/15], Step [14/114], Loss: 0.0187\n",
      "Epoch [6/15], Step [28/114], Loss: 0.1985\n",
      "Epoch [6/15], Step [42/114], Loss: 0.0460\n",
      "Epoch [6/15], Step [56/114], Loss: 0.0203\n",
      "Epoch [6/15], Step [70/114], Loss: 0.0120\n",
      "Epoch [6/15], Step [84/114], Loss: 0.0092\n",
      "Epoch [6/15], Step [98/114], Loss: 0.0057\n",
      "Epoch [6/15], Step [112/114], Loss: 0.0362\n",
      "Validation phase -  Epoch 6 Loss: 0.0647 Acc: 0.9888\n",
      "----------\n",
      "Epoch 7/15\n",
      "----------\n",
      "Epoch [7/15], Step [56/454], Loss: 0.0048\n",
      "Epoch [7/15], Step [112/454], Loss: 0.0056\n",
      "Epoch [7/15], Step [168/454], Loss: 0.0048\n",
      "Epoch [7/15], Step [224/454], Loss: 0.0203\n",
      "Epoch [7/15], Step [280/454], Loss: 0.0219\n",
      "Epoch [7/15], Step [336/454], Loss: 0.0009\n",
      "Epoch [7/15], Step [392/454], Loss: 0.0125\n",
      "Epoch [7/15], Step [448/454], Loss: 0.0175\n",
      "Train phase -  Epoch 7 Loss: 0.0234 Acc: 0.9943\n",
      "Epoch [7/15], Step [14/114], Loss: 0.0474\n",
      "Epoch [7/15], Step [28/114], Loss: 0.0109\n",
      "Epoch [7/15], Step [42/114], Loss: 0.0184\n",
      "Epoch [7/15], Step [56/114], Loss: 0.1410\n",
      "Epoch [7/15], Step [70/114], Loss: 0.0469\n",
      "Epoch [7/15], Step [84/114], Loss: 0.0073\n",
      "Epoch [7/15], Step [98/114], Loss: 0.5179\n",
      "Epoch [7/15], Step [112/114], Loss: 0.0618\n",
      "Validation phase -  Epoch 7 Loss: 0.0930 Acc: 0.9784\n",
      "----------\n",
      "Epoch 8/15\n",
      "----------\n",
      "Epoch [8/15], Step [56/454], Loss: 0.0066\n",
      "Epoch [8/15], Step [112/454], Loss: 0.0011\n",
      "Epoch [8/15], Step [168/454], Loss: 0.0054\n",
      "Epoch [8/15], Step [224/454], Loss: 0.0045\n",
      "Epoch [8/15], Step [280/454], Loss: 0.0045\n",
      "Epoch [8/15], Step [336/454], Loss: 0.0104\n",
      "Epoch [8/15], Step [392/454], Loss: 0.0039\n",
      "Epoch [8/15], Step [448/454], Loss: 0.0229\n",
      "Train phase -  Epoch 8 Loss: 0.0284 Acc: 0.9927\n",
      "Epoch [8/15], Step [14/114], Loss: 0.1570\n",
      "Epoch [8/15], Step [28/114], Loss: 0.1402\n",
      "Epoch [8/15], Step [42/114], Loss: 0.2082\n",
      "Epoch [8/15], Step [56/114], Loss: 0.0330\n",
      "Epoch [8/15], Step [70/114], Loss: 0.0844\n",
      "Epoch [8/15], Step [84/114], Loss: 0.5280\n",
      "Epoch [8/15], Step [98/114], Loss: 0.1359\n",
      "Epoch [8/15], Step [112/114], Loss: 0.0878\n",
      "Validation phase -  Epoch 8 Loss: 0.1316 Acc: 0.9683\n",
      "----------\n",
      "Epoch 9/15\n",
      "----------\n",
      "Epoch [9/15], Step [56/454], Loss: 0.0102\n",
      "Epoch [9/15], Step [112/454], Loss: 0.0310\n",
      "Epoch [9/15], Step [168/454], Loss: 0.0136\n",
      "Epoch [9/15], Step [224/454], Loss: 0.0089\n",
      "Epoch [9/15], Step [280/454], Loss: 0.0012\n",
      "Epoch [9/15], Step [336/454], Loss: 0.0024\n",
      "Epoch [9/15], Step [392/454], Loss: 0.0303\n",
      "Epoch [9/15], Step [448/454], Loss: 0.0089\n",
      "Train phase -  Epoch 9 Loss: 0.0128 Acc: 0.9969\n",
      "Epoch [9/15], Step [14/114], Loss: 0.0010\n",
      "Epoch [9/15], Step [28/114], Loss: 0.4195\n",
      "Epoch [9/15], Step [42/114], Loss: 0.0363\n",
      "Epoch [9/15], Step [56/114], Loss: 0.0097\n",
      "Epoch [9/15], Step [70/114], Loss: 0.0013\n",
      "Epoch [9/15], Step [84/114], Loss: 0.0180\n",
      "Epoch [9/15], Step [98/114], Loss: 0.0012\n",
      "Epoch [9/15], Step [112/114], Loss: 0.0515\n",
      "Validation phase -  Epoch 9 Loss: 0.0596 Acc: 0.9924\n",
      "----------\n",
      "Epoch 10/15\n",
      "----------\n",
      "Epoch [10/15], Step [56/454], Loss: 0.0016\n",
      "Epoch [10/15], Step [112/454], Loss: 0.0290\n",
      "Epoch [10/15], Step [168/454], Loss: 0.0123\n",
      "Epoch [10/15], Step [224/454], Loss: 0.0029\n",
      "Epoch [10/15], Step [280/454], Loss: 0.0041\n",
      "Epoch [10/15], Step [336/454], Loss: 0.0017\n",
      "Epoch [10/15], Step [392/454], Loss: 0.0005\n",
      "Epoch [10/15], Step [448/454], Loss: 0.0104\n",
      "Train phase -  Epoch 10 Loss: 0.0077 Acc: 0.9983\n",
      "Epoch [10/15], Step [14/114], Loss: 0.0027\n",
      "Epoch [10/15], Step [28/114], Loss: 0.0061\n",
      "Epoch [10/15], Step [42/114], Loss: 0.1610\n",
      "Epoch [10/15], Step [56/114], Loss: 0.0200\n",
      "Epoch [10/15], Step [70/114], Loss: 0.0503\n",
      "Epoch [10/15], Step [84/114], Loss: 0.0008\n",
      "Epoch [10/15], Step [98/114], Loss: 0.0021\n",
      "Epoch [10/15], Step [112/114], Loss: 0.0154\n",
      "Validation phase -  Epoch 10 Loss: 0.0685 Acc: 0.9890\n",
      "----------\n",
      "Epoch 11/15\n",
      "----------\n",
      "Epoch [11/15], Step [56/454], Loss: 0.0108\n",
      "Epoch [11/15], Step [112/454], Loss: 0.0028\n",
      "Epoch [11/15], Step [168/454], Loss: 0.0004\n",
      "Epoch [11/15], Step [224/454], Loss: 0.0033\n",
      "Epoch [11/15], Step [280/454], Loss: 0.0118\n",
      "Epoch [11/15], Step [336/454], Loss: 0.0197\n",
      "Epoch [11/15], Step [392/454], Loss: 0.0086\n",
      "Epoch [11/15], Step [448/454], Loss: 0.0231\n",
      "Train phase -  Epoch 11 Loss: 0.0195 Acc: 0.9953\n",
      "Epoch [11/15], Step [14/114], Loss: 0.0403\n",
      "Epoch [11/15], Step [28/114], Loss: 0.0029\n",
      "Epoch [11/15], Step [42/114], Loss: 0.3050\n",
      "Epoch [11/15], Step [56/114], Loss: 0.0152\n",
      "Epoch [11/15], Step [70/114], Loss: 0.1774\n",
      "Epoch [11/15], Step [84/114], Loss: 0.0088\n",
      "Epoch [11/15], Step [98/114], Loss: 0.0110\n",
      "Epoch [11/15], Step [112/114], Loss: 0.0155\n",
      "Validation phase -  Epoch 11 Loss: 0.0583 Acc: 0.9908\n",
      "----------\n",
      "Epoch 12/15\n",
      "----------\n",
      "Epoch [12/15], Step [56/454], Loss: 0.0051\n",
      "Epoch [12/15], Step [112/454], Loss: 0.0034\n",
      "Epoch [12/15], Step [168/454], Loss: 0.0028\n",
      "Epoch [12/15], Step [224/454], Loss: 0.0052\n",
      "Epoch [12/15], Step [280/454], Loss: 0.0027\n",
      "Epoch [12/15], Step [336/454], Loss: 0.0037\n",
      "Epoch [12/15], Step [392/454], Loss: 0.0119\n",
      "Epoch [12/15], Step [448/454], Loss: 0.0095\n",
      "Train phase -  Epoch 12 Loss: 0.0077 Acc: 0.9979\n",
      "Epoch [12/15], Step [14/114], Loss: 0.0198\n",
      "Epoch [12/15], Step [28/114], Loss: 0.0127\n",
      "Epoch [12/15], Step [42/114], Loss: 0.1363\n",
      "Epoch [12/15], Step [56/114], Loss: 0.0256\n",
      "Epoch [12/15], Step [70/114], Loss: 0.0005\n",
      "Epoch [12/15], Step [84/114], Loss: 0.0420\n",
      "Epoch [12/15], Step [98/114], Loss: 0.0092\n",
      "Epoch [12/15], Step [112/114], Loss: 0.0149\n",
      "Validation phase -  Epoch 12 Loss: 0.0490 Acc: 0.9941\n",
      "----------\n",
      "Epoch 13/15\n",
      "----------\n",
      "Epoch [13/15], Step [56/454], Loss: 0.0012\n",
      "Epoch [13/15], Step [112/454], Loss: 0.0068\n",
      "Epoch [13/15], Step [168/454], Loss: 0.0010\n",
      "Epoch [13/15], Step [224/454], Loss: 0.0003\n",
      "Epoch [13/15], Step [280/454], Loss: 0.0008\n",
      "Epoch [13/15], Step [336/454], Loss: 0.0001\n",
      "Epoch [13/15], Step [392/454], Loss: 0.0005\n",
      "Epoch [13/15], Step [448/454], Loss: 0.0005\n",
      "Train phase -  Epoch 13 Loss: 0.0040 Acc: 0.9990\n",
      "Epoch [13/15], Step [14/114], Loss: 0.0050\n",
      "Epoch [13/15], Step [28/114], Loss: 0.3407\n",
      "Epoch [13/15], Step [42/114], Loss: 0.0017\n",
      "Epoch [13/15], Step [56/114], Loss: 0.2893\n",
      "Epoch [13/15], Step [70/114], Loss: 0.0428\n",
      "Epoch [13/15], Step [84/114], Loss: 0.0136\n",
      "Epoch [13/15], Step [98/114], Loss: 0.0003\n",
      "Epoch [13/15], Step [112/114], Loss: 0.0013\n",
      "Validation phase -  Epoch 13 Loss: 0.0460 Acc: 0.9938\n",
      "----------\n",
      "Epoch 14/15\n",
      "----------\n",
      "Epoch [14/15], Step [56/454], Loss: 0.0010\n",
      "Epoch [14/15], Step [112/454], Loss: 0.0005\n",
      "Epoch [14/15], Step [168/454], Loss: 0.0023\n",
      "Epoch [14/15], Step [224/454], Loss: 0.0024\n",
      "Epoch [14/15], Step [280/454], Loss: 0.0009\n",
      "Epoch [14/15], Step [336/454], Loss: 0.0643\n",
      "Epoch [14/15], Step [392/454], Loss: 0.0573\n",
      "Epoch [14/15], Step [448/454], Loss: 0.0213\n",
      "Train phase -  Epoch 14 Loss: 0.0116 Acc: 0.9968\n",
      "Epoch [14/15], Step [14/114], Loss: 0.0253\n",
      "Epoch [14/15], Step [28/114], Loss: 0.0830\n",
      "Epoch [14/15], Step [42/114], Loss: 0.0896\n",
      "Epoch [14/15], Step [56/114], Loss: 0.2303\n",
      "Epoch [14/15], Step [70/114], Loss: 0.0519\n",
      "Epoch [14/15], Step [84/114], Loss: 0.0027\n",
      "Epoch [14/15], Step [98/114], Loss: 0.0133\n",
      "Epoch [14/15], Step [112/114], Loss: 0.0051\n",
      "Validation phase -  Epoch 14 Loss: 0.0787 Acc: 0.9883\n",
      "----------\n",
      "Epoch 15/15\n",
      "----------\n",
      "Epoch [15/15], Step [56/454], Loss: 0.0012\n",
      "Epoch [15/15], Step [112/454], Loss: 0.0045\n",
      "Epoch [15/15], Step [168/454], Loss: 0.0013\n",
      "Epoch [15/15], Step [224/454], Loss: 0.0040\n",
      "Epoch [15/15], Step [280/454], Loss: 0.0541\n",
      "Epoch [15/15], Step [336/454], Loss: 0.0010\n",
      "Epoch [15/15], Step [392/454], Loss: 0.0006\n",
      "Epoch [15/15], Step [448/454], Loss: 0.0010\n",
      "Train phase -  Epoch 15 Loss: 0.0113 Acc: 0.9970\n",
      "Epoch [15/15], Step [14/114], Loss: 0.0033\n",
      "Epoch [15/15], Step [28/114], Loss: 0.0006\n",
      "Epoch [15/15], Step [42/114], Loss: 0.2169\n",
      "Epoch [15/15], Step [56/114], Loss: 0.0033\n",
      "Epoch [15/15], Step [70/114], Loss: 0.0302\n",
      "Epoch [15/15], Step [84/114], Loss: 0.0008\n",
      "Epoch [15/15], Step [98/114], Loss: 0.0104\n",
      "Epoch [15/15], Step [112/114], Loss: 0.0006\n",
      "Validation phase -  Epoch 15 Loss: 0.0394 Acc: 0.9937\n",
      "Training complete in 15m 5s\n",
      "Best val Acc:0.9941\n",
      "Test phase -  Model accuracy: 0.9953\n",
      "Finished Training no-loss-weight_P_CNN_ST_adam\n",
      "----------\n",
      "Epoch 1/15\n",
      "----------\n",
      "Epoch [1/15], Step [56/454], Loss: 3.7287\n",
      "Epoch [1/15], Step [112/454], Loss: 3.6667\n",
      "Epoch [1/15], Step [168/454], Loss: 3.4967\n",
      "Epoch [1/15], Step [224/454], Loss: 3.4351\n",
      "Epoch [1/15], Step [280/454], Loss: 3.4721\n",
      "Epoch [1/15], Step [336/454], Loss: 3.3807\n",
      "Epoch [1/15], Step [392/454], Loss: 3.2261\n",
      "Epoch [1/15], Step [448/454], Loss: 3.3965\n",
      "Train phase -  Epoch 1 Loss: 3.5369 Acc: 0.0723\n",
      "Epoch [1/15], Step [14/114], Loss: 3.3773\n",
      "Epoch [1/15], Step [28/114], Loss: 3.4304\n",
      "Epoch [1/15], Step [42/114], Loss: 3.3850\n",
      "Epoch [1/15], Step [56/114], Loss: 3.4213\n",
      "Epoch [1/15], Step [70/114], Loss: 3.4730\n",
      "Epoch [1/15], Step [84/114], Loss: 3.4726\n",
      "Epoch [1/15], Step [98/114], Loss: 3.4869\n",
      "Epoch [1/15], Step [112/114], Loss: 3.4411\n",
      "Validation phase -  Epoch 1 Loss: 3.4323 Acc: 0.0803\n",
      "----------\n",
      "Epoch 2/15\n",
      "----------\n",
      "Epoch [2/15], Step [56/454], Loss: 3.4930\n",
      "Epoch [2/15], Step [112/454], Loss: 3.3207\n",
      "Epoch [2/15], Step [168/454], Loss: 3.4390\n",
      "Epoch [2/15], Step [224/454], Loss: 3.2645\n",
      "Epoch [2/15], Step [280/454], Loss: 3.3359\n",
      "Epoch [2/15], Step [336/454], Loss: 3.3433\n",
      "Epoch [2/15], Step [392/454], Loss: 3.2555\n",
      "Epoch [2/15], Step [448/454], Loss: 3.3709\n",
      "Train phase -  Epoch 2 Loss: 3.3438 Acc: 0.1233\n",
      "Epoch [2/15], Step [14/114], Loss: 3.3739\n",
      "Epoch [2/15], Step [28/114], Loss: 3.2065\n",
      "Epoch [2/15], Step [42/114], Loss: 3.3511\n",
      "Epoch [2/15], Step [56/114], Loss: 3.2433\n",
      "Epoch [2/15], Step [70/114], Loss: 3.2779\n",
      "Epoch [2/15], Step [84/114], Loss: 3.3062\n",
      "Epoch [2/15], Step [98/114], Loss: 3.2902\n",
      "Epoch [2/15], Step [112/114], Loss: 3.2876\n",
      "Validation phase -  Epoch 2 Loss: 3.2563 Acc: 0.1633\n",
      "----------\n",
      "Epoch 3/15\n",
      "----------\n",
      "Epoch [3/15], Step [56/454], Loss: 3.0623\n",
      "Epoch [3/15], Step [112/454], Loss: 3.2828\n",
      "Epoch [3/15], Step [168/454], Loss: 3.1137\n",
      "Epoch [3/15], Step [224/454], Loss: 2.8741\n",
      "Epoch [3/15], Step [280/454], Loss: 2.7935\n",
      "Epoch [3/15], Step [336/454], Loss: 3.0752\n",
      "Epoch [3/15], Step [392/454], Loss: 2.8761\n",
      "Epoch [3/15], Step [448/454], Loss: 2.5657\n",
      "Train phase -  Epoch 3 Loss: 3.0132 Acc: 0.2149\n",
      "Epoch [3/15], Step [14/114], Loss: 2.6619\n",
      "Epoch [3/15], Step [28/114], Loss: 2.7710\n",
      "Epoch [3/15], Step [42/114], Loss: 2.9008\n",
      "Epoch [3/15], Step [56/114], Loss: 2.9683\n",
      "Epoch [3/15], Step [70/114], Loss: 2.7749\n",
      "Epoch [3/15], Step [84/114], Loss: 2.9721\n",
      "Epoch [3/15], Step [98/114], Loss: 2.6847\n",
      "Epoch [3/15], Step [112/114], Loss: 2.9298\n",
      "Validation phase -  Epoch 3 Loss: 2.8388 Acc: 0.2324\n",
      "----------\n",
      "Epoch 4/15\n",
      "----------\n",
      "Epoch [4/15], Step [56/454], Loss: 2.7141\n",
      "Epoch [4/15], Step [112/454], Loss: 2.4987\n",
      "Epoch [4/15], Step [168/454], Loss: 2.5521\n",
      "Epoch [4/15], Step [224/454], Loss: 2.5728\n",
      "Epoch [4/15], Step [280/454], Loss: 2.4489\n",
      "Epoch [4/15], Step [336/454], Loss: 2.7385\n",
      "Epoch [4/15], Step [392/454], Loss: 2.2808\n",
      "Epoch [4/15], Step [448/454], Loss: 2.3105\n",
      "Train phase -  Epoch 4 Loss: 2.5283 Acc: 0.3214\n",
      "Epoch [4/15], Step [14/114], Loss: 2.2515\n",
      "Epoch [4/15], Step [28/114], Loss: 2.3863\n",
      "Epoch [4/15], Step [42/114], Loss: 2.1370\n",
      "Epoch [4/15], Step [56/114], Loss: 2.2435\n",
      "Epoch [4/15], Step [70/114], Loss: 2.4027\n",
      "Epoch [4/15], Step [84/114], Loss: 2.2026\n",
      "Epoch [4/15], Step [98/114], Loss: 2.4782\n",
      "Epoch [4/15], Step [112/114], Loss: 2.5580\n",
      "Validation phase -  Epoch 4 Loss: 2.3486 Acc: 0.3509\n",
      "----------\n",
      "Epoch 5/15\n",
      "----------\n",
      "Epoch [5/15], Step [56/454], Loss: 2.3206\n",
      "Epoch [5/15], Step [112/454], Loss: 2.2015\n",
      "Epoch [5/15], Step [168/454], Loss: 1.9441\n",
      "Epoch [5/15], Step [224/454], Loss: 1.7936\n",
      "Epoch [5/15], Step [280/454], Loss: 2.2033\n",
      "Epoch [5/15], Step [336/454], Loss: 2.3105\n",
      "Epoch [5/15], Step [392/454], Loss: 1.9278\n",
      "Epoch [5/15], Step [448/454], Loss: 2.0701\n",
      "Train phase -  Epoch 5 Loss: 2.0881 Acc: 0.4214\n",
      "Epoch [5/15], Step [14/114], Loss: 1.6723\n",
      "Epoch [5/15], Step [28/114], Loss: 2.0129\n",
      "Epoch [5/15], Step [42/114], Loss: 1.8995\n",
      "Epoch [5/15], Step [56/114], Loss: 1.8185\n",
      "Epoch [5/15], Step [70/114], Loss: 1.8685\n",
      "Epoch [5/15], Step [84/114], Loss: 2.0837\n",
      "Epoch [5/15], Step [98/114], Loss: 1.9422\n",
      "Epoch [5/15], Step [112/114], Loss: 1.9128\n",
      "Validation phase -  Epoch 5 Loss: 1.9282 Acc: 0.4464\n",
      "----------\n",
      "Epoch 6/15\n",
      "----------\n",
      "Epoch [6/15], Step [56/454], Loss: 1.7317\n",
      "Epoch [6/15], Step [112/454], Loss: 1.5837\n",
      "Epoch [6/15], Step [168/454], Loss: 1.9252\n",
      "Epoch [6/15], Step [224/454], Loss: 1.6844\n",
      "Epoch [6/15], Step [280/454], Loss: 1.8136\n",
      "Epoch [6/15], Step [336/454], Loss: 1.4901\n",
      "Epoch [6/15], Step [392/454], Loss: 1.9554\n",
      "Epoch [6/15], Step [448/454], Loss: 1.4930\n",
      "Train phase -  Epoch 6 Loss: 1.7581 Acc: 0.5011\n",
      "Epoch [6/15], Step [14/114], Loss: 1.7673\n",
      "Epoch [6/15], Step [28/114], Loss: 1.6510\n",
      "Epoch [6/15], Step [42/114], Loss: 2.0624\n",
      "Epoch [6/15], Step [56/114], Loss: 1.6964\n",
      "Epoch [6/15], Step [70/114], Loss: 1.5904\n",
      "Epoch [6/15], Step [84/114], Loss: 1.7712\n",
      "Epoch [6/15], Step [98/114], Loss: 1.6209\n",
      "Epoch [6/15], Step [112/114], Loss: 1.8304\n",
      "Validation phase -  Epoch 6 Loss: 1.7921 Acc: 0.4866\n",
      "----------\n",
      "Epoch 7/15\n",
      "----------\n",
      "Epoch [7/15], Step [56/454], Loss: 1.8463\n",
      "Epoch [7/15], Step [112/454], Loss: 1.6964\n",
      "Epoch [7/15], Step [168/454], Loss: 1.6845\n",
      "Epoch [7/15], Step [224/454], Loss: 1.4678\n",
      "Epoch [7/15], Step [280/454], Loss: 1.4931\n",
      "Epoch [7/15], Step [336/454], Loss: 1.7363\n",
      "Epoch [7/15], Step [392/454], Loss: 1.2560\n",
      "Epoch [7/15], Step [448/454], Loss: 1.5225\n",
      "Train phase -  Epoch 7 Loss: 1.5320 Acc: 0.5629\n",
      "Epoch [7/15], Step [14/114], Loss: 1.4777\n",
      "Epoch [7/15], Step [28/114], Loss: 1.2796\n",
      "Epoch [7/15], Step [42/114], Loss: 1.3198\n",
      "Epoch [7/15], Step [56/114], Loss: 1.3718\n",
      "Epoch [7/15], Step [70/114], Loss: 1.6477\n",
      "Epoch [7/15], Step [84/114], Loss: 1.3766\n",
      "Epoch [7/15], Step [98/114], Loss: 1.8948\n",
      "Epoch [7/15], Step [112/114], Loss: 1.4437\n",
      "Validation phase -  Epoch 7 Loss: 1.6156 Acc: 0.5288\n",
      "----------\n",
      "Epoch 8/15\n",
      "----------\n",
      "Epoch [8/15], Step [56/454], Loss: 1.5051\n",
      "Epoch [8/15], Step [112/454], Loss: 1.2247\n",
      "Epoch [8/15], Step [168/454], Loss: 1.2610\n",
      "Epoch [8/15], Step [224/454], Loss: 1.3254\n",
      "Epoch [8/15], Step [280/454], Loss: 1.0712\n",
      "Epoch [8/15], Step [336/454], Loss: 1.2538\n",
      "Epoch [8/15], Step [392/454], Loss: 1.1290\n",
      "Epoch [8/15], Step [448/454], Loss: 1.6118\n",
      "Train phase -  Epoch 8 Loss: 1.3634 Acc: 0.6092\n",
      "Epoch [8/15], Step [14/114], Loss: 1.4475\n",
      "Epoch [8/15], Step [28/114], Loss: 1.2289\n",
      "Epoch [8/15], Step [42/114], Loss: 1.2608\n",
      "Epoch [8/15], Step [56/114], Loss: 1.1947\n",
      "Epoch [8/15], Step [70/114], Loss: 1.3865\n",
      "Epoch [8/15], Step [84/114], Loss: 1.4484\n",
      "Epoch [8/15], Step [98/114], Loss: 1.5822\n",
      "Epoch [8/15], Step [112/114], Loss: 1.8682\n",
      "Validation phase -  Epoch 8 Loss: 1.3621 Acc: 0.6094\n",
      "----------\n",
      "Epoch 9/15\n",
      "----------\n",
      "Epoch [9/15], Step [56/454], Loss: 1.2181\n",
      "Epoch [9/15], Step [112/454], Loss: 1.3479\n",
      "Epoch [9/15], Step [168/454], Loss: 0.9283\n",
      "Epoch [9/15], Step [224/454], Loss: 1.1459\n",
      "Epoch [9/15], Step [280/454], Loss: 1.0060\n",
      "Epoch [9/15], Step [336/454], Loss: 1.2862\n",
      "Epoch [9/15], Step [392/454], Loss: 1.2386\n",
      "Epoch [9/15], Step [448/454], Loss: 1.4016\n",
      "Train phase -  Epoch 9 Loss: 1.2346 Acc: 0.6501\n",
      "Epoch [9/15], Step [14/114], Loss: 1.0951\n",
      "Epoch [9/15], Step [28/114], Loss: 1.5036\n",
      "Epoch [9/15], Step [42/114], Loss: 1.0907\n",
      "Epoch [9/15], Step [56/114], Loss: 1.2316\n",
      "Epoch [9/15], Step [70/114], Loss: 1.4269\n",
      "Epoch [9/15], Step [84/114], Loss: 1.1579\n",
      "Epoch [9/15], Step [98/114], Loss: 1.3861\n",
      "Epoch [9/15], Step [112/114], Loss: 1.2888\n",
      "Validation phase -  Epoch 9 Loss: 1.2722 Acc: 0.6233\n",
      "----------\n",
      "Epoch 10/15\n",
      "----------\n",
      "Epoch [10/15], Step [56/454], Loss: 1.1870\n",
      "Epoch [10/15], Step [112/454], Loss: 1.3541\n",
      "Epoch [10/15], Step [168/454], Loss: 1.3433\n",
      "Epoch [10/15], Step [224/454], Loss: 1.5738\n",
      "Epoch [10/15], Step [280/454], Loss: 0.9747\n",
      "Epoch [10/15], Step [336/454], Loss: 1.3331\n",
      "Epoch [10/15], Step [392/454], Loss: 1.1885\n",
      "Epoch [10/15], Step [448/454], Loss: 0.8768\n",
      "Train phase -  Epoch 10 Loss: 1.1278 Acc: 0.6807\n",
      "Epoch [10/15], Step [14/114], Loss: 1.1571\n",
      "Epoch [10/15], Step [28/114], Loss: 1.1272\n",
      "Epoch [10/15], Step [42/114], Loss: 1.2707\n",
      "Epoch [10/15], Step [56/114], Loss: 0.9163\n",
      "Epoch [10/15], Step [70/114], Loss: 0.8479\n",
      "Epoch [10/15], Step [84/114], Loss: 1.2207\n",
      "Epoch [10/15], Step [98/114], Loss: 1.0304\n",
      "Epoch [10/15], Step [112/114], Loss: 0.8648\n",
      "Validation phase -  Epoch 10 Loss: 1.2043 Acc: 0.6466\n",
      "----------\n",
      "Epoch 11/15\n",
      "----------\n",
      "Epoch [11/15], Step [56/454], Loss: 0.8308\n",
      "Epoch [11/15], Step [112/454], Loss: 0.9272\n",
      "Epoch [11/15], Step [168/454], Loss: 1.0132\n",
      "Epoch [11/15], Step [224/454], Loss: 0.9826\n",
      "Epoch [11/15], Step [280/454], Loss: 1.0563\n",
      "Epoch [11/15], Step [336/454], Loss: 1.1659\n",
      "Epoch [11/15], Step [392/454], Loss: 0.9936\n",
      "Epoch [11/15], Step [448/454], Loss: 0.8289\n",
      "Train phase -  Epoch 11 Loss: 1.0437 Acc: 0.7069\n",
      "Epoch [11/15], Step [14/114], Loss: 0.8598\n",
      "Epoch [11/15], Step [28/114], Loss: 0.9438\n",
      "Epoch [11/15], Step [42/114], Loss: 0.8587\n",
      "Epoch [11/15], Step [56/114], Loss: 1.1687\n",
      "Epoch [11/15], Step [70/114], Loss: 0.9097\n",
      "Epoch [11/15], Step [84/114], Loss: 1.1317\n",
      "Epoch [11/15], Step [98/114], Loss: 1.3836\n",
      "Epoch [11/15], Step [112/114], Loss: 1.0512\n",
      "Validation phase -  Epoch 11 Loss: 1.0980 Acc: 0.6872\n",
      "----------\n",
      "Epoch 12/15\n",
      "----------\n",
      "Epoch [12/15], Step [56/454], Loss: 0.9992\n",
      "Epoch [12/15], Step [112/454], Loss: 1.0242\n",
      "Epoch [12/15], Step [168/454], Loss: 0.9593\n",
      "Epoch [12/15], Step [224/454], Loss: 1.2233\n",
      "Epoch [12/15], Step [280/454], Loss: 0.8396\n",
      "Epoch [12/15], Step [336/454], Loss: 0.9867\n",
      "Epoch [12/15], Step [392/454], Loss: 0.8466\n",
      "Epoch [12/15], Step [448/454], Loss: 1.1913\n",
      "Train phase -  Epoch 12 Loss: 0.9722 Acc: 0.7308\n",
      "Epoch [12/15], Step [14/114], Loss: 1.1437\n",
      "Epoch [12/15], Step [28/114], Loss: 0.9492\n",
      "Epoch [12/15], Step [42/114], Loss: 1.0929\n",
      "Epoch [12/15], Step [56/114], Loss: 0.9788\n",
      "Epoch [12/15], Step [70/114], Loss: 0.8910\n",
      "Epoch [12/15], Step [84/114], Loss: 1.0220\n",
      "Epoch [12/15], Step [98/114], Loss: 0.8908\n",
      "Epoch [12/15], Step [112/114], Loss: 1.1666\n",
      "Validation phase -  Epoch 12 Loss: 1.0161 Acc: 0.7131\n",
      "----------\n",
      "Epoch 13/15\n",
      "----------\n",
      "Epoch [13/15], Step [56/454], Loss: 0.8705\n",
      "Epoch [13/15], Step [112/454], Loss: 1.0941\n",
      "Epoch [13/15], Step [168/454], Loss: 0.8603\n",
      "Epoch [13/15], Step [224/454], Loss: 1.2197\n",
      "Epoch [13/15], Step [280/454], Loss: 1.1495\n",
      "Epoch [13/15], Step [336/454], Loss: 1.0347\n",
      "Epoch [13/15], Step [392/454], Loss: 0.9433\n",
      "Epoch [13/15], Step [448/454], Loss: 1.1191\n",
      "Train phase -  Epoch 13 Loss: 0.9093 Acc: 0.7478\n",
      "Epoch [13/15], Step [14/114], Loss: 1.2484\n",
      "Epoch [13/15], Step [28/114], Loss: 1.0539\n",
      "Epoch [13/15], Step [42/114], Loss: 1.0514\n",
      "Epoch [13/15], Step [56/114], Loss: 0.9280\n",
      "Epoch [13/15], Step [70/114], Loss: 0.9475\n",
      "Epoch [13/15], Step [84/114], Loss: 0.7140\n",
      "Epoch [13/15], Step [98/114], Loss: 1.2991\n",
      "Epoch [13/15], Step [112/114], Loss: 1.0296\n",
      "Validation phase -  Epoch 13 Loss: 1.0234 Acc: 0.7061\n",
      "----------\n",
      "Epoch 14/15\n",
      "----------\n",
      "Epoch [14/15], Step [56/454], Loss: 0.7185\n",
      "Epoch [14/15], Step [112/454], Loss: 0.7891\n",
      "Epoch [14/15], Step [168/454], Loss: 1.0098\n",
      "Epoch [14/15], Step [224/454], Loss: 0.7561\n",
      "Epoch [14/15], Step [280/454], Loss: 0.6267\n",
      "Epoch [14/15], Step [336/454], Loss: 1.1125\n",
      "Epoch [14/15], Step [392/454], Loss: 0.7413\n",
      "Epoch [14/15], Step [448/454], Loss: 0.8857\n",
      "Train phase -  Epoch 14 Loss: 0.8586 Acc: 0.7632\n",
      "Epoch [14/15], Step [14/114], Loss: 1.0454\n",
      "Epoch [14/15], Step [28/114], Loss: 0.9634\n",
      "Epoch [14/15], Step [42/114], Loss: 0.6040\n",
      "Epoch [14/15], Step [56/114], Loss: 1.0188\n",
      "Epoch [14/15], Step [70/114], Loss: 0.9607\n",
      "Epoch [14/15], Step [84/114], Loss: 0.8263\n",
      "Epoch [14/15], Step [98/114], Loss: 1.0915\n",
      "Epoch [14/15], Step [112/114], Loss: 1.2160\n",
      "Validation phase -  Epoch 14 Loss: 0.9801 Acc: 0.7272\n",
      "----------\n",
      "Epoch 15/15\n",
      "----------\n",
      "Epoch [15/15], Step [56/454], Loss: 0.9019\n",
      "Epoch [15/15], Step [112/454], Loss: 0.8633\n",
      "Epoch [15/15], Step [168/454], Loss: 0.9489\n",
      "Epoch [15/15], Step [224/454], Loss: 0.8954\n",
      "Epoch [15/15], Step [280/454], Loss: 0.7232\n",
      "Epoch [15/15], Step [336/454], Loss: 0.6291\n",
      "Epoch [15/15], Step [392/454], Loss: 0.7317\n",
      "Epoch [15/15], Step [448/454], Loss: 0.8076\n",
      "Train phase -  Epoch 15 Loss: 0.8139 Acc: 0.7752\n",
      "Epoch [15/15], Step [14/114], Loss: 0.7576\n",
      "Epoch [15/15], Step [28/114], Loss: 0.8309\n",
      "Epoch [15/15], Step [42/114], Loss: 0.6896\n",
      "Epoch [15/15], Step [56/114], Loss: 1.1551\n",
      "Epoch [15/15], Step [70/114], Loss: 0.8222\n",
      "Epoch [15/15], Step [84/114], Loss: 1.0833\n",
      "Epoch [15/15], Step [98/114], Loss: 0.7814\n",
      "Epoch [15/15], Step [112/114], Loss: 0.7758\n",
      "Validation phase -  Epoch 15 Loss: 0.8799 Acc: 0.7564\n",
      "Training complete in 10m 30s\n",
      "Best val Acc:0.7564\n",
      "Test phase -  Model accuracy: 0.7551\n",
      "Finished Training no-loss-weight_W_CNN_sgd\n",
      "----------\n",
      "Epoch 1/15\n",
      "----------\n",
      "Epoch [1/15], Step [56/454], Loss: 3.3927\n",
      "Epoch [1/15], Step [112/454], Loss: 2.9775\n",
      "Epoch [1/15], Step [168/454], Loss: 2.5479\n",
      "Epoch [1/15], Step [224/454], Loss: 2.5594\n",
      "Epoch [1/15], Step [280/454], Loss: 2.1653\n",
      "Epoch [1/15], Step [336/454], Loss: 1.8030\n",
      "Epoch [1/15], Step [392/454], Loss: 1.6038\n",
      "Epoch [1/15], Step [448/454], Loss: 1.7731\n",
      "Train phase -  Epoch 1 Loss: 2.5269 Acc: 0.3192\n",
      "Epoch [1/15], Step [14/114], Loss: 1.6644\n",
      "Epoch [1/15], Step [28/114], Loss: 1.6401\n",
      "Epoch [1/15], Step [42/114], Loss: 1.6164\n",
      "Epoch [1/15], Step [56/114], Loss: 1.8153\n",
      "Epoch [1/15], Step [70/114], Loss: 1.5354\n",
      "Epoch [1/15], Step [84/114], Loss: 1.6433\n",
      "Epoch [1/15], Step [98/114], Loss: 1.8312\n",
      "Epoch [1/15], Step [112/114], Loss: 1.6187\n",
      "Validation phase -  Epoch 1 Loss: 1.7045 Acc: 0.5226\n",
      "----------\n",
      "Epoch 2/15\n",
      "----------\n",
      "Epoch [2/15], Step [56/454], Loss: 1.3312\n",
      "Epoch [2/15], Step [112/454], Loss: 1.5799\n",
      "Epoch [2/15], Step [168/454], Loss: 1.3675\n",
      "Epoch [2/15], Step [224/454], Loss: 1.2077\n",
      "Epoch [2/15], Step [280/454], Loss: 1.5317\n",
      "Epoch [2/15], Step [336/454], Loss: 1.2631\n",
      "Epoch [2/15], Step [392/454], Loss: 1.2897\n",
      "Epoch [2/15], Step [448/454], Loss: 0.9295\n",
      "Train phase -  Epoch 2 Loss: 1.3324 Acc: 0.6266\n",
      "Epoch [2/15], Step [14/114], Loss: 1.1391\n",
      "Epoch [2/15], Step [28/114], Loss: 1.1072\n",
      "Epoch [2/15], Step [42/114], Loss: 1.0488\n",
      "Epoch [2/15], Step [56/114], Loss: 1.0284\n",
      "Epoch [2/15], Step [70/114], Loss: 1.1449\n",
      "Epoch [2/15], Step [84/114], Loss: 1.1020\n",
      "Epoch [2/15], Step [98/114], Loss: 1.2943\n",
      "Epoch [2/15], Step [112/114], Loss: 0.9844\n",
      "Validation phase -  Epoch 2 Loss: 1.1168 Acc: 0.6852\n",
      "----------\n",
      "Epoch 3/15\n",
      "----------\n",
      "Epoch [3/15], Step [56/454], Loss: 1.0114\n",
      "Epoch [3/15], Step [112/454], Loss: 1.1484\n",
      "Epoch [3/15], Step [168/454], Loss: 1.0280\n",
      "Epoch [3/15], Step [224/454], Loss: 0.7489\n",
      "Epoch [3/15], Step [280/454], Loss: 0.5678\n",
      "Epoch [3/15], Step [336/454], Loss: 0.6065\n",
      "Epoch [3/15], Step [392/454], Loss: 0.8679\n",
      "Epoch [3/15], Step [448/454], Loss: 0.7342\n",
      "Train phase -  Epoch 3 Loss: 0.9684 Acc: 0.7318\n",
      "Epoch [3/15], Step [14/114], Loss: 0.8149\n",
      "Epoch [3/15], Step [28/114], Loss: 1.0597\n",
      "Epoch [3/15], Step [42/114], Loss: 0.9328\n",
      "Epoch [3/15], Step [56/114], Loss: 0.9972\n",
      "Epoch [3/15], Step [70/114], Loss: 0.5979\n",
      "Epoch [3/15], Step [84/114], Loss: 1.0106\n",
      "Epoch [3/15], Step [98/114], Loss: 0.7024\n",
      "Epoch [3/15], Step [112/114], Loss: 0.8014\n",
      "Validation phase -  Epoch 3 Loss: 0.9176 Acc: 0.7492\n",
      "----------\n",
      "Epoch 4/15\n",
      "----------\n",
      "Epoch [4/15], Step [56/454], Loss: 0.5216\n",
      "Epoch [4/15], Step [112/454], Loss: 0.6939\n",
      "Epoch [4/15], Step [168/454], Loss: 0.4695\n",
      "Epoch [4/15], Step [224/454], Loss: 0.8959\n",
      "Epoch [4/15], Step [280/454], Loss: 0.9008\n",
      "Epoch [4/15], Step [336/454], Loss: 0.8495\n",
      "Epoch [4/15], Step [392/454], Loss: 0.3368\n",
      "Epoch [4/15], Step [448/454], Loss: 0.9326\n",
      "Train phase -  Epoch 4 Loss: 0.7957 Acc: 0.7809\n",
      "Epoch [4/15], Step [14/114], Loss: 0.5954\n",
      "Epoch [4/15], Step [28/114], Loss: 0.9440\n",
      "Epoch [4/15], Step [42/114], Loss: 0.6171\n",
      "Epoch [4/15], Step [56/114], Loss: 0.7560\n",
      "Epoch [4/15], Step [70/114], Loss: 0.5793\n",
      "Epoch [4/15], Step [84/114], Loss: 0.9093\n",
      "Epoch [4/15], Step [98/114], Loss: 0.9448\n",
      "Epoch [4/15], Step [112/114], Loss: 0.8420\n",
      "Validation phase -  Epoch 4 Loss: 0.7991 Acc: 0.7826\n",
      "----------\n",
      "Epoch 5/15\n",
      "----------\n",
      "Epoch [5/15], Step [56/454], Loss: 0.5860\n",
      "Epoch [5/15], Step [112/454], Loss: 0.6584\n",
      "Epoch [5/15], Step [168/454], Loss: 0.6438\n",
      "Epoch [5/15], Step [224/454], Loss: 0.7706\n",
      "Epoch [5/15], Step [280/454], Loss: 0.7160\n",
      "Epoch [5/15], Step [336/454], Loss: 0.5023\n",
      "Epoch [5/15], Step [392/454], Loss: 0.5364\n",
      "Epoch [5/15], Step [448/454], Loss: 0.6442\n",
      "Train phase -  Epoch 5 Loss: 0.6990 Acc: 0.8079\n",
      "Epoch [5/15], Step [14/114], Loss: 0.7644\n",
      "Epoch [5/15], Step [28/114], Loss: 0.7529\n",
      "Epoch [5/15], Step [42/114], Loss: 0.7567\n",
      "Epoch [5/15], Step [56/114], Loss: 0.5243\n",
      "Epoch [5/15], Step [70/114], Loss: 0.5570\n",
      "Epoch [5/15], Step [84/114], Loss: 0.9968\n",
      "Epoch [5/15], Step [98/114], Loss: 0.8820\n",
      "Epoch [5/15], Step [112/114], Loss: 0.8367\n",
      "Validation phase -  Epoch 5 Loss: 0.7489 Acc: 0.7931\n",
      "----------\n",
      "Epoch 6/15\n",
      "----------\n",
      "Epoch [6/15], Step [56/454], Loss: 0.8388\n",
      "Epoch [6/15], Step [112/454], Loss: 0.6734\n",
      "Epoch [6/15], Step [168/454], Loss: 0.8591\n",
      "Epoch [6/15], Step [224/454], Loss: 0.6267\n",
      "Epoch [6/15], Step [280/454], Loss: 0.4205\n",
      "Epoch [6/15], Step [336/454], Loss: 0.8925\n",
      "Epoch [6/15], Step [392/454], Loss: 0.6264\n",
      "Epoch [6/15], Step [448/454], Loss: 0.4962\n",
      "Train phase -  Epoch 6 Loss: 0.6274 Acc: 0.8312\n",
      "Epoch [6/15], Step [14/114], Loss: 0.5960\n",
      "Epoch [6/15], Step [28/114], Loss: 0.7244\n",
      "Epoch [6/15], Step [42/114], Loss: 0.8961\n",
      "Epoch [6/15], Step [56/114], Loss: 0.8810\n",
      "Epoch [6/15], Step [70/114], Loss: 0.6451\n",
      "Epoch [6/15], Step [84/114], Loss: 0.8048\n",
      "Epoch [6/15], Step [98/114], Loss: 0.7216\n",
      "Epoch [6/15], Step [112/114], Loss: 0.9727\n",
      "Validation phase -  Epoch 6 Loss: 0.6931 Acc: 0.8082\n",
      "----------\n",
      "Epoch 7/15\n",
      "----------\n",
      "Epoch [7/15], Step [56/454], Loss: 0.3199\n",
      "Epoch [7/15], Step [112/454], Loss: 0.3291\n",
      "Epoch [7/15], Step [168/454], Loss: 0.4974\n",
      "Epoch [7/15], Step [224/454], Loss: 0.3819\n",
      "Epoch [7/15], Step [280/454], Loss: 0.6614\n",
      "Epoch [7/15], Step [336/454], Loss: 0.3204\n",
      "Epoch [7/15], Step [392/454], Loss: 0.8134\n",
      "Epoch [7/15], Step [448/454], Loss: 0.4133\n",
      "Train phase -  Epoch 7 Loss: 0.5773 Acc: 0.8437\n",
      "Epoch [7/15], Step [14/114], Loss: 0.4869\n",
      "Epoch [7/15], Step [28/114], Loss: 0.8011\n",
      "Epoch [7/15], Step [42/114], Loss: 0.6751\n",
      "Epoch [7/15], Step [56/114], Loss: 0.4819\n",
      "Epoch [7/15], Step [70/114], Loss: 0.8456\n",
      "Epoch [7/15], Step [84/114], Loss: 0.6767\n",
      "Epoch [7/15], Step [98/114], Loss: 0.5754\n",
      "Epoch [7/15], Step [112/114], Loss: 0.4687\n",
      "Validation phase -  Epoch 7 Loss: 0.6560 Acc: 0.8194\n",
      "----------\n",
      "Epoch 8/15\n",
      "----------\n",
      "Epoch [8/15], Step [56/454], Loss: 0.6491\n",
      "Epoch [8/15], Step [112/454], Loss: 0.4428\n",
      "Epoch [8/15], Step [168/454], Loss: 0.4797\n",
      "Epoch [8/15], Step [224/454], Loss: 0.7326\n",
      "Epoch [8/15], Step [280/454], Loss: 0.6124\n",
      "Epoch [8/15], Step [336/454], Loss: 0.5203\n",
      "Epoch [8/15], Step [392/454], Loss: 0.4121\n",
      "Epoch [8/15], Step [448/454], Loss: 0.5166\n",
      "Train phase -  Epoch 8 Loss: 0.5321 Acc: 0.8552\n",
      "Epoch [8/15], Step [14/114], Loss: 0.5657\n",
      "Epoch [8/15], Step [28/114], Loss: 0.5036\n",
      "Epoch [8/15], Step [42/114], Loss: 0.5254\n",
      "Epoch [8/15], Step [56/114], Loss: 0.7567\n",
      "Epoch [8/15], Step [70/114], Loss: 0.7068\n",
      "Epoch [8/15], Step [84/114], Loss: 0.7110\n",
      "Epoch [8/15], Step [98/114], Loss: 0.6397\n",
      "Epoch [8/15], Step [112/114], Loss: 1.0161\n",
      "Validation phase -  Epoch 8 Loss: 0.6500 Acc: 0.8234\n",
      "----------\n",
      "Epoch 9/15\n",
      "----------\n",
      "Epoch [9/15], Step [56/454], Loss: 0.3456\n",
      "Epoch [9/15], Step [112/454], Loss: 0.5282\n",
      "Epoch [9/15], Step [168/454], Loss: 0.4146\n",
      "Epoch [9/15], Step [224/454], Loss: 0.4991\n",
      "Epoch [9/15], Step [280/454], Loss: 0.4350\n",
      "Epoch [9/15], Step [336/454], Loss: 0.6715\n",
      "Epoch [9/15], Step [392/454], Loss: 0.4592\n",
      "Epoch [9/15], Step [448/454], Loss: 0.4881\n",
      "Train phase -  Epoch 9 Loss: 0.4988 Acc: 0.8654\n",
      "Epoch [9/15], Step [14/114], Loss: 0.6778\n",
      "Epoch [9/15], Step [28/114], Loss: 0.5510\n",
      "Epoch [9/15], Step [42/114], Loss: 0.9793\n",
      "Epoch [9/15], Step [56/114], Loss: 0.6168\n",
      "Epoch [9/15], Step [70/114], Loss: 0.5960\n",
      "Epoch [9/15], Step [84/114], Loss: 0.6171\n",
      "Epoch [9/15], Step [98/114], Loss: 0.7943\n",
      "Epoch [9/15], Step [112/114], Loss: 0.4996\n",
      "Validation phase -  Epoch 9 Loss: 0.6612 Acc: 0.8176\n",
      "----------\n",
      "Epoch 10/15\n",
      "----------\n",
      "Epoch [10/15], Step [56/454], Loss: 0.7424\n",
      "Epoch [10/15], Step [112/454], Loss: 0.7304\n",
      "Epoch [10/15], Step [168/454], Loss: 0.3492\n",
      "Epoch [10/15], Step [224/454], Loss: 0.5843\n",
      "Epoch [10/15], Step [280/454], Loss: 0.3163\n",
      "Epoch [10/15], Step [336/454], Loss: 0.4655\n",
      "Epoch [10/15], Step [392/454], Loss: 0.5360\n",
      "Epoch [10/15], Step [448/454], Loss: 0.4380\n",
      "Train phase -  Epoch 10 Loss: 0.4736 Acc: 0.8730\n",
      "Epoch [10/15], Step [14/114], Loss: 0.7977\n",
      "Epoch [10/15], Step [28/114], Loss: 0.7849\n",
      "Epoch [10/15], Step [42/114], Loss: 0.5969\n",
      "Epoch [10/15], Step [56/114], Loss: 0.9410\n",
      "Epoch [10/15], Step [70/114], Loss: 0.6212\n",
      "Epoch [10/15], Step [84/114], Loss: 0.6301\n",
      "Epoch [10/15], Step [98/114], Loss: 0.3979\n",
      "Epoch [10/15], Step [112/114], Loss: 0.4916\n",
      "Validation phase -  Epoch 10 Loss: 0.6446 Acc: 0.8192\n",
      "----------\n",
      "Epoch 11/15\n",
      "----------\n",
      "Epoch [11/15], Step [56/454], Loss: 0.2216\n",
      "Epoch [11/15], Step [112/454], Loss: 0.2712\n",
      "Epoch [11/15], Step [168/454], Loss: 0.5236\n",
      "Epoch [11/15], Step [224/454], Loss: 0.6544\n",
      "Epoch [11/15], Step [280/454], Loss: 0.4723\n",
      "Epoch [11/15], Step [336/454], Loss: 0.4526\n",
      "Epoch [11/15], Step [392/454], Loss: 0.3881\n",
      "Epoch [11/15], Step [448/454], Loss: 0.2418\n",
      "Train phase -  Epoch 11 Loss: 0.4481 Acc: 0.8801\n",
      "Epoch [11/15], Step [14/114], Loss: 0.5163\n",
      "Epoch [11/15], Step [28/114], Loss: 0.4202\n",
      "Epoch [11/15], Step [42/114], Loss: 0.9976\n",
      "Epoch [11/15], Step [56/114], Loss: 0.5800\n",
      "Epoch [11/15], Step [70/114], Loss: 0.7250\n",
      "Epoch [11/15], Step [84/114], Loss: 0.8731\n",
      "Epoch [11/15], Step [98/114], Loss: 0.7004\n",
      "Epoch [11/15], Step [112/114], Loss: 0.5327\n",
      "Validation phase -  Epoch 11 Loss: 0.6426 Acc: 0.8300\n",
      "----------\n",
      "Epoch 12/15\n",
      "----------\n",
      "Epoch [12/15], Step [56/454], Loss: 0.3402\n",
      "Epoch [12/15], Step [112/454], Loss: 0.4326\n",
      "Epoch [12/15], Step [168/454], Loss: 0.3461\n",
      "Epoch [12/15], Step [224/454], Loss: 0.4084\n",
      "Epoch [12/15], Step [280/454], Loss: 0.1920\n",
      "Epoch [12/15], Step [336/454], Loss: 0.1381\n",
      "Epoch [12/15], Step [392/454], Loss: 0.3990\n",
      "Epoch [12/15], Step [448/454], Loss: 0.6738\n",
      "Train phase -  Epoch 12 Loss: 0.4296 Acc: 0.8856\n",
      "Epoch [12/15], Step [14/114], Loss: 0.7209\n",
      "Epoch [12/15], Step [28/114], Loss: 0.7102\n",
      "Epoch [12/15], Step [42/114], Loss: 0.3572\n",
      "Epoch [12/15], Step [56/114], Loss: 0.5687\n",
      "Epoch [12/15], Step [70/114], Loss: 0.8273\n",
      "Epoch [12/15], Step [84/114], Loss: 0.2433\n",
      "Epoch [12/15], Step [98/114], Loss: 0.7395\n",
      "Epoch [12/15], Step [112/114], Loss: 0.6582\n",
      "Validation phase -  Epoch 12 Loss: 0.6281 Acc: 0.8344\n",
      "----------\n",
      "Epoch 13/15\n",
      "----------\n",
      "Epoch [13/15], Step [56/454], Loss: 0.3346\n",
      "Epoch [13/15], Step [112/454], Loss: 0.1876\n",
      "Epoch [13/15], Step [168/454], Loss: 0.5181\n",
      "Epoch [13/15], Step [224/454], Loss: 0.5646\n",
      "Epoch [13/15], Step [280/454], Loss: 0.8483\n",
      "Epoch [13/15], Step [336/454], Loss: 0.3564\n",
      "Epoch [13/15], Step [392/454], Loss: 0.1659\n",
      "Epoch [13/15], Step [448/454], Loss: 0.3496\n",
      "Train phase -  Epoch 13 Loss: 0.4116 Acc: 0.8914\n",
      "Epoch [13/15], Step [14/114], Loss: 0.6308\n",
      "Epoch [13/15], Step [28/114], Loss: 0.6557\n",
      "Epoch [13/15], Step [42/114], Loss: 0.2668\n",
      "Epoch [13/15], Step [56/114], Loss: 1.0301\n",
      "Epoch [13/15], Step [70/114], Loss: 0.6075\n",
      "Epoch [13/15], Step [84/114], Loss: 0.8600\n",
      "Epoch [13/15], Step [98/114], Loss: 0.4895\n",
      "Epoch [13/15], Step [112/114], Loss: 0.6929\n",
      "Validation phase -  Epoch 13 Loss: 0.6414 Acc: 0.8320\n",
      "----------\n",
      "Epoch 14/15\n",
      "----------\n",
      "Epoch [14/15], Step [56/454], Loss: 0.7657\n",
      "Epoch [14/15], Step [112/454], Loss: 0.3665\n",
      "Epoch [14/15], Step [168/454], Loss: 0.4572\n",
      "Epoch [14/15], Step [224/454], Loss: 0.2549\n",
      "Epoch [14/15], Step [280/454], Loss: 0.3387\n",
      "Epoch [14/15], Step [336/454], Loss: 0.3539\n",
      "Epoch [14/15], Step [392/454], Loss: 0.4657\n",
      "Epoch [14/15], Step [448/454], Loss: 0.4570\n",
      "Train phase -  Epoch 14 Loss: 0.4078 Acc: 0.8918\n",
      "Epoch [14/15], Step [14/114], Loss: 0.6588\n",
      "Epoch [14/15], Step [28/114], Loss: 0.3864\n",
      "Epoch [14/15], Step [42/114], Loss: 0.9115\n",
      "Epoch [14/15], Step [56/114], Loss: 0.7886\n",
      "Epoch [14/15], Step [70/114], Loss: 0.4368\n",
      "Epoch [14/15], Step [84/114], Loss: 0.4398\n",
      "Epoch [14/15], Step [98/114], Loss: 0.9778\n",
      "Epoch [14/15], Step [112/114], Loss: 0.7241\n",
      "Validation phase -  Epoch 14 Loss: 0.6275 Acc: 0.8359\n",
      "----------\n",
      "Epoch 15/15\n",
      "----------\n",
      "Epoch [15/15], Step [56/454], Loss: 0.5197\n",
      "Epoch [15/15], Step [112/454], Loss: 0.5297\n",
      "Epoch [15/15], Step [168/454], Loss: 0.4923\n",
      "Epoch [15/15], Step [224/454], Loss: 0.4637\n",
      "Epoch [15/15], Step [280/454], Loss: 0.1640\n",
      "Epoch [15/15], Step [336/454], Loss: 0.5019\n",
      "Epoch [15/15], Step [392/454], Loss: 0.2797\n",
      "Epoch [15/15], Step [448/454], Loss: 0.2009\n",
      "Train phase -  Epoch 15 Loss: 0.3909 Acc: 0.8963\n",
      "Epoch [15/15], Step [14/114], Loss: 0.4666\n",
      "Epoch [15/15], Step [28/114], Loss: 0.6305\n",
      "Epoch [15/15], Step [42/114], Loss: 0.6457\n",
      "Epoch [15/15], Step [56/114], Loss: 0.6937\n",
      "Epoch [15/15], Step [70/114], Loss: 0.4744\n",
      "Epoch [15/15], Step [84/114], Loss: 0.5517\n",
      "Epoch [15/15], Step [98/114], Loss: 0.4175\n",
      "Epoch [15/15], Step [112/114], Loss: 0.8336\n",
      "Validation phase -  Epoch 15 Loss: 0.6247 Acc: 0.8381\n",
      "Training complete in 10m 43s\n",
      "Best val Acc:0.8381\n",
      "Test phase -  Model accuracy: 0.8354\n",
      "Finished Training no-loss-weight_W_CNN_adam\n",
      "----------\n",
      "Epoch 1/15\n",
      "----------\n",
      "Epoch [1/15], Step [56/454], Loss: 3.7319\n",
      "Epoch [1/15], Step [112/454], Loss: 3.6934\n",
      "Epoch [1/15], Step [168/454], Loss: 3.5338\n",
      "Epoch [1/15], Step [224/454], Loss: 3.5425\n",
      "Epoch [1/15], Step [280/454], Loss: 3.4798\n",
      "Epoch [1/15], Step [336/454], Loss: 3.3151\n",
      "Epoch [1/15], Step [392/454], Loss: 3.6162\n",
      "Epoch [1/15], Step [448/454], Loss: 3.3252\n",
      "Train phase -  Epoch 1 Loss: 3.5424 Acc: 0.0746\n",
      "Epoch [1/15], Step [14/114], Loss: 3.3550\n",
      "Epoch [1/15], Step [28/114], Loss: 3.4526\n",
      "Epoch [1/15], Step [42/114], Loss: 3.3534\n",
      "Epoch [1/15], Step [56/114], Loss: 3.3711\n",
      "Epoch [1/15], Step [70/114], Loss: 3.6285\n",
      "Epoch [1/15], Step [84/114], Loss: 3.4835\n",
      "Epoch [1/15], Step [98/114], Loss: 3.3842\n",
      "Epoch [1/15], Step [112/114], Loss: 3.4681\n",
      "Validation phase -  Epoch 1 Loss: 3.4127 Acc: 0.0817\n",
      "----------\n",
      "Epoch 2/15\n",
      "----------\n",
      "Epoch [2/15], Step [56/454], Loss: 3.4072\n",
      "Epoch [2/15], Step [112/454], Loss: 3.3136\n",
      "Epoch [2/15], Step [168/454], Loss: 3.4812\n",
      "Epoch [2/15], Step [224/454], Loss: 3.2757\n",
      "Epoch [2/15], Step [280/454], Loss: 3.2806\n",
      "Epoch [2/15], Step [336/454], Loss: 3.6006\n",
      "Epoch [2/15], Step [392/454], Loss: 3.2850\n",
      "Epoch [2/15], Step [448/454], Loss: 3.1278\n",
      "Train phase -  Epoch 2 Loss: 3.3424 Acc: 0.1214\n",
      "Epoch [2/15], Step [14/114], Loss: 3.2582\n",
      "Epoch [2/15], Step [28/114], Loss: 3.2114\n",
      "Epoch [2/15], Step [42/114], Loss: 3.2616\n",
      "Epoch [2/15], Step [56/114], Loss: 3.3634\n",
      "Epoch [2/15], Step [70/114], Loss: 3.2276\n",
      "Epoch [2/15], Step [84/114], Loss: 3.2289\n",
      "Epoch [2/15], Step [98/114], Loss: 3.3450\n",
      "Epoch [2/15], Step [112/114], Loss: 3.0799\n",
      "Validation phase -  Epoch 2 Loss: 3.2588 Acc: 0.1308\n",
      "----------\n",
      "Epoch 3/15\n",
      "----------\n",
      "Epoch [3/15], Step [56/454], Loss: 3.5325\n",
      "Epoch [3/15], Step [112/454], Loss: 3.3250\n",
      "Epoch [3/15], Step [168/454], Loss: 3.1271\n",
      "Epoch [3/15], Step [224/454], Loss: 2.8820\n",
      "Epoch [3/15], Step [280/454], Loss: 2.8779\n",
      "Epoch [3/15], Step [336/454], Loss: 2.7365\n",
      "Epoch [3/15], Step [392/454], Loss: 2.7900\n",
      "Epoch [3/15], Step [448/454], Loss: 2.5435\n",
      "Train phase -  Epoch 3 Loss: 2.9387 Acc: 0.2348\n",
      "Epoch [3/15], Step [14/114], Loss: 2.8668\n",
      "Epoch [3/15], Step [28/114], Loss: 2.5319\n",
      "Epoch [3/15], Step [42/114], Loss: 2.8830\n",
      "Epoch [3/15], Step [56/114], Loss: 2.7896\n",
      "Epoch [3/15], Step [70/114], Loss: 2.4109\n",
      "Epoch [3/15], Step [84/114], Loss: 2.4139\n",
      "Epoch [3/15], Step [98/114], Loss: 2.6782\n",
      "Epoch [3/15], Step [112/114], Loss: 2.8864\n",
      "Validation phase -  Epoch 3 Loss: 2.6391 Acc: 0.2968\n",
      "----------\n",
      "Epoch 4/15\n",
      "----------\n",
      "Epoch [4/15], Step [56/454], Loss: 2.5192\n",
      "Epoch [4/15], Step [112/454], Loss: 2.2371\n",
      "Epoch [4/15], Step [168/454], Loss: 2.0863\n",
      "Epoch [4/15], Step [224/454], Loss: 2.2807\n",
      "Epoch [4/15], Step [280/454], Loss: 2.2871\n",
      "Epoch [4/15], Step [336/454], Loss: 2.4013\n",
      "Epoch [4/15], Step [392/454], Loss: 1.9416\n",
      "Epoch [4/15], Step [448/454], Loss: 2.0687\n",
      "Train phase -  Epoch 4 Loss: 2.2603 Acc: 0.3941\n",
      "Epoch [4/15], Step [14/114], Loss: 1.8623\n",
      "Epoch [4/15], Step [28/114], Loss: 1.8000\n",
      "Epoch [4/15], Step [42/114], Loss: 2.0499\n",
      "Epoch [4/15], Step [56/114], Loss: 2.0808\n",
      "Epoch [4/15], Step [70/114], Loss: 1.8345\n",
      "Epoch [4/15], Step [84/114], Loss: 2.3686\n",
      "Epoch [4/15], Step [98/114], Loss: 1.9828\n",
      "Epoch [4/15], Step [112/114], Loss: 1.8017\n",
      "Validation phase -  Epoch 4 Loss: 2.0010 Acc: 0.4475\n",
      "----------\n",
      "Epoch 5/15\n",
      "----------\n",
      "Epoch [5/15], Step [56/454], Loss: 1.9102\n",
      "Epoch [5/15], Step [112/454], Loss: 1.8279\n",
      "Epoch [5/15], Step [168/454], Loss: 1.6393\n",
      "Epoch [5/15], Step [224/454], Loss: 1.7393\n",
      "Epoch [5/15], Step [280/454], Loss: 1.5958\n",
      "Epoch [5/15], Step [336/454], Loss: 1.4928\n",
      "Epoch [5/15], Step [392/454], Loss: 1.2441\n",
      "Epoch [5/15], Step [448/454], Loss: 1.4699\n",
      "Train phase -  Epoch 5 Loss: 1.7191 Acc: 0.5281\n",
      "Epoch [5/15], Step [14/114], Loss: 1.3507\n",
      "Epoch [5/15], Step [28/114], Loss: 1.8048\n",
      "Epoch [5/15], Step [42/114], Loss: 1.6424\n",
      "Epoch [5/15], Step [56/114], Loss: 1.5126\n",
      "Epoch [5/15], Step [70/114], Loss: 1.9585\n",
      "Epoch [5/15], Step [84/114], Loss: 1.5132\n",
      "Epoch [5/15], Step [98/114], Loss: 1.7263\n",
      "Epoch [5/15], Step [112/114], Loss: 1.7498\n",
      "Validation phase -  Epoch 5 Loss: 1.6037 Acc: 0.5508\n",
      "----------\n",
      "Epoch 6/15\n",
      "----------\n",
      "Epoch [6/15], Step [56/454], Loss: 1.6183\n",
      "Epoch [6/15], Step [112/454], Loss: 1.3768\n",
      "Epoch [6/15], Step [168/454], Loss: 1.3692\n",
      "Epoch [6/15], Step [224/454], Loss: 1.2138\n",
      "Epoch [6/15], Step [280/454], Loss: 1.4591\n",
      "Epoch [6/15], Step [336/454], Loss: 1.3431\n",
      "Epoch [6/15], Step [392/454], Loss: 1.1043\n",
      "Epoch [6/15], Step [448/454], Loss: 1.2443\n",
      "Train phase -  Epoch 6 Loss: 1.3787 Acc: 0.6278\n",
      "Epoch [6/15], Step [14/114], Loss: 1.5414\n",
      "Epoch [6/15], Step [28/114], Loss: 1.2982\n",
      "Epoch [6/15], Step [42/114], Loss: 1.1610\n",
      "Epoch [6/15], Step [56/114], Loss: 1.3466\n",
      "Epoch [6/15], Step [70/114], Loss: 1.4233\n",
      "Epoch [6/15], Step [84/114], Loss: 1.4107\n",
      "Epoch [6/15], Step [98/114], Loss: 1.1617\n",
      "Epoch [6/15], Step [112/114], Loss: 0.8784\n",
      "Validation phase -  Epoch 6 Loss: 1.3048 Acc: 0.6550\n",
      "----------\n",
      "Epoch 7/15\n",
      "----------\n",
      "Epoch [7/15], Step [56/454], Loss: 1.5640\n",
      "Epoch [7/15], Step [112/454], Loss: 1.1691\n",
      "Epoch [7/15], Step [168/454], Loss: 1.3298\n",
      "Epoch [7/15], Step [224/454], Loss: 1.2075\n",
      "Epoch [7/15], Step [280/454], Loss: 0.7442\n",
      "Epoch [7/15], Step [336/454], Loss: 1.2125\n",
      "Epoch [7/15], Step [392/454], Loss: 0.9162\n",
      "Epoch [7/15], Step [448/454], Loss: 1.2101\n",
      "Train phase -  Epoch 7 Loss: 1.1302 Acc: 0.7039\n",
      "Epoch [7/15], Step [14/114], Loss: 1.4052\n",
      "Epoch [7/15], Step [28/114], Loss: 0.9433\n",
      "Epoch [7/15], Step [42/114], Loss: 1.1132\n",
      "Epoch [7/15], Step [56/114], Loss: 0.8537\n",
      "Epoch [7/15], Step [70/114], Loss: 1.4283\n",
      "Epoch [7/15], Step [84/114], Loss: 1.0591\n",
      "Epoch [7/15], Step [98/114], Loss: 1.1508\n",
      "Epoch [7/15], Step [112/114], Loss: 0.8691\n",
      "Validation phase -  Epoch 7 Loss: 1.1440 Acc: 0.6894\n",
      "----------\n",
      "Epoch 8/15\n",
      "----------\n",
      "Epoch [8/15], Step [56/454], Loss: 0.8808\n",
      "Epoch [8/15], Step [112/454], Loss: 1.0511\n",
      "Epoch [8/15], Step [168/454], Loss: 0.9452\n",
      "Epoch [8/15], Step [224/454], Loss: 0.9759\n",
      "Epoch [8/15], Step [280/454], Loss: 0.8655\n",
      "Epoch [8/15], Step [336/454], Loss: 0.6311\n",
      "Epoch [8/15], Step [392/454], Loss: 0.9784\n",
      "Epoch [8/15], Step [448/454], Loss: 0.8412\n",
      "Train phase -  Epoch 8 Loss: 0.9690 Acc: 0.7489\n",
      "Epoch [8/15], Step [14/114], Loss: 1.0927\n",
      "Epoch [8/15], Step [28/114], Loss: 0.9093\n",
      "Epoch [8/15], Step [42/114], Loss: 0.9871\n",
      "Epoch [8/15], Step [56/114], Loss: 1.0610\n",
      "Epoch [8/15], Step [70/114], Loss: 1.2743\n",
      "Epoch [8/15], Step [84/114], Loss: 0.9541\n",
      "Epoch [8/15], Step [98/114], Loss: 0.8150\n",
      "Epoch [8/15], Step [112/114], Loss: 0.8902\n",
      "Validation phase -  Epoch 8 Loss: 0.9287 Acc: 0.7683\n",
      "----------\n",
      "Epoch 9/15\n",
      "----------\n",
      "Epoch [9/15], Step [56/454], Loss: 0.8685\n",
      "Epoch [9/15], Step [112/454], Loss: 0.8657\n",
      "Epoch [9/15], Step [168/454], Loss: 0.8776\n",
      "Epoch [9/15], Step [224/454], Loss: 0.9743\n",
      "Epoch [9/15], Step [280/454], Loss: 0.8335\n",
      "Epoch [9/15], Step [336/454], Loss: 0.8740\n",
      "Epoch [9/15], Step [392/454], Loss: 0.6234\n",
      "Epoch [9/15], Step [448/454], Loss: 1.1260\n",
      "Train phase -  Epoch 9 Loss: 0.8596 Acc: 0.7779\n",
      "Epoch [9/15], Step [14/114], Loss: 0.5027\n",
      "Epoch [9/15], Step [28/114], Loss: 1.1901\n",
      "Epoch [9/15], Step [42/114], Loss: 1.2400\n",
      "Epoch [9/15], Step [56/114], Loss: 0.8226\n",
      "Epoch [9/15], Step [70/114], Loss: 0.8199\n",
      "Epoch [9/15], Step [84/114], Loss: 0.6129\n",
      "Epoch [9/15], Step [98/114], Loss: 0.8010\n",
      "Epoch [9/15], Step [112/114], Loss: 0.7327\n",
      "Validation phase -  Epoch 9 Loss: 0.8592 Acc: 0.7808\n",
      "----------\n",
      "Epoch 10/15\n",
      "----------\n",
      "Epoch [10/15], Step [56/454], Loss: 0.8692\n",
      "Epoch [10/15], Step [112/454], Loss: 1.0683\n",
      "Epoch [10/15], Step [168/454], Loss: 0.5943\n",
      "Epoch [10/15], Step [224/454], Loss: 0.7888\n",
      "Epoch [10/15], Step [280/454], Loss: 0.6198\n",
      "Epoch [10/15], Step [336/454], Loss: 0.6516\n",
      "Epoch [10/15], Step [392/454], Loss: 0.7839\n",
      "Epoch [10/15], Step [448/454], Loss: 0.5022\n",
      "Train phase -  Epoch 10 Loss: 0.7765 Acc: 0.7996\n",
      "Epoch [10/15], Step [14/114], Loss: 0.8545\n",
      "Epoch [10/15], Step [28/114], Loss: 0.9804\n",
      "Epoch [10/15], Step [42/114], Loss: 0.8081\n",
      "Epoch [10/15], Step [56/114], Loss: 0.7916\n",
      "Epoch [10/15], Step [70/114], Loss: 1.1606\n",
      "Epoch [10/15], Step [84/114], Loss: 1.0509\n",
      "Epoch [10/15], Step [98/114], Loss: 0.3882\n",
      "Epoch [10/15], Step [112/114], Loss: 0.7383\n",
      "Validation phase -  Epoch 10 Loss: 0.7904 Acc: 0.7959\n",
      "----------\n",
      "Epoch 11/15\n",
      "----------\n",
      "Epoch [11/15], Step [56/454], Loss: 0.7515\n",
      "Epoch [11/15], Step [112/454], Loss: 0.6772\n",
      "Epoch [11/15], Step [168/454], Loss: 0.8183\n",
      "Epoch [11/15], Step [224/454], Loss: 0.7576\n",
      "Epoch [11/15], Step [280/454], Loss: 0.5612\n",
      "Epoch [11/15], Step [336/454], Loss: 0.6875\n",
      "Epoch [11/15], Step [392/454], Loss: 0.6344\n",
      "Epoch [11/15], Step [448/454], Loss: 0.6333\n",
      "Train phase -  Epoch 11 Loss: 0.7269 Acc: 0.8107\n",
      "Epoch [11/15], Step [14/114], Loss: 0.7573\n",
      "Epoch [11/15], Step [28/114], Loss: 0.5970\n",
      "Epoch [11/15], Step [42/114], Loss: 0.7631\n",
      "Epoch [11/15], Step [56/114], Loss: 0.9069\n",
      "Epoch [11/15], Step [70/114], Loss: 0.7258\n",
      "Epoch [11/15], Step [84/114], Loss: 0.7619\n",
      "Epoch [11/15], Step [98/114], Loss: 0.7573\n",
      "Epoch [11/15], Step [112/114], Loss: 0.7941\n",
      "Validation phase -  Epoch 11 Loss: 0.7692 Acc: 0.7953\n",
      "----------\n",
      "Epoch 12/15\n",
      "----------\n",
      "Epoch [12/15], Step [56/454], Loss: 0.6185\n",
      "Epoch [12/15], Step [112/454], Loss: 0.7237\n",
      "Epoch [12/15], Step [168/454], Loss: 0.8536\n",
      "Epoch [12/15], Step [224/454], Loss: 0.4475\n",
      "Epoch [12/15], Step [280/454], Loss: 0.7485\n",
      "Epoch [12/15], Step [336/454], Loss: 0.8002\n",
      "Epoch [12/15], Step [392/454], Loss: 0.6834\n",
      "Epoch [12/15], Step [448/454], Loss: 0.4497\n",
      "Train phase -  Epoch 12 Loss: 0.6742 Acc: 0.8239\n",
      "Epoch [12/15], Step [14/114], Loss: 0.5043\n",
      "Epoch [12/15], Step [28/114], Loss: 0.6181\n",
      "Epoch [12/15], Step [42/114], Loss: 0.7399\n",
      "Epoch [12/15], Step [56/114], Loss: 0.8917\n",
      "Epoch [12/15], Step [70/114], Loss: 0.8430\n",
      "Epoch [12/15], Step [84/114], Loss: 0.7017\n",
      "Epoch [12/15], Step [98/114], Loss: 0.4626\n",
      "Epoch [12/15], Step [112/114], Loss: 0.6694\n",
      "Validation phase -  Epoch 12 Loss: 0.7442 Acc: 0.8041\n",
      "----------\n",
      "Epoch 13/15\n",
      "----------\n",
      "Epoch [13/15], Step [56/454], Loss: 0.5580\n",
      "Epoch [13/15], Step [112/454], Loss: 0.5871\n",
      "Epoch [13/15], Step [168/454], Loss: 0.5326\n",
      "Epoch [13/15], Step [224/454], Loss: 0.7629\n",
      "Epoch [13/15], Step [280/454], Loss: 0.7945\n",
      "Epoch [13/15], Step [336/454], Loss: 0.6397\n",
      "Epoch [13/15], Step [392/454], Loss: 0.5696\n",
      "Epoch [13/15], Step [448/454], Loss: 0.7699\n",
      "Train phase -  Epoch 13 Loss: 0.6401 Acc: 0.8324\n",
      "Epoch [13/15], Step [14/114], Loss: 0.7347\n",
      "Epoch [13/15], Step [28/114], Loss: 0.5978\n",
      "Epoch [13/15], Step [42/114], Loss: 0.5971\n",
      "Epoch [13/15], Step [56/114], Loss: 0.6406\n",
      "Epoch [13/15], Step [70/114], Loss: 0.9702\n",
      "Epoch [13/15], Step [84/114], Loss: 0.7160\n",
      "Epoch [13/15], Step [98/114], Loss: 0.4242\n",
      "Epoch [13/15], Step [112/114], Loss: 0.9152\n",
      "Validation phase -  Epoch 13 Loss: 0.7713 Acc: 0.8002\n",
      "----------\n",
      "Epoch 14/15\n",
      "----------\n",
      "Epoch [14/15], Step [56/454], Loss: 0.6751\n",
      "Epoch [14/15], Step [112/454], Loss: 0.4975\n",
      "Epoch [14/15], Step [168/454], Loss: 0.5912\n",
      "Epoch [14/15], Step [224/454], Loss: 0.7487\n",
      "Epoch [14/15], Step [280/454], Loss: 0.6828\n",
      "Epoch [14/15], Step [336/454], Loss: 0.5283\n",
      "Epoch [14/15], Step [392/454], Loss: 0.4777\n",
      "Epoch [14/15], Step [448/454], Loss: 0.5553\n",
      "Train phase -  Epoch 14 Loss: 0.6126 Acc: 0.8403\n",
      "Epoch [14/15], Step [14/114], Loss: 0.6540\n",
      "Epoch [14/15], Step [28/114], Loss: 0.8046\n",
      "Epoch [14/15], Step [42/114], Loss: 0.7339\n",
      "Epoch [14/15], Step [56/114], Loss: 0.7502\n",
      "Epoch [14/15], Step [70/114], Loss: 0.8951\n",
      "Epoch [14/15], Step [84/114], Loss: 0.7083\n",
      "Epoch [14/15], Step [98/114], Loss: 0.9811\n",
      "Epoch [14/15], Step [112/114], Loss: 0.5248\n",
      "Validation phase -  Epoch 14 Loss: 0.7259 Acc: 0.8039\n",
      "----------\n",
      "Epoch 15/15\n",
      "----------\n",
      "Epoch [15/15], Step [56/454], Loss: 0.5681\n",
      "Epoch [15/15], Step [112/454], Loss: 0.6407\n",
      "Epoch [15/15], Step [168/454], Loss: 0.4186\n",
      "Epoch [15/15], Step [224/454], Loss: 0.6598\n",
      "Epoch [15/15], Step [280/454], Loss: 0.5349\n",
      "Epoch [15/15], Step [336/454], Loss: 0.7785\n",
      "Epoch [15/15], Step [392/454], Loss: 0.5332\n",
      "Epoch [15/15], Step [448/454], Loss: 0.2699\n",
      "Train phase -  Epoch 15 Loss: 0.6814 Acc: 0.8287\n",
      "Epoch [15/15], Step [14/114], Loss: 0.4260\n",
      "Epoch [15/15], Step [28/114], Loss: 0.7773\n",
      "Epoch [15/15], Step [42/114], Loss: 0.5062\n",
      "Epoch [15/15], Step [56/114], Loss: 0.5930\n",
      "Epoch [15/15], Step [70/114], Loss: 0.7383\n",
      "Epoch [15/15], Step [84/114], Loss: 0.6447\n",
      "Epoch [15/15], Step [98/114], Loss: 0.4551\n",
      "Epoch [15/15], Step [112/114], Loss: 0.6241\n",
      "Validation phase -  Epoch 15 Loss: 0.6858 Acc: 0.8245\n",
      "Training complete in 18m 34s\n",
      "Best val Acc:0.8245\n",
      "Test phase -  Model accuracy: 0.8124\n",
      "Finished Training no-loss-weight_W_CNN_ST_sgd\n",
      "----------\n",
      "Epoch 1/15\n",
      "----------\n",
      "Epoch [1/15], Step [56/454], Loss: 3.2383\n",
      "Epoch [1/15], Step [112/454], Loss: 2.9716\n",
      "Epoch [1/15], Step [168/454], Loss: 2.3112\n",
      "Epoch [1/15], Step [224/454], Loss: 2.0106\n",
      "Epoch [1/15], Step [280/454], Loss: 1.5535\n",
      "Epoch [1/15], Step [336/454], Loss: 1.4532\n",
      "Epoch [1/15], Step [392/454], Loss: 1.8160\n",
      "Epoch [1/15], Step [448/454], Loss: 1.5896\n",
      "Train phase -  Epoch 1 Loss: 2.3147 Acc: 0.3759\n",
      "Epoch [1/15], Step [14/114], Loss: 1.3907\n",
      "Epoch [1/15], Step [28/114], Loss: 0.9984\n",
      "Epoch [1/15], Step [42/114], Loss: 1.4912\n",
      "Epoch [1/15], Step [56/114], Loss: 1.5417\n",
      "Epoch [1/15], Step [70/114], Loss: 1.3271\n",
      "Epoch [1/15], Step [84/114], Loss: 1.5376\n",
      "Epoch [1/15], Step [98/114], Loss: 1.1846\n",
      "Epoch [1/15], Step [112/114], Loss: 1.4167\n",
      "Validation phase -  Epoch 1 Loss: 1.3937 Acc: 0.6159\n",
      "----------\n",
      "Epoch 2/15\n",
      "----------\n",
      "Epoch [2/15], Step [56/454], Loss: 0.9998\n",
      "Epoch [2/15], Step [112/454], Loss: 0.8218\n",
      "Epoch [2/15], Step [168/454], Loss: 1.0192\n",
      "Epoch [2/15], Step [224/454], Loss: 0.8682\n",
      "Epoch [2/15], Step [280/454], Loss: 0.8595\n",
      "Epoch [2/15], Step [336/454], Loss: 1.2802\n",
      "Epoch [2/15], Step [392/454], Loss: 1.0498\n",
      "Epoch [2/15], Step [448/454], Loss: 0.7282\n",
      "Train phase -  Epoch 2 Loss: 1.0709 Acc: 0.7091\n",
      "Epoch [2/15], Step [14/114], Loss: 0.6120\n",
      "Epoch [2/15], Step [28/114], Loss: 0.8047\n",
      "Epoch [2/15], Step [42/114], Loss: 0.8872\n",
      "Epoch [2/15], Step [56/114], Loss: 0.8798\n",
      "Epoch [2/15], Step [70/114], Loss: 1.1051\n",
      "Epoch [2/15], Step [84/114], Loss: 0.7736\n",
      "Epoch [2/15], Step [98/114], Loss: 1.0608\n",
      "Epoch [2/15], Step [112/114], Loss: 0.8116\n",
      "Validation phase -  Epoch 2 Loss: 0.9150 Acc: 0.7694\n",
      "----------\n",
      "Epoch 3/15\n",
      "----------\n",
      "Epoch [3/15], Step [56/454], Loss: 1.1315\n",
      "Epoch [3/15], Step [112/454], Loss: 0.6934\n",
      "Epoch [3/15], Step [168/454], Loss: 0.8864\n",
      "Epoch [3/15], Step [224/454], Loss: 0.5971\n",
      "Epoch [3/15], Step [280/454], Loss: 0.7649\n",
      "Epoch [3/15], Step [336/454], Loss: 0.7826\n",
      "Epoch [3/15], Step [392/454], Loss: 0.7529\n",
      "Epoch [3/15], Step [448/454], Loss: 0.4563\n",
      "Train phase -  Epoch 3 Loss: 0.7899 Acc: 0.7914\n",
      "Epoch [3/15], Step [14/114], Loss: 0.6208\n",
      "Epoch [3/15], Step [28/114], Loss: 0.8101\n",
      "Epoch [3/15], Step [42/114], Loss: 0.8609\n",
      "Epoch [3/15], Step [56/114], Loss: 1.0705\n",
      "Epoch [3/15], Step [70/114], Loss: 1.0150\n",
      "Epoch [3/15], Step [84/114], Loss: 0.6406\n",
      "Epoch [3/15], Step [98/114], Loss: 0.8697\n",
      "Epoch [3/15], Step [112/114], Loss: 0.6987\n",
      "Validation phase -  Epoch 3 Loss: 0.7565 Acc: 0.7958\n",
      "----------\n",
      "Epoch 4/15\n",
      "----------\n",
      "Epoch [4/15], Step [56/454], Loss: 0.6057\n",
      "Epoch [4/15], Step [112/454], Loss: 0.6251\n",
      "Epoch [4/15], Step [168/454], Loss: 0.5870\n",
      "Epoch [4/15], Step [224/454], Loss: 0.6413\n",
      "Epoch [4/15], Step [280/454], Loss: 0.8521\n",
      "Epoch [4/15], Step [336/454], Loss: 0.4258\n",
      "Epoch [4/15], Step [392/454], Loss: 0.4408\n",
      "Epoch [4/15], Step [448/454], Loss: 0.7037\n",
      "Train phase -  Epoch 4 Loss: 0.6601 Acc: 0.8228\n",
      "Epoch [4/15], Step [14/114], Loss: 0.8620\n",
      "Epoch [4/15], Step [28/114], Loss: 0.6517\n",
      "Epoch [4/15], Step [42/114], Loss: 0.3809\n",
      "Epoch [4/15], Step [56/114], Loss: 0.8414\n",
      "Epoch [4/15], Step [70/114], Loss: 0.7654\n",
      "Epoch [4/15], Step [84/114], Loss: 0.5478\n",
      "Epoch [4/15], Step [98/114], Loss: 0.3494\n",
      "Epoch [4/15], Step [112/114], Loss: 0.6833\n",
      "Validation phase -  Epoch 4 Loss: 0.6684 Acc: 0.8198\n",
      "----------\n",
      "Epoch 5/15\n",
      "----------\n",
      "Epoch [5/15], Step [56/454], Loss: 0.8377\n",
      "Epoch [5/15], Step [112/454], Loss: 0.3503\n",
      "Epoch [5/15], Step [168/454], Loss: 0.6126\n",
      "Epoch [5/15], Step [224/454], Loss: 0.7735\n",
      "Epoch [5/15], Step [280/454], Loss: 0.8269\n",
      "Epoch [5/15], Step [336/454], Loss: 0.5459\n",
      "Epoch [5/15], Step [392/454], Loss: 0.6358\n",
      "Epoch [5/15], Step [448/454], Loss: 0.8019\n",
      "Train phase -  Epoch 5 Loss: 0.5867 Acc: 0.8414\n",
      "Epoch [5/15], Step [14/114], Loss: 0.7688\n",
      "Epoch [5/15], Step [28/114], Loss: 0.7380\n",
      "Epoch [5/15], Step [42/114], Loss: 0.5459\n",
      "Epoch [5/15], Step [56/114], Loss: 0.4200\n",
      "Epoch [5/15], Step [70/114], Loss: 0.6884\n",
      "Epoch [5/15], Step [84/114], Loss: 0.7721\n",
      "Epoch [5/15], Step [98/114], Loss: 0.8702\n",
      "Epoch [5/15], Step [112/114], Loss: 0.6027\n",
      "Validation phase -  Epoch 5 Loss: 0.6517 Acc: 0.8220\n",
      "----------\n",
      "Epoch 6/15\n",
      "----------\n",
      "Epoch [6/15], Step [56/454], Loss: 0.5227\n",
      "Epoch [6/15], Step [112/454], Loss: 0.4861\n",
      "Epoch [6/15], Step [168/454], Loss: 0.7697\n",
      "Epoch [6/15], Step [224/454], Loss: 0.4747\n",
      "Epoch [6/15], Step [280/454], Loss: 0.7198\n",
      "Epoch [6/15], Step [336/454], Loss: 0.7597\n",
      "Epoch [6/15], Step [392/454], Loss: 0.4863\n",
      "Epoch [6/15], Step [448/454], Loss: 0.4323\n",
      "Train phase -  Epoch 6 Loss: 0.5366 Acc: 0.8536\n",
      "Epoch [6/15], Step [14/114], Loss: 0.5025\n",
      "Epoch [6/15], Step [28/114], Loss: 0.7731\n",
      "Epoch [6/15], Step [42/114], Loss: 0.5568\n",
      "Epoch [6/15], Step [56/114], Loss: 0.9345\n",
      "Epoch [6/15], Step [70/114], Loss: 0.7711\n",
      "Epoch [6/15], Step [84/114], Loss: 0.9624\n",
      "Epoch [6/15], Step [98/114], Loss: 0.7248\n",
      "Epoch [6/15], Step [112/114], Loss: 0.6506\n",
      "Validation phase -  Epoch 6 Loss: 0.5998 Acc: 0.8399\n",
      "----------\n",
      "Epoch 7/15\n",
      "----------\n",
      "Epoch [7/15], Step [56/454], Loss: 0.5929\n",
      "Epoch [7/15], Step [112/454], Loss: 0.6470\n",
      "Epoch [7/15], Step [168/454], Loss: 0.7302\n",
      "Epoch [7/15], Step [224/454], Loss: 0.4940\n",
      "Epoch [7/15], Step [280/454], Loss: 0.6950\n",
      "Epoch [7/15], Step [336/454], Loss: 0.6033\n",
      "Epoch [7/15], Step [392/454], Loss: 0.5068\n",
      "Epoch [7/15], Step [448/454], Loss: 0.6140\n",
      "Train phase -  Epoch 7 Loss: 0.5040 Acc: 0.8621\n",
      "Epoch [7/15], Step [14/114], Loss: 0.4702\n",
      "Epoch [7/15], Step [28/114], Loss: 0.6185\n",
      "Epoch [7/15], Step [42/114], Loss: 0.5290\n",
      "Epoch [7/15], Step [56/114], Loss: 0.8305\n",
      "Epoch [7/15], Step [70/114], Loss: 0.5444\n",
      "Epoch [7/15], Step [84/114], Loss: 0.4396\n",
      "Epoch [7/15], Step [98/114], Loss: 0.9288\n",
      "Epoch [7/15], Step [112/114], Loss: 0.6696\n",
      "Validation phase -  Epoch 7 Loss: 0.5763 Acc: 0.8416\n",
      "----------\n",
      "Epoch 8/15\n",
      "----------\n",
      "Epoch [8/15], Step [56/454], Loss: 0.3174\n",
      "Epoch [8/15], Step [112/454], Loss: 0.4771\n",
      "Epoch [8/15], Step [168/454], Loss: 0.1538\n",
      "Epoch [8/15], Step [224/454], Loss: 0.4129\n",
      "Epoch [8/15], Step [280/454], Loss: 0.6540\n",
      "Epoch [8/15], Step [336/454], Loss: 0.6052\n",
      "Epoch [8/15], Step [392/454], Loss: 0.3284\n",
      "Epoch [8/15], Step [448/454], Loss: 0.4099\n",
      "Train phase -  Epoch 8 Loss: 0.4704 Acc: 0.8710\n",
      "Epoch [8/15], Step [14/114], Loss: 0.6134\n",
      "Epoch [8/15], Step [28/114], Loss: 0.2896\n",
      "Epoch [8/15], Step [42/114], Loss: 0.5722\n",
      "Epoch [8/15], Step [56/114], Loss: 0.4475\n",
      "Epoch [8/15], Step [70/114], Loss: 0.7366\n",
      "Epoch [8/15], Step [84/114], Loss: 0.5450\n",
      "Epoch [8/15], Step [98/114], Loss: 0.4995\n",
      "Epoch [8/15], Step [112/114], Loss: 0.6692\n",
      "Validation phase -  Epoch 8 Loss: 0.5640 Acc: 0.8453\n",
      "----------\n",
      "Epoch 9/15\n",
      "----------\n",
      "Epoch [9/15], Step [56/454], Loss: 0.3469\n",
      "Epoch [9/15], Step [112/454], Loss: 0.6919\n",
      "Epoch [9/15], Step [168/454], Loss: 0.2865\n",
      "Epoch [9/15], Step [224/454], Loss: 0.6335\n",
      "Epoch [9/15], Step [280/454], Loss: 0.3051\n",
      "Epoch [9/15], Step [336/454], Loss: 0.4399\n",
      "Epoch [9/15], Step [392/454], Loss: 0.6589\n",
      "Epoch [9/15], Step [448/454], Loss: 0.4291\n",
      "Train phase -  Epoch 9 Loss: 0.4509 Acc: 0.8756\n",
      "Epoch [9/15], Step [14/114], Loss: 0.6529\n",
      "Epoch [9/15], Step [28/114], Loss: 0.6196\n",
      "Epoch [9/15], Step [42/114], Loss: 0.2936\n",
      "Epoch [9/15], Step [56/114], Loss: 0.3659\n",
      "Epoch [9/15], Step [70/114], Loss: 0.5642\n",
      "Epoch [9/15], Step [84/114], Loss: 0.7534\n",
      "Epoch [9/15], Step [98/114], Loss: 0.3467\n",
      "Epoch [9/15], Step [112/114], Loss: 0.6395\n",
      "Validation phase -  Epoch 9 Loss: 0.5675 Acc: 0.8432\n",
      "----------\n",
      "Epoch 10/15\n",
      "----------\n",
      "Epoch [10/15], Step [56/454], Loss: 0.5231\n",
      "Epoch [10/15], Step [112/454], Loss: 0.6100\n",
      "Epoch [10/15], Step [168/454], Loss: 0.5819\n",
      "Epoch [10/15], Step [224/454], Loss: 0.5677\n",
      "Epoch [10/15], Step [280/454], Loss: 0.5524\n",
      "Epoch [10/15], Step [336/454], Loss: 0.4533\n",
      "Epoch [10/15], Step [392/454], Loss: 0.4639\n",
      "Epoch [10/15], Step [448/454], Loss: 0.1920\n",
      "Train phase -  Epoch 10 Loss: 0.4290 Acc: 0.8831\n",
      "Epoch [10/15], Step [14/114], Loss: 0.3957\n",
      "Epoch [10/15], Step [28/114], Loss: 0.2151\n",
      "Epoch [10/15], Step [42/114], Loss: 0.5922\n",
      "Epoch [10/15], Step [56/114], Loss: 0.3686\n",
      "Epoch [10/15], Step [70/114], Loss: 0.6681\n",
      "Epoch [10/15], Step [84/114], Loss: 1.1176\n",
      "Epoch [10/15], Step [98/114], Loss: 0.3029\n",
      "Epoch [10/15], Step [112/114], Loss: 0.4893\n",
      "Validation phase -  Epoch 10 Loss: 0.5489 Acc: 0.8530\n",
      "----------\n",
      "Epoch 11/15\n",
      "----------\n",
      "Epoch [11/15], Step [56/454], Loss: 0.4944\n",
      "Epoch [11/15], Step [112/454], Loss: 0.3711\n",
      "Epoch [11/15], Step [168/454], Loss: 0.4832\n",
      "Epoch [11/15], Step [224/454], Loss: 0.1846\n",
      "Epoch [11/15], Step [280/454], Loss: 0.4976\n",
      "Epoch [11/15], Step [336/454], Loss: 0.3130\n",
      "Epoch [11/15], Step [392/454], Loss: 0.5314\n",
      "Epoch [11/15], Step [448/454], Loss: 0.3901\n",
      "Train phase -  Epoch 11 Loss: 0.4164 Acc: 0.8856\n",
      "Epoch [11/15], Step [14/114], Loss: 0.4437\n",
      "Epoch [11/15], Step [28/114], Loss: 0.4702\n",
      "Epoch [11/15], Step [42/114], Loss: 0.6608\n",
      "Epoch [11/15], Step [56/114], Loss: 0.5962\n",
      "Epoch [11/15], Step [70/114], Loss: 1.0780\n",
      "Epoch [11/15], Step [84/114], Loss: 0.6107\n",
      "Epoch [11/15], Step [98/114], Loss: 0.4549\n",
      "Epoch [11/15], Step [112/114], Loss: 0.7440\n",
      "Validation phase -  Epoch 11 Loss: 0.5547 Acc: 0.8504\n",
      "----------\n",
      "Epoch 12/15\n",
      "----------\n",
      "Epoch [12/15], Step [56/454], Loss: 0.2236\n",
      "Epoch [12/15], Step [112/454], Loss: 0.2573\n",
      "Epoch [12/15], Step [168/454], Loss: 0.4304\n",
      "Epoch [12/15], Step [224/454], Loss: 0.1787\n",
      "Epoch [12/15], Step [280/454], Loss: 0.4056\n",
      "Epoch [12/15], Step [336/454], Loss: 0.1956\n",
      "Epoch [12/15], Step [392/454], Loss: 0.3761\n",
      "Epoch [12/15], Step [448/454], Loss: 0.2582\n",
      "Train phase -  Epoch 12 Loss: 0.4018 Acc: 0.8898\n",
      "Epoch [12/15], Step [14/114], Loss: 0.5479\n",
      "Epoch [12/15], Step [28/114], Loss: 0.7946\n",
      "Epoch [12/15], Step [42/114], Loss: 0.6845\n",
      "Epoch [12/15], Step [56/114], Loss: 0.7247\n",
      "Epoch [12/15], Step [70/114], Loss: 0.4758\n",
      "Epoch [12/15], Step [84/114], Loss: 0.6325\n",
      "Epoch [12/15], Step [98/114], Loss: 0.2568\n",
      "Epoch [12/15], Step [112/114], Loss: 1.0287\n",
      "Validation phase -  Epoch 12 Loss: 0.5743 Acc: 0.8504\n",
      "----------\n",
      "Epoch 13/15\n",
      "----------\n",
      "Epoch [13/15], Step [56/454], Loss: 0.3870\n",
      "Epoch [13/15], Step [112/454], Loss: 0.3071\n",
      "Epoch [13/15], Step [168/454], Loss: 0.2303\n",
      "Epoch [13/15], Step [224/454], Loss: 0.4613\n",
      "Epoch [13/15], Step [280/454], Loss: 0.3132\n",
      "Epoch [13/15], Step [336/454], Loss: 0.1774\n",
      "Epoch [13/15], Step [392/454], Loss: 0.2168\n",
      "Epoch [13/15], Step [448/454], Loss: 0.5972\n",
      "Train phase -  Epoch 13 Loss: 0.3912 Acc: 0.8932\n",
      "Epoch [13/15], Step [14/114], Loss: 0.4256\n",
      "Epoch [13/15], Step [28/114], Loss: 0.3763\n",
      "Epoch [13/15], Step [42/114], Loss: 0.5701\n",
      "Epoch [13/15], Step [56/114], Loss: 0.7241\n",
      "Epoch [13/15], Step [70/114], Loss: 0.4598\n",
      "Epoch [13/15], Step [84/114], Loss: 0.7611\n",
      "Epoch [13/15], Step [98/114], Loss: 0.4660\n",
      "Epoch [13/15], Step [112/114], Loss: 0.4592\n",
      "Validation phase -  Epoch 13 Loss: 0.5727 Acc: 0.8501\n",
      "----------\n",
      "Epoch 14/15\n",
      "----------\n",
      "Epoch [14/15], Step [56/454], Loss: 0.3039\n",
      "Epoch [14/15], Step [112/454], Loss: 0.6097\n",
      "Epoch [14/15], Step [168/454], Loss: 0.3325\n",
      "Epoch [14/15], Step [224/454], Loss: 0.6372\n",
      "Epoch [14/15], Step [280/454], Loss: 0.1815\n",
      "Epoch [14/15], Step [336/454], Loss: 0.3276\n",
      "Epoch [14/15], Step [392/454], Loss: 0.3052\n",
      "Epoch [14/15], Step [448/454], Loss: 0.3107\n",
      "Train phase -  Epoch 14 Loss: 0.3835 Acc: 0.8957\n",
      "Epoch [14/15], Step [14/114], Loss: 1.0112\n",
      "Epoch [14/15], Step [28/114], Loss: 0.5245\n",
      "Epoch [14/15], Step [42/114], Loss: 0.5141\n",
      "Epoch [14/15], Step [56/114], Loss: 0.2775\n",
      "Epoch [14/15], Step [70/114], Loss: 0.6834\n",
      "Epoch [14/15], Step [84/114], Loss: 0.7722\n",
      "Epoch [14/15], Step [98/114], Loss: 0.6043\n",
      "Epoch [14/15], Step [112/114], Loss: 0.7218\n",
      "Validation phase -  Epoch 14 Loss: 0.5546 Acc: 0.8535\n",
      "----------\n",
      "Epoch 15/15\n",
      "----------\n",
      "Epoch [15/15], Step [56/454], Loss: 0.3476\n",
      "Epoch [15/15], Step [112/454], Loss: 0.3285\n",
      "Epoch [15/15], Step [168/454], Loss: 0.3500\n",
      "Epoch [15/15], Step [224/454], Loss: 0.2102\n",
      "Epoch [15/15], Step [280/454], Loss: 0.3406\n",
      "Epoch [15/15], Step [336/454], Loss: 0.5115\n",
      "Epoch [15/15], Step [392/454], Loss: 0.6030\n",
      "Epoch [15/15], Step [448/454], Loss: 0.3158\n",
      "Train phase -  Epoch 15 Loss: 0.3763 Acc: 0.8979\n",
      "Epoch [15/15], Step [14/114], Loss: 0.6582\n",
      "Epoch [15/15], Step [28/114], Loss: 0.5699\n",
      "Epoch [15/15], Step [42/114], Loss: 0.5262\n",
      "Epoch [15/15], Step [56/114], Loss: 0.4957\n",
      "Epoch [15/15], Step [70/114], Loss: 0.7727\n",
      "Epoch [15/15], Step [84/114], Loss: 0.5656\n",
      "Epoch [15/15], Step [98/114], Loss: 0.6433\n",
      "Epoch [15/15], Step [112/114], Loss: 0.3773\n",
      "Validation phase -  Epoch 15 Loss: 0.5756 Acc: 0.8544\n",
      "Training complete in 15m 4s\n",
      "Best val Acc:0.8544\n",
      "Test phase -  Model accuracy: 0.8500\n",
      "Finished Training no-loss-weight_W_CNN_ST_adam\n"
     ]
    }
   ],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "# runs_arguments = [\n",
    "#     {'type': 'P', 'cnn': 'CNN'},\n",
    "#     {'type': 'P', 'cnn': 'CNN_ST'},\n",
    "#     {'type': 'W', 'cnn': 'CNN'},\n",
    "#     {'type': 'W', 'cnn': 'CNN_ST'},\n",
    "# ]\n",
    "for r_args in runs_arguments:\n",
    "    dataset_type = r_args['type']\n",
    "    model_architecture = r_args['cnn']\n",
    "    \n",
    "    train_dir = plain_train_dir if dataset_type == 'P' else weather_train_dir   \n",
    "    test_dir = plain_test_dir if dataset_type == 'P' else weather_test_dir   \n",
    "    train_dataset, test_dataset = load_train_test_dir(train_dir, test_dir)\n",
    "    \n",
    "    # Compute class weights\n",
    "    train_size = len(train_dataset)\n",
    "    number_of_classes = len(train_dataset.classes)\n",
    "    train_samples_per_class = np.bincount(train_dataset.targets)\n",
    "    class_weights=(train_size/(number_of_classes*train_samples_per_class))\n",
    "    class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    "    \n",
    "    for sel_optim in ['sgd', 'adam']:\n",
    "        hyperparams = sgd_hyperparams if sel_optim == 'sgd' else adam_hyperparams\n",
    "        model_name = f'no-loss-weight_{dataset_type}_{model_architecture}_{hyperparams[\"opt\"]}'\n",
    "        writer = SummaryWriter(f'runs/{model_name}')\n",
    "    \n",
    "        test_abs = int(len(train_dataset) * 0.8)\n",
    "        train_subset, val_subset = random_split(\n",
    "            train_dataset, [test_abs, len(train_dataset) - test_abs])\n",
    "        \n",
    "        train_data_size = len(train_subset)\n",
    "        \n",
    "        # Create DataLoader instances for training and validation\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_subset,\n",
    "            batch_size=hyperparams[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            num_workers=0)\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_subset,\n",
    "            batch_size=hyperparams[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            num_workers=0)\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=hyperparams[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            num_workers=0)\n",
    "        \n",
    "        # Model initialization\n",
    "        model = CNN() if model_architecture == 'CNN' else CNN_ST()\n",
    "        model.to(device)\n",
    "        \n",
    "        # Define loss function, optimizer, etc.\n",
    "        # class_weights = class_weights.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Set optimizers\n",
    "        if hyperparams['opt'] == 'sgd':\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=hyperparams[\"learning_rate\"], momentum=hyperparams[\"momentum\"],\n",
    "                                        weight_decay=hyperparams[\"weight_decay\"])\n",
    "        elif hyperparams['opt'] == 'adam':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams[\"learning_rate\"],\n",
    "                                         betas=(hyperparams[\"beta_1\"], hyperparams[\"beta_2\"]), eps=hyperparams[\"eps\"],\n",
    "                                         weight_decay=hyperparams[\"weight_decay\"])\n",
    "        elif hyperparams['opt'] == 'rmsprop':\n",
    "            optimizer = torch.optim.RMSprop(model.parameters(), lr=hyperparams[\"learning_rate\"])\n",
    "        else:\n",
    "            raise ValueError('Invalid optimizer provided')\n",
    "        scheduler = lr_scheduler.LinearLR(optimizer)\n",
    "        \n",
    "        # Train model\n",
    "        trained_model = train_model(device=device, model=model, criterion=criterion, optimizer=optimizer, scheduler=scheduler,\n",
    "                                    train_loader=train_loader, val_loader=val_loader, num_epochs=hyperparams[\"num_epochs\"],\n",
    "                                    model_name=model_name)\n",
    "        \n",
    "        ta = test_model(trained_model=trained_model, test_loader=test_loader)\n",
    "        \n",
    "        writer.add_hparams({key: str(value) if isinstance(value, list) else value for key, value in hyperparams.items()},\n",
    "                       metric_dict={'Training/Test Accuracy': ta})\n",
    "        print(f'Finished Training {model_name}')\n",
    "        torch.save(trained_model, f'./models/trained_model_{model_name}_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tzJPf39GWxB9",
   "metadata": {
    "id": "tzJPf39GWxB9"
   },
   "source": [
    "# Zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "OL41g_-KDYWe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:16:21.422785Z",
     "start_time": "2024-06-27T19:16:21.422695Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OL41g_-KDYWe",
    "outputId": "88276013-7cd0-49f9-a20a-3a7e5391a36d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: runs/ (stored 0%)\n",
      "  adding: runs/W_CNN_sgd/ (stored 0%)\n",
      "  adding: runs/W_CNN_sgd/events.out.tfevents.1719563872.39cd9eb4b40e.243.8 (deflated 15%)\n",
      "  adding: runs/W_CNN_sgd/1719564675.3643107/ (stored 0%)\n",
      "  adding: runs/W_CNN_sgd/1719564675.3643107/events.out.tfevents.1719564675.39cd9eb4b40e.243.9 (deflated 34%)\n",
      "  adding: runs/no-loss-weight_P_CNN_ST_adam/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_P_CNN_ST_adam/1719767924.08928/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_P_CNN_ST_adam/1719767924.08928/events.out.tfevents.1719767924.toldo-MS-7A62.4457.7 (deflated 35%)\n",
      "  adding: runs/no-loss-weight_P_CNN_ST_adam/events.out.tfevents.1719767009.toldo-MS-7A62.4457.6 (deflated 14%)\n",
      "  adding: runs/W_CNN_ST_adam/ (stored 0%)\n",
      "  adding: runs/W_CNN_ST_adam/events.out.tfevents.1719577200.toldo-Victus.16359.0 (deflated 14%)\n",
      "  adding: runs/W_CNN_ST_adam/1719578451.8710594/ (stored 0%)\n",
      "  adding: runs/W_CNN_ST_adam/1719578451.8710594/events.out.tfevents.1719578451.toldo-Victus.16359.1 (deflated 34%)\n",
      "  adding: runs/no-loss-weight_P_CNN_sgd/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_P_CNN_sgd/1719765461.0344858/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_P_CNN_sgd/1719765461.0344858/events.out.tfevents.1719765461.toldo-MS-7A62.4457.1 (deflated 34%)\n",
      "  adding: runs/no-loss-weight_P_CNN_sgd/events.out.tfevents.1719763944.toldo-MS-7A62.35218.0 (deflated 67%)\n",
      "  adding: runs/no-loss-weight_P_CNN_sgd/events.out.tfevents.1719764814.toldo-MS-7A62.4457.0 (deflated 14%)\n",
      "  adding: runs/no-loss-weight_P_CNN_ST_sgd/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_P_CNN_ST_sgd/1719767008.9580157/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_P_CNN_ST_sgd/1719767008.9580157/events.out.tfevents.1719767008.toldo-MS-7A62.4457.5 (deflated 35%)\n",
      "  adding: runs/no-loss-weight_P_CNN_ST_sgd/events.out.tfevents.1719766119.toldo-MS-7A62.4457.4 (deflated 14%)\n",
      "  adding: runs/W_ResNet50_Adam/ (stored 0%)\n",
      "  adding: runs/W_ResNet50_Adam/events.out.tfevents.1719662370.d4ff53c2a257.197.3 (deflated 3%)\n",
      "  adding: runs/W_ResNet50_Adam/1719665573.8164225/ (stored 0%)\n",
      "  adding: runs/W_ResNet50_Adam/1719665573.8164225/events.out.tfevents.1719665573.d4ff53c2a257.197.4 (deflated 32%)\n",
      "  adding: runs/P_CNN_ST_adam/ (stored 0%)\n",
      "  adding: runs/P_CNN_ST_adam/events.out.tfevents.1719562721.39cd9eb4b40e.243.6 (deflated 14%)\n",
      "  adding: runs/P_CNN_ST_adam/1719563853.8960962/ (stored 0%)\n",
      "  adding: runs/P_CNN_ST_adam/1719563853.8960962/events.out.tfevents.1719563853.39cd9eb4b40e.243.7 (deflated 35%)\n",
      "  adding: runs/P_CNN_ST_sgd/ (stored 0%)\n",
      "  adding: runs/P_CNN_ST_sgd/events.out.tfevents.1719561617.39cd9eb4b40e.243.4 (deflated 14%)\n",
      "  adding: runs/P_CNN_ST_sgd/1719562721.8635318/ (stored 0%)\n",
      "  adding: runs/P_CNN_ST_sgd/1719562721.8635318/events.out.tfevents.1719562721.39cd9eb4b40e.243.5 (deflated 35%)\n",
      "  adding: runs/P_ResNet50FN_Adam/ (stored 0%)\n",
      "  adding: runs/P_ResNet50FN_Adam/1719670290.417198/ (stored 0%)\n",
      "  adding: runs/P_ResNet50FN_Adam/1719670290.417198/events.out.tfevents.1719670290.883c3da72eae.809.1 (deflated 32%)\n",
      "  adding: runs/P_ResNet50FN_Adam/events.out.tfevents.1719666305.883c3da72eae.809.0 (deflated 2%)\n",
      "  adding: runs/P_ResNet50_Adam/ (stored 0%)\n",
      "  adding: runs/P_ResNet50_Adam/1719661260.2112327/ (stored 0%)\n",
      "  adding: runs/P_ResNet50_Adam/1719661260.2112327/events.out.tfevents.1719661260.d4ff53c2a257.197.1 (deflated 32%)\n",
      "  adding: runs/P_ResNet50_Adam/events.out.tfevents.1719657983.d4ff53c2a257.197.0 (deflated 2%)\n",
      "  adding: runs/no-loss-weight_W_CNN_ST_adam/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_W_CNN_ST_adam/events.out.tfevents.1719770457.toldo-MS-7A62.4457.14 (deflated 15%)\n",
      "  adding: runs/no-loss-weight_W_CNN_ST_adam/1719771372.3582761/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_W_CNN_ST_adam/1719771372.3582761/events.out.tfevents.1719771372.toldo-MS-7A62.4457.15 (deflated 35%)\n",
      "  adding: runs/P_CNN_adam/ (stored 0%)\n",
      "  adding: runs/P_CNN_adam/events.out.tfevents.1719560792.39cd9eb4b40e.243.2 (deflated 14%)\n",
      "  adding: runs/P_CNN_adam/1719561601.8377876/ (stored 0%)\n",
      "  adding: runs/P_CNN_adam/1719561601.8377876/events.out.tfevents.1719561601.39cd9eb4b40e.243.3 (deflated 34%)\n",
      "  adding: runs/W_CNN_ST_sgd/ (stored 0%)\n",
      "  adding: runs/W_CNN_ST_sgd/1719566649.7252536/ (stored 0%)\n",
      "  adding: runs/W_CNN_ST_sgd/1719566649.7252536/events.out.tfevents.1719566649.39cd9eb4b40e.243.13 (deflated 34%)\n",
      "  adding: runs/W_CNN_ST_sgd/events.out.tfevents.1719565519.39cd9eb4b40e.243.12 (deflated 15%)\n",
      "  adding: runs/W_CNN_adam/ (stored 0%)\n",
      "  adding: runs/W_CNN_adam/events.out.tfevents.1719564675.39cd9eb4b40e.243.10 (deflated 15%)\n",
      "  adding: runs/W_CNN_adam/1719565503.6744998/ (stored 0%)\n",
      "  adding: runs/W_CNN_adam/1719565503.6744998/events.out.tfevents.1719565503.39cd9eb4b40e.243.11 (deflated 34%)\n",
      "  adding: runs/no-loss-weight_W_CNN_sgd/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_W_CNN_sgd/1719768570.633684/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_W_CNN_sgd/1719768570.633684/events.out.tfevents.1719768570.toldo-MS-7A62.4457.9 (deflated 35%)\n",
      "  adding: runs/no-loss-weight_W_CNN_sgd/events.out.tfevents.1719767932.toldo-MS-7A62.4457.8 (deflated 15%)\n",
      "  adding: runs/no-loss-weight_W_CNN_adam/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_W_CNN_adam/1719769222.1507816/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_W_CNN_adam/1719769222.1507816/events.out.tfevents.1719769222.toldo-MS-7A62.4457.11 (deflated 35%)\n",
      "  adding: runs/no-loss-weight_W_CNN_adam/events.out.tfevents.1719768570.toldo-MS-7A62.4457.10 (deflated 14%)\n",
      "  adding: runs/P_CNN_sgd/ (stored 0%)\n",
      "  adding: runs/P_CNN_sgd/events.out.tfevents.1719559992.39cd9eb4b40e.243.0 (deflated 14%)\n",
      "  adding: runs/P_CNN_sgd/1719560792.5622551/ (stored 0%)\n",
      "  adding: runs/P_CNN_sgd/1719560792.5622551/events.out.tfevents.1719560792.39cd9eb4b40e.243.1 (deflated 35%)\n",
      "  adding: runs/no-loss-weight_W_CNN_ST_sgd/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_W_CNN_ST_sgd/events.out.tfevents.1719769231.toldo-MS-7A62.4457.12 (deflated 15%)\n",
      "  adding: runs/no-loss-weight_W_CNN_ST_sgd/1719770457.1687884/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_W_CNN_ST_sgd/1719770457.1687884/events.out.tfevents.1719770457.toldo-MS-7A62.4457.13 (deflated 34%)\n",
      "  adding: runs/no-loss-weight_P_CNN_adam/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_P_CNN_adam/events.out.tfevents.1719765461.toldo-MS-7A62.4457.2 (deflated 14%)\n",
      "  adding: runs/no-loss-weight_P_CNN_adam/1719766111.4240127/ (stored 0%)\n",
      "  adding: runs/no-loss-weight_P_CNN_adam/1719766111.4240127/events.out.tfevents.1719766111.toldo-MS-7A62.4457.3 (deflated 35%)\n",
      "  adding: runs/W_ResNet50FN_Adam/ (stored 0%)\n",
      "  adding: runs/W_ResNet50FN_Adam/events.out.tfevents.1719665913.d4ff53c2a257.197.5 (deflated 3%)\n",
      "  adding: runs/W_ResNet50FN_Adam/1719669590.7512825/ (stored 0%)\n",
      "  adding: runs/W_ResNet50FN_Adam/1719669590.7512825/events.out.tfevents.1719669590.d4ff53c2a257.197.6 (deflated 32%)\n",
      "  adding: models/ (stored 0%)\n",
      "  adding: models/trained_model_no-loss-weight_P_CNN_ST_adam_final.pth (deflated 8%)\n",
      "  adding: models/trained_model_no-loss-weight_W_CNN_sgd_final.pth (deflated 8%)\n",
      "  adding: models/trained_model_no-loss-weight_W_CNN_adam_final.pth (deflated 8%)\n",
      "  adding: models/trained_model_no-loss-weight_P_CNN_ST_sgd_final.pth (deflated 8%)\n",
      "  adding: models/trained_model_no-loss-weight_P_CNN_sgd_final.pth (deflated 8%)\n",
      "  adding: models/trained_model_no-loss-weight_W_CNN_ST_sgd_final.pth (deflated 8%)\n",
      "  adding: models/trained_model_no-loss-weight_W_CNN_ST_adam_final.pth (deflated 8%)\n",
      "  adding: models/trained_model_no-loss-weight_P_CNN_adam_final.pth (deflated 8%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r runs.zip runs\n",
    "!zip -r models.zip models"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
