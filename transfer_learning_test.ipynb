{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "95feb99553e5f381"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-30T15:48:21.582175Z",
     "start_time": "2024-04-30T15:48:21.578997Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n"
   ],
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setting device for the computation",
   "id": "f26a8210e0afc41d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:48:21.598642Z",
     "start_time": "2024-04-30T15:48:21.596205Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "2c3071b3341a7e3e",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Resizing all the images to the same size",
   "id": "34b616576f3daeb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:48:21.615811Z",
     "start_time": "2024-04-30T15:48:21.612877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "        #TODO:think a better transformation pipeline\n",
    "        #naive transformation\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "        #TODO:think a better transformation pipeline\n",
    "        #naive transformation\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ],
   "id": "50d7d9e3cbf71956",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading the train dataset",
   "id": "1e0e1c4761d44bcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:48:21.693960Z",
     "start_time": "2024-04-30T15:48:21.616846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dir='./dataset/GTSRB/train'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir,train_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1000,shuffle=True, num_workers=4)\n",
    "\n",
    "train_total_steps = len(train_loader)\n",
    "train_size = len(train_dataset)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "print('Total steps for training:',train_total_steps)\n",
    "print('Train size:',train_size)\n",
    "print('Class names:',class_names)"
   ],
   "id": "233a264dd2428bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps for training: 40\n",
      "Train size: 39209\n",
      "Class names: ['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00015', '00016', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042']\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1239b390bd17bb84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading the test dataset",
   "id": "8199467383be87c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:51:17.507390Z",
     "start_time": "2024-04-30T15:51:17.482141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dir='./dataset/GTSRB/test'\n",
    "\n",
    "test_dataset = datasets.ImageFolder(test_dir,test_transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, num_workers=0)\n",
    "\n",
    "test_size = len(test_dataset)\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "print('Test size:',train_size)\n",
    "print('Class names:',class_names)"
   ],
   "id": "4757b88147ac3fbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 39209\n",
      "Class names: ['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00015', '00016', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042']\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining the training phase",
   "id": "3191a2bde55202e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:48:21.728398Z",
     "start_time": "2024-04-30T15:48:21.723447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        #iterates over the batches\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            # forward pass\n",
    "            outputs = model(images) #compute predictions\n",
    "            _, preds = torch.max(outputs, 1) #maximum value along dimension 1\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward + optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #prints the stats every 20 steps (20 batches performed)\n",
    "            if (i+1) % 10 == 0:\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{train_total_steps}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "            # statistics\n",
    "            running_loss += loss.item() * images.size(0) # scalar loss * n.of samples in the batch: necessary to average the loss over the batch\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            #to update weights\n",
    "            # scheduler.step()\n",
    "    \n",
    "        epoch_loss = running_loss / train_size\n",
    "        epoch_acc = running_corrects.double() / train_size\n",
    "    \n",
    "        print('{} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            'Train phase - ',epoch, epoch_loss, epoch_acc))\n",
    "    \n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model"
   ],
   "id": "d1388a73ca0b9760",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining the model using ResNet18 as backbone",
   "id": "6a9c4fc45c415b8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:49:52.655667Z",
     "start_time": "2024-04-30T15:48:21.729921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "#### ConvNet as fixed feature extractor ####\n",
    "# freeze all the network parameters except the final layer settings, to not compute the gradients backward\n",
    "model_conv = torchvision.models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "# Define the layers you want to add\n",
    "additional_layers = nn.Sequential(\n",
    "    # nn.Linear(num_ftrs, 100),  # Example additional layer with 100 units\n",
    "    # nn.ReLU(),                  # Activation function\n",
    "    # nn.Linear(100, 100),         # Another layer with 50 units\n",
    "    # nn.ReLU(),\n",
    "    nn.Linear(num_ftrs, 43)\n",
    ")\n",
    "model_conv.fc = additional_layers\n",
    "\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized\n",
    "optimizer_conv = torch.optim.Adam(model_conv.fc.parameters(), lr=0.05)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                        exp_lr_scheduler, num_epochs=20)"
   ],
   "id": "731771455515444c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "Epoch [1/20], Step [10/40], Loss: 24.4728\n",
      "Epoch [1/20], Step [20/40], Loss: 11.7694\n",
      "Epoch [1/20], Step [30/40], Loss: 5.0185\n",
      "Epoch [1/20], Step [40/40], Loss: 3.2709\n",
      "Train phase -  Epoch 0 Loss: 13.3178 Acc: 0.3215\n",
      "Epoch 1/19\n",
      "----------\n",
      "Epoch [2/20], Step [10/40], Loss: 1.7734\n",
      "Epoch [2/20], Step [20/40], Loss: 1.5437\n",
      "Epoch [2/20], Step [30/40], Loss: 1.4148\n",
      "Epoch [2/20], Step [40/40], Loss: 1.6063\n",
      "Train phase -  Epoch 1 Loss: 1.6797 Acc: 0.6582\n",
      "Epoch 2/19\n",
      "----------\n",
      "Epoch [3/20], Step [10/40], Loss: 1.0736\n",
      "Epoch [3/20], Step [20/40], Loss: 0.9824\n",
      "Epoch [3/20], Step [30/40], Loss: 0.9941\n",
      "Epoch [3/20], Step [40/40], Loss: 1.2210\n",
      "Train phase -  Epoch 2 Loss: 0.9993 Acc: 0.7278\n",
      "Epoch 3/19\n",
      "----------\n",
      "Epoch [4/20], Step [10/40], Loss: 0.8382\n",
      "Epoch [4/20], Step [20/40], Loss: 0.7618\n",
      "Epoch [4/20], Step [30/40], Loss: 0.7704\n",
      "Epoch [4/20], Step [40/40], Loss: 0.7365\n",
      "Train phase -  Epoch 3 Loss: 0.8145 Acc: 0.7601\n",
      "Epoch 4/19\n",
      "----------\n",
      "Epoch [5/20], Step [10/40], Loss: 0.7612\n",
      "Epoch [5/20], Step [20/40], Loss: 0.8505\n",
      "Epoch [5/20], Step [30/40], Loss: 0.8477\n",
      "Epoch [5/20], Step [40/40], Loss: 0.9950\n",
      "Train phase -  Epoch 4 Loss: 0.8102 Acc: 0.7574\n",
      "Epoch 5/19\n",
      "----------\n",
      "Epoch [6/20], Step [10/40], Loss: 0.7467\n",
      "Epoch [6/20], Step [20/40], Loss: 1.0117\n",
      "Epoch [6/20], Step [30/40], Loss: 0.7388\n",
      "Epoch [6/20], Step [40/40], Loss: 1.0652\n",
      "Train phase -  Epoch 5 Loss: 0.7807 Acc: 0.7695\n",
      "Epoch 6/19\n",
      "----------\n",
      "Epoch [7/20], Step [10/40], Loss: 0.8280\n",
      "Epoch [7/20], Step [20/40], Loss: 0.9126\n",
      "Epoch [7/20], Step [30/40], Loss: 0.8983\n",
      "Epoch [7/20], Step [40/40], Loss: 0.9407\n",
      "Train phase -  Epoch 6 Loss: 0.8293 Acc: 0.7615\n",
      "Epoch 7/19\n",
      "----------\n",
      "Epoch [8/20], Step [10/40], Loss: 0.8850\n",
      "Epoch [8/20], Step [20/40], Loss: 0.7476\n",
      "Epoch [8/20], Step [30/40], Loss: 0.7322\n",
      "Epoch [8/20], Step [40/40], Loss: 0.8686\n",
      "Train phase -  Epoch 7 Loss: 0.8143 Acc: 0.7694\n",
      "Epoch 8/19\n",
      "----------\n",
      "Epoch [9/20], Step [10/40], Loss: 0.7992\n",
      "Epoch [9/20], Step [20/40], Loss: 0.6774\n",
      "Epoch [9/20], Step [30/40], Loss: 0.7361\n",
      "Epoch [9/20], Step [40/40], Loss: 0.9037\n",
      "Train phase -  Epoch 8 Loss: 0.8167 Acc: 0.7701\n",
      "Epoch 9/19\n",
      "----------\n",
      "Epoch [10/20], Step [10/40], Loss: 0.8332\n",
      "Epoch [10/20], Step [20/40], Loss: 0.7058\n",
      "Epoch [10/20], Step [30/40], Loss: 0.9389\n",
      "Epoch [10/20], Step [40/40], Loss: 0.8946\n",
      "Train phase -  Epoch 9 Loss: 0.7833 Acc: 0.7804\n",
      "Epoch 10/19\n",
      "----------\n",
      "Epoch [11/20], Step [10/40], Loss: 0.7246\n",
      "Epoch [11/20], Step [20/40], Loss: 0.8108\n",
      "Epoch [11/20], Step [30/40], Loss: 0.7086\n",
      "Epoch [11/20], Step [40/40], Loss: 1.0159\n",
      "Train phase -  Epoch 10 Loss: 0.7558 Acc: 0.7853\n",
      "Epoch 11/19\n",
      "----------\n",
      "Epoch [12/20], Step [10/40], Loss: 0.8555\n",
      "Epoch [12/20], Step [20/40], Loss: 0.7469\n",
      "Epoch [12/20], Step [30/40], Loss: 0.9963\n",
      "Epoch [12/20], Step [40/40], Loss: 0.9854\n",
      "Train phase -  Epoch 11 Loss: 0.7939 Acc: 0.7798\n",
      "Epoch 12/19\n",
      "----------\n",
      "Epoch [13/20], Step [10/40], Loss: 0.6413\n",
      "Epoch [13/20], Step [20/40], Loss: 0.7300\n",
      "Epoch [13/20], Step [30/40], Loss: 0.6805\n",
      "Epoch [13/20], Step [40/40], Loss: 0.6693\n",
      "Train phase -  Epoch 12 Loss: 0.7251 Acc: 0.7950\n",
      "Epoch 13/19\n",
      "----------\n",
      "Epoch [14/20], Step [10/40], Loss: 0.6267\n",
      "Epoch [14/20], Step [20/40], Loss: 0.7844\n",
      "Epoch [14/20], Step [30/40], Loss: 0.7955\n",
      "Epoch [14/20], Step [40/40], Loss: 1.0264\n",
      "Train phase -  Epoch 13 Loss: 0.7437 Acc: 0.7918\n",
      "Epoch 14/19\n",
      "----------\n",
      "Epoch [15/20], Step [10/40], Loss: 0.7385\n",
      "Epoch [15/20], Step [20/40], Loss: 0.8554\n",
      "Epoch [15/20], Step [30/40], Loss: 0.9108\n",
      "Epoch [15/20], Step [40/40], Loss: 1.0805\n",
      "Train phase -  Epoch 14 Loss: 0.8182 Acc: 0.7822\n",
      "Epoch 15/19\n",
      "----------\n",
      "Epoch [16/20], Step [10/40], Loss: 0.8999\n",
      "Epoch [16/20], Step [20/40], Loss: 0.7652\n",
      "Epoch [16/20], Step [30/40], Loss: 0.8018\n",
      "Epoch [16/20], Step [40/40], Loss: 0.8658\n",
      "Train phase -  Epoch 15 Loss: 0.7795 Acc: 0.7910\n",
      "Epoch 16/19\n",
      "----------\n",
      "Epoch [17/20], Step [10/40], Loss: 0.7839\n",
      "Epoch [17/20], Step [20/40], Loss: 0.8248\n",
      "Epoch [17/20], Step [30/40], Loss: 1.0121\n",
      "Epoch [17/20], Step [40/40], Loss: 0.9225\n",
      "Train phase -  Epoch 16 Loss: 0.7886 Acc: 0.7909\n",
      "Epoch 17/19\n",
      "----------\n",
      "Epoch [18/20], Step [10/40], Loss: 1.0028\n",
      "Epoch [18/20], Step [20/40], Loss: 0.8613\n",
      "Epoch [18/20], Step [30/40], Loss: 0.8360\n",
      "Epoch [18/20], Step [40/40], Loss: 0.8997\n",
      "Train phase -  Epoch 17 Loss: 0.8343 Acc: 0.7834\n",
      "Epoch 18/19\n",
      "----------\n",
      "Epoch [19/20], Step [10/40], Loss: 0.7057\n",
      "Epoch [19/20], Step [20/40], Loss: 0.8286\n",
      "Epoch [19/20], Step [30/40], Loss: 0.8520\n",
      "Epoch [19/20], Step [40/40], Loss: 0.9479\n",
      "Train phase -  Epoch 18 Loss: 0.7871 Acc: 0.7933\n",
      "Epoch 19/19\n",
      "----------\n",
      "Epoch [20/20], Step [10/40], Loss: 0.7338\n",
      "Epoch [20/20], Step [20/40], Loss: 0.7814\n",
      "Epoch [20/20], Step [30/40], Loss: 0.9104\n",
      "Epoch [20/20], Step [40/40], Loss: 1.0041\n",
      "Train phase -  Epoch 19 Loss: 0.8133 Acc: 0.7902\n",
      "\n",
      "Training complete in 1m 31s\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Saving the trained model",
   "id": "e4d9605ef361a0d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:49:52.776746Z",
     "start_time": "2024-04-30T15:49:52.656730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Finished Training')\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "PATH = './models/trained_model.pth'\n",
    "torch.save(model_conv, PATH)"
   ],
   "id": "9f5f26cdefec21bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading the model",
   "id": "6f3fea444bec58bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:49:52.809702Z",
     "start_time": "2024-04-30T15:49:52.777842Z"
    }
   },
   "cell_type": "code",
   "source": "trained_model=torch.load('./models/trained_model.pth',map_location=device)",
   "id": "fb1aa946a282ac0f",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluating the model",
   "id": "9e3a434c2806a2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:51:57.046633Z",
     "start_time": "2024-04-30T15:51:57.042941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, dataloader, dataset_size):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "            # Statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if (i+1) % 50 == 0:\n",
    "                print ( f'Evaluating: [{i+1}/{test_size}]')\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_acc = running_corrects.double() / dataset_size\n",
    "\n",
    "    print('Test Acc: {:.4f}'.format( test_acc))\n",
    "    "
   ],
   "id": "6488b43f7e58c5d",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:52:27.324283Z",
     "start_time": "2024-04-30T15:51:57.514422Z"
    }
   },
   "cell_type": "code",
   "source": "test_model(trained_model, test_loader, test_size)",
   "id": "5b3a78850fc2ef92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: [50/12630]\n",
      "Evaluating: [100/12630]\n",
      "Evaluating: [150/12630]\n",
      "Evaluating: [200/12630]\n",
      "Evaluating: [250/12630]\n",
      "Evaluating: [300/12630]\n",
      "Evaluating: [350/12630]\n",
      "Evaluating: [400/12630]\n",
      "Evaluating: [450/12630]\n",
      "Evaluating: [500/12630]\n",
      "Evaluating: [550/12630]\n",
      "Evaluating: [600/12630]\n",
      "Evaluating: [650/12630]\n",
      "Evaluating: [700/12630]\n",
      "Evaluating: [750/12630]\n",
      "Evaluating: [800/12630]\n",
      "Evaluating: [850/12630]\n",
      "Evaluating: [900/12630]\n",
      "Evaluating: [950/12630]\n",
      "Evaluating: [1000/12630]\n",
      "Evaluating: [1050/12630]\n",
      "Evaluating: [1100/12630]\n",
      "Evaluating: [1150/12630]\n",
      "Evaluating: [1200/12630]\n",
      "Evaluating: [1250/12630]\n",
      "Evaluating: [1300/12630]\n",
      "Evaluating: [1350/12630]\n",
      "Evaluating: [1400/12630]\n",
      "Evaluating: [1450/12630]\n",
      "Evaluating: [1500/12630]\n",
      "Evaluating: [1550/12630]\n",
      "Evaluating: [1600/12630]\n",
      "Evaluating: [1650/12630]\n",
      "Evaluating: [1700/12630]\n",
      "Evaluating: [1750/12630]\n",
      "Evaluating: [1800/12630]\n",
      "Evaluating: [1850/12630]\n",
      "Evaluating: [1900/12630]\n",
      "Evaluating: [1950/12630]\n",
      "Evaluating: [2000/12630]\n",
      "Evaluating: [2050/12630]\n",
      "Evaluating: [2100/12630]\n",
      "Evaluating: [2150/12630]\n",
      "Evaluating: [2200/12630]\n",
      "Evaluating: [2250/12630]\n",
      "Evaluating: [2300/12630]\n",
      "Evaluating: [2350/12630]\n",
      "Evaluating: [2400/12630]\n",
      "Evaluating: [2450/12630]\n",
      "Evaluating: [2500/12630]\n",
      "Evaluating: [2550/12630]\n",
      "Evaluating: [2600/12630]\n",
      "Evaluating: [2650/12630]\n",
      "Evaluating: [2700/12630]\n",
      "Evaluating: [2750/12630]\n",
      "Evaluating: [2800/12630]\n",
      "Evaluating: [2850/12630]\n",
      "Evaluating: [2900/12630]\n",
      "Evaluating: [2950/12630]\n",
      "Evaluating: [3000/12630]\n",
      "Evaluating: [3050/12630]\n",
      "Evaluating: [3100/12630]\n",
      "Evaluating: [3150/12630]\n",
      "Evaluating: [3200/12630]\n",
      "Evaluating: [3250/12630]\n",
      "Evaluating: [3300/12630]\n",
      "Evaluating: [3350/12630]\n",
      "Evaluating: [3400/12630]\n",
      "Evaluating: [3450/12630]\n",
      "Evaluating: [3500/12630]\n",
      "Evaluating: [3550/12630]\n",
      "Evaluating: [3600/12630]\n",
      "Evaluating: [3650/12630]\n",
      "Evaluating: [3700/12630]\n",
      "Evaluating: [3750/12630]\n",
      "Evaluating: [3800/12630]\n",
      "Evaluating: [3850/12630]\n",
      "Evaluating: [3900/12630]\n",
      "Evaluating: [3950/12630]\n",
      "Evaluating: [4000/12630]\n",
      "Evaluating: [4050/12630]\n",
      "Evaluating: [4100/12630]\n",
      "Evaluating: [4150/12630]\n",
      "Evaluating: [4200/12630]\n",
      "Evaluating: [4250/12630]\n",
      "Evaluating: [4300/12630]\n",
      "Evaluating: [4350/12630]\n",
      "Evaluating: [4400/12630]\n",
      "Evaluating: [4450/12630]\n",
      "Evaluating: [4500/12630]\n",
      "Evaluating: [4550/12630]\n",
      "Evaluating: [4600/12630]\n",
      "Evaluating: [4650/12630]\n",
      "Evaluating: [4700/12630]\n",
      "Evaluating: [4750/12630]\n",
      "Evaluating: [4800/12630]\n",
      "Evaluating: [4850/12630]\n",
      "Evaluating: [4900/12630]\n",
      "Evaluating: [4950/12630]\n",
      "Evaluating: [5000/12630]\n",
      "Evaluating: [5050/12630]\n",
      "Evaluating: [5100/12630]\n",
      "Evaluating: [5150/12630]\n",
      "Evaluating: [5200/12630]\n",
      "Evaluating: [5250/12630]\n",
      "Evaluating: [5300/12630]\n",
      "Evaluating: [5350/12630]\n",
      "Evaluating: [5400/12630]\n",
      "Evaluating: [5450/12630]\n",
      "Evaluating: [5500/12630]\n",
      "Evaluating: [5550/12630]\n",
      "Evaluating: [5600/12630]\n",
      "Evaluating: [5650/12630]\n",
      "Evaluating: [5700/12630]\n",
      "Evaluating: [5750/12630]\n",
      "Evaluating: [5800/12630]\n",
      "Evaluating: [5850/12630]\n",
      "Evaluating: [5900/12630]\n",
      "Evaluating: [5950/12630]\n",
      "Evaluating: [6000/12630]\n",
      "Evaluating: [6050/12630]\n",
      "Evaluating: [6100/12630]\n",
      "Evaluating: [6150/12630]\n",
      "Evaluating: [6200/12630]\n",
      "Evaluating: [6250/12630]\n",
      "Evaluating: [6300/12630]\n",
      "Evaluating: [6350/12630]\n",
      "Evaluating: [6400/12630]\n",
      "Evaluating: [6450/12630]\n",
      "Evaluating: [6500/12630]\n",
      "Evaluating: [6550/12630]\n",
      "Evaluating: [6600/12630]\n",
      "Evaluating: [6650/12630]\n",
      "Evaluating: [6700/12630]\n",
      "Evaluating: [6750/12630]\n",
      "Evaluating: [6800/12630]\n",
      "Evaluating: [6850/12630]\n",
      "Evaluating: [6900/12630]\n",
      "Evaluating: [6950/12630]\n",
      "Evaluating: [7000/12630]\n",
      "Evaluating: [7050/12630]\n",
      "Evaluating: [7100/12630]\n",
      "Evaluating: [7150/12630]\n",
      "Evaluating: [7200/12630]\n",
      "Evaluating: [7250/12630]\n",
      "Evaluating: [7300/12630]\n",
      "Evaluating: [7350/12630]\n",
      "Evaluating: [7400/12630]\n",
      "Evaluating: [7450/12630]\n",
      "Evaluating: [7500/12630]\n",
      "Evaluating: [7550/12630]\n",
      "Evaluating: [7600/12630]\n",
      "Evaluating: [7650/12630]\n",
      "Evaluating: [7700/12630]\n",
      "Evaluating: [7750/12630]\n",
      "Evaluating: [7800/12630]\n",
      "Evaluating: [7850/12630]\n",
      "Evaluating: [7900/12630]\n",
      "Evaluating: [7950/12630]\n",
      "Evaluating: [8000/12630]\n",
      "Evaluating: [8050/12630]\n",
      "Evaluating: [8100/12630]\n",
      "Evaluating: [8150/12630]\n",
      "Evaluating: [8200/12630]\n",
      "Evaluating: [8250/12630]\n",
      "Evaluating: [8300/12630]\n",
      "Evaluating: [8350/12630]\n",
      "Evaluating: [8400/12630]\n",
      "Evaluating: [8450/12630]\n",
      "Evaluating: [8500/12630]\n",
      "Evaluating: [8550/12630]\n",
      "Evaluating: [8600/12630]\n",
      "Evaluating: [8650/12630]\n",
      "Evaluating: [8700/12630]\n",
      "Evaluating: [8750/12630]\n",
      "Evaluating: [8800/12630]\n",
      "Evaluating: [8850/12630]\n",
      "Evaluating: [8900/12630]\n",
      "Evaluating: [8950/12630]\n",
      "Evaluating: [9000/12630]\n",
      "Evaluating: [9050/12630]\n",
      "Evaluating: [9100/12630]\n",
      "Evaluating: [9150/12630]\n",
      "Evaluating: [9200/12630]\n",
      "Evaluating: [9250/12630]\n",
      "Evaluating: [9300/12630]\n",
      "Evaluating: [9350/12630]\n",
      "Evaluating: [9400/12630]\n",
      "Evaluating: [9450/12630]\n",
      "Evaluating: [9500/12630]\n",
      "Evaluating: [9550/12630]\n",
      "Evaluating: [9600/12630]\n",
      "Evaluating: [9650/12630]\n",
      "Evaluating: [9700/12630]\n",
      "Evaluating: [9750/12630]\n",
      "Evaluating: [9800/12630]\n",
      "Evaluating: [9850/12630]\n",
      "Evaluating: [9900/12630]\n",
      "Evaluating: [9950/12630]\n",
      "Evaluating: [10000/12630]\n",
      "Evaluating: [10050/12630]\n",
      "Evaluating: [10100/12630]\n",
      "Evaluating: [10150/12630]\n",
      "Evaluating: [10200/12630]\n",
      "Evaluating: [10250/12630]\n",
      "Evaluating: [10300/12630]\n",
      "Evaluating: [10350/12630]\n",
      "Evaluating: [10400/12630]\n",
      "Evaluating: [10450/12630]\n",
      "Evaluating: [10500/12630]\n",
      "Evaluating: [10550/12630]\n",
      "Evaluating: [10600/12630]\n",
      "Evaluating: [10650/12630]\n",
      "Evaluating: [10700/12630]\n",
      "Evaluating: [10750/12630]\n",
      "Evaluating: [10800/12630]\n",
      "Evaluating: [10850/12630]\n",
      "Evaluating: [10900/12630]\n",
      "Evaluating: [10950/12630]\n",
      "Evaluating: [11000/12630]\n",
      "Evaluating: [11050/12630]\n",
      "Evaluating: [11100/12630]\n",
      "Evaluating: [11150/12630]\n",
      "Evaluating: [11200/12630]\n",
      "Evaluating: [11250/12630]\n",
      "Evaluating: [11300/12630]\n",
      "Evaluating: [11350/12630]\n",
      "Evaluating: [11400/12630]\n",
      "Evaluating: [11450/12630]\n",
      "Evaluating: [11500/12630]\n",
      "Evaluating: [11550/12630]\n",
      "Evaluating: [11600/12630]\n",
      "Evaluating: [11650/12630]\n",
      "Evaluating: [11700/12630]\n",
      "Evaluating: [11750/12630]\n",
      "Evaluating: [11800/12630]\n",
      "Evaluating: [11850/12630]\n",
      "Evaluating: [11900/12630]\n",
      "Evaluating: [11950/12630]\n",
      "Evaluating: [12000/12630]\n",
      "Evaluating: [12050/12630]\n",
      "Evaluating: [12100/12630]\n",
      "Evaluating: [12150/12630]\n",
      "Evaluating: [12200/12630]\n",
      "Evaluating: [12250/12630]\n",
      "Evaluating: [12300/12630]\n",
      "Evaluating: [12350/12630]\n",
      "Evaluating: [12400/12630]\n",
      "Evaluating: [12450/12630]\n",
      "Evaluating: [12500/12630]\n",
      "Evaluating: [12550/12630]\n",
      "Evaluating: [12600/12630]\n",
      "Test Acc: 0.5025\n"
     ]
    }
   ],
   "execution_count": 132
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
