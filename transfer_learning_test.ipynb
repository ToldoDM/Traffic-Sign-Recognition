{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "95feb99553e5f381"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-28T14:33:11.375240Z",
     "start_time": "2024-04-28T14:33:11.352629Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n"
   ],
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set device",
   "id": "f26a8210e0afc41d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T08:56:00.323679Z",
     "start_time": "2024-04-28T08:56:00.305969Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "2c3071b3341a7e3e",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training dataset",
   "id": "179809bcd90eb62a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T08:56:00.331966Z",
     "start_time": "2024-04-28T08:56:00.323679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_transform = transforms.Compose([\n",
    "        #TODO:think a better transformation pipeline\n",
    "        #naive transformation\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ],
   "id": "50d7d9e3cbf71956",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:45:18.368026Z",
     "start_time": "2024-04-28T14:45:16.201030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dir='./dataset/GTSRB/train/original'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir,data_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=200,shuffle=True, num_workers=0)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "train_size = len(train_dataset)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "print(class_names)"
   ],
   "id": "233a264dd2428bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00015', '00016', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042']\n"
     ]
    }
   ],
   "execution_count": 168
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test dataset",
   "id": "8199467383be87c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:45:30.035859Z",
     "start_time": "2024-04-28T14:45:29.909835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dir='./dataset/GTSRB/test'\n",
    "\n",
    "test_dataset = datasets.ImageFolder(test_dir,data_transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,shuffle=True, num_workers=0)\n",
    "\n",
    "test_size = len(test_dataset)\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "print(class_names)"
   ],
   "id": "4757b88147ac3fbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00015', '00016', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042']\n"
     ]
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining the training",
   "id": "3191a2bde55202e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:45:33.994798Z",
     "start_time": "2024-04-28T14:45:33.978012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward + optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 20 == 0:\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "            # statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            #to update weights\n",
    "            scheduler.step()\n",
    "    \n",
    "        epoch_loss = running_loss / train_size\n",
    "        epoch_acc = running_corrects.double() / train_size\n",
    "    \n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            'train', epoch_loss, epoch_acc))\n",
    "    \n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model"
   ],
   "id": "d1388a73ca0b9760",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining the model using ResNet18 as backbone",
   "id": "6a9c4fc45c415b8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T10:12:57.995214Z",
     "start_time": "2024-04-28T08:56:00.674266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#### ConvNet as fixed feature extractor ####\n",
    "# freeze all the network parameters except the final layer settings, to not compute the gradients backward\n",
    "model_conv = torchvision.models.resnet18(weights=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 43)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as opposed to before.\n",
    "optimizer_conv = torch.optim.Adam(model_conv.fc.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                        exp_lr_scheduler, num_epochs=20)"
   ],
   "id": "731771455515444c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "Epoch [1/20], Step [20/197], Loss: 2.5146\n",
      "Epoch [1/20], Step [40/197], Loss: 2.3447\n",
      "Epoch [1/20], Step [60/197], Loss: 2.4745\n",
      "Epoch [1/20], Step [80/197], Loss: 2.5187\n",
      "Epoch [1/20], Step [100/197], Loss: 2.5092\n",
      "Epoch [1/20], Step [120/197], Loss: 2.1257\n",
      "Epoch [1/20], Step [140/197], Loss: 2.5073\n",
      "Epoch [1/20], Step [160/197], Loss: 2.3934\n",
      "Epoch [1/20], Step [180/197], Loss: 2.2725\n",
      "train Loss: 2.5088 Acc: 0.3567\n",
      "Epoch 1/19\n",
      "----------\n",
      "Epoch [2/20], Step [20/197], Loss: 2.4934\n",
      "Epoch [2/20], Step [40/197], Loss: 2.3936\n",
      "Epoch [2/20], Step [60/197], Loss: 2.2139\n",
      "Epoch [2/20], Step [80/197], Loss: 2.4036\n",
      "Epoch [2/20], Step [100/197], Loss: 2.1705\n",
      "Epoch [2/20], Step [120/197], Loss: 2.1302\n",
      "Epoch [2/20], Step [140/197], Loss: 2.1465\n",
      "Epoch [2/20], Step [160/197], Loss: 2.4035\n",
      "Epoch [2/20], Step [180/197], Loss: 2.5734\n",
      "train Loss: 2.4159 Acc: 0.3720\n",
      "Epoch 2/19\n",
      "----------\n",
      "Epoch [3/20], Step [20/197], Loss: 2.6098\n",
      "Epoch [3/20], Step [40/197], Loss: 2.6668\n",
      "Epoch [3/20], Step [60/197], Loss: 2.4126\n",
      "Epoch [3/20], Step [80/197], Loss: 2.4405\n",
      "Epoch [3/20], Step [100/197], Loss: 2.5317\n",
      "Epoch [3/20], Step [120/197], Loss: 2.3792\n",
      "Epoch [3/20], Step [140/197], Loss: 2.5601\n",
      "Epoch [3/20], Step [160/197], Loss: 2.5931\n",
      "Epoch [3/20], Step [180/197], Loss: 2.2559\n",
      "train Loss: 2.4147 Acc: 0.3720\n",
      "Epoch 3/19\n",
      "----------\n",
      "Epoch [4/20], Step [20/197], Loss: 2.2934\n",
      "Epoch [4/20], Step [40/197], Loss: 2.5971\n",
      "Epoch [4/20], Step [60/197], Loss: 2.1953\n",
      "Epoch [4/20], Step [80/197], Loss: 2.4470\n",
      "Epoch [4/20], Step [100/197], Loss: 2.3276\n",
      "Epoch [4/20], Step [120/197], Loss: 2.5019\n",
      "Epoch [4/20], Step [140/197], Loss: 2.3575\n",
      "Epoch [4/20], Step [160/197], Loss: 2.2182\n",
      "Epoch [4/20], Step [180/197], Loss: 2.4192\n",
      "train Loss: 2.4148 Acc: 0.3718\n",
      "Epoch 4/19\n",
      "----------\n",
      "Epoch [5/20], Step [20/197], Loss: 2.3967\n",
      "Epoch [5/20], Step [40/197], Loss: 2.4625\n",
      "Epoch [5/20], Step [60/197], Loss: 2.4789\n",
      "Epoch [5/20], Step [80/197], Loss: 2.6005\n",
      "Epoch [5/20], Step [100/197], Loss: 2.4934\n",
      "Epoch [5/20], Step [120/197], Loss: 2.3923\n",
      "Epoch [5/20], Step [140/197], Loss: 2.5194\n",
      "Epoch [5/20], Step [160/197], Loss: 2.2538\n",
      "Epoch [5/20], Step [180/197], Loss: 2.3509\n",
      "train Loss: 2.4128 Acc: 0.3732\n",
      "Epoch 5/19\n",
      "----------\n",
      "Epoch [6/20], Step [20/197], Loss: 2.4770\n",
      "Epoch [6/20], Step [40/197], Loss: 2.3673\n",
      "Epoch [6/20], Step [60/197], Loss: 2.4526\n",
      "Epoch [6/20], Step [80/197], Loss: 2.5681\n",
      "Epoch [6/20], Step [100/197], Loss: 2.4691\n",
      "Epoch [6/20], Step [120/197], Loss: 2.4669\n",
      "Epoch [6/20], Step [140/197], Loss: 2.3074\n",
      "Epoch [6/20], Step [160/197], Loss: 2.3150\n",
      "Epoch [6/20], Step [180/197], Loss: 2.4043\n",
      "train Loss: 2.4165 Acc: 0.3741\n",
      "Epoch 6/19\n",
      "----------\n",
      "Epoch [7/20], Step [20/197], Loss: 2.4975\n",
      "Epoch [7/20], Step [40/197], Loss: 2.1614\n",
      "Epoch [7/20], Step [60/197], Loss: 2.2130\n",
      "Epoch [7/20], Step [80/197], Loss: 2.2753\n",
      "Epoch [7/20], Step [100/197], Loss: 2.5045\n",
      "Epoch [7/20], Step [120/197], Loss: 2.3088\n",
      "Epoch [7/20], Step [140/197], Loss: 2.3868\n",
      "Epoch [7/20], Step [160/197], Loss: 2.4963\n",
      "Epoch [7/20], Step [180/197], Loss: 2.5089\n",
      "train Loss: 2.4150 Acc: 0.3729\n",
      "Epoch 7/19\n",
      "----------\n",
      "Epoch [8/20], Step [20/197], Loss: 2.3068\n",
      "Epoch [8/20], Step [40/197], Loss: 2.4087\n",
      "Epoch [8/20], Step [60/197], Loss: 2.3291\n",
      "Epoch [8/20], Step [80/197], Loss: 2.4748\n",
      "Epoch [8/20], Step [100/197], Loss: 2.2011\n",
      "Epoch [8/20], Step [120/197], Loss: 2.3950\n",
      "Epoch [8/20], Step [140/197], Loss: 2.4155\n",
      "Epoch [8/20], Step [160/197], Loss: 2.4373\n",
      "Epoch [8/20], Step [180/197], Loss: 2.3742\n",
      "train Loss: 2.4156 Acc: 0.3717\n",
      "Epoch 8/19\n",
      "----------\n",
      "Epoch [9/20], Step [20/197], Loss: 2.4662\n",
      "Epoch [9/20], Step [40/197], Loss: 2.1950\n",
      "Epoch [9/20], Step [60/197], Loss: 2.3225\n",
      "Epoch [9/20], Step [80/197], Loss: 2.3821\n",
      "Epoch [9/20], Step [100/197], Loss: 2.4594\n",
      "Epoch [9/20], Step [120/197], Loss: 2.3072\n",
      "Epoch [9/20], Step [140/197], Loss: 2.6309\n",
      "Epoch [9/20], Step [160/197], Loss: 2.2872\n",
      "Epoch [9/20], Step [180/197], Loss: 2.5145\n",
      "train Loss: 2.4150 Acc: 0.3737\n",
      "Epoch 9/19\n",
      "----------\n",
      "Epoch [10/20], Step [20/197], Loss: 2.4063\n",
      "Epoch [10/20], Step [40/197], Loss: 2.5121\n",
      "Epoch [10/20], Step [60/197], Loss: 2.4950\n",
      "Epoch [10/20], Step [80/197], Loss: 2.6007\n",
      "Epoch [10/20], Step [100/197], Loss: 2.5496\n",
      "Epoch [10/20], Step [120/197], Loss: 2.5382\n",
      "Epoch [10/20], Step [140/197], Loss: 2.1983\n",
      "Epoch [10/20], Step [160/197], Loss: 2.3541\n",
      "Epoch [10/20], Step [180/197], Loss: 2.3152\n",
      "train Loss: 2.4147 Acc: 0.3712\n",
      "Epoch 10/19\n",
      "----------\n",
      "Epoch [11/20], Step [20/197], Loss: 2.5144\n",
      "Epoch [11/20], Step [40/197], Loss: 2.3873\n",
      "Epoch [11/20], Step [60/197], Loss: 2.2384\n",
      "Epoch [11/20], Step [80/197], Loss: 2.3360\n",
      "Epoch [11/20], Step [100/197], Loss: 2.4326\n",
      "Epoch [11/20], Step [120/197], Loss: 2.3247\n",
      "Epoch [11/20], Step [140/197], Loss: 2.4337\n",
      "Epoch [11/20], Step [160/197], Loss: 2.4767\n",
      "Epoch [11/20], Step [180/197], Loss: 2.2636\n",
      "train Loss: 2.4172 Acc: 0.3719\n",
      "Epoch 11/19\n",
      "----------\n",
      "Epoch [12/20], Step [20/197], Loss: 2.4643\n",
      "Epoch [12/20], Step [40/197], Loss: 2.7876\n",
      "Epoch [12/20], Step [60/197], Loss: 2.5113\n",
      "Epoch [12/20], Step [80/197], Loss: 2.3708\n",
      "Epoch [12/20], Step [100/197], Loss: 2.3657\n",
      "Epoch [12/20], Step [120/197], Loss: 2.1410\n",
      "Epoch [12/20], Step [140/197], Loss: 2.4561\n",
      "Epoch [12/20], Step [160/197], Loss: 2.3216\n",
      "Epoch [12/20], Step [180/197], Loss: 2.7488\n",
      "train Loss: 2.4146 Acc: 0.3717\n",
      "Epoch 12/19\n",
      "----------\n",
      "Epoch [13/20], Step [20/197], Loss: 2.1527\n",
      "Epoch [13/20], Step [40/197], Loss: 2.4124\n",
      "Epoch [13/20], Step [60/197], Loss: 2.3907\n",
      "Epoch [13/20], Step [80/197], Loss: 2.2177\n",
      "Epoch [13/20], Step [100/197], Loss: 2.3570\n",
      "Epoch [13/20], Step [120/197], Loss: 2.3419\n",
      "Epoch [13/20], Step [140/197], Loss: 2.3131\n",
      "Epoch [13/20], Step [160/197], Loss: 2.4410\n",
      "Epoch [13/20], Step [180/197], Loss: 2.3969\n",
      "train Loss: 2.4141 Acc: 0.3745\n",
      "Epoch 13/19\n",
      "----------\n",
      "Epoch [14/20], Step [20/197], Loss: 2.2620\n",
      "Epoch [14/20], Step [40/197], Loss: 2.3293\n",
      "Epoch [14/20], Step [60/197], Loss: 2.5347\n",
      "Epoch [14/20], Step [80/197], Loss: 2.5462\n",
      "Epoch [14/20], Step [100/197], Loss: 2.3661\n",
      "Epoch [14/20], Step [120/197], Loss: 2.5702\n",
      "Epoch [14/20], Step [140/197], Loss: 2.3247\n",
      "Epoch [14/20], Step [160/197], Loss: 2.6929\n",
      "Epoch [14/20], Step [180/197], Loss: 2.4329\n",
      "train Loss: 2.4167 Acc: 0.3725\n",
      "Epoch 14/19\n",
      "----------\n",
      "Epoch [15/20], Step [20/197], Loss: 2.4908\n",
      "Epoch [15/20], Step [40/197], Loss: 2.2097\n",
      "Epoch [15/20], Step [60/197], Loss: 2.4203\n",
      "Epoch [15/20], Step [80/197], Loss: 2.5094\n",
      "Epoch [15/20], Step [100/197], Loss: 2.6416\n",
      "Epoch [15/20], Step [120/197], Loss: 2.6156\n",
      "Epoch [15/20], Step [140/197], Loss: 2.1949\n",
      "Epoch [15/20], Step [160/197], Loss: 2.4731\n",
      "Epoch [15/20], Step [180/197], Loss: 2.2425\n",
      "train Loss: 2.4157 Acc: 0.3732\n",
      "Epoch 15/19\n",
      "----------\n",
      "Epoch [16/20], Step [20/197], Loss: 2.3623\n",
      "Epoch [16/20], Step [40/197], Loss: 2.4665\n",
      "Epoch [16/20], Step [60/197], Loss: 2.1884\n",
      "Epoch [16/20], Step [80/197], Loss: 2.3270\n",
      "Epoch [16/20], Step [100/197], Loss: 2.4954\n",
      "Epoch [16/20], Step [120/197], Loss: 2.3373\n",
      "Epoch [16/20], Step [140/197], Loss: 2.4847\n",
      "Epoch [16/20], Step [160/197], Loss: 2.5000\n",
      "Epoch [16/20], Step [180/197], Loss: 2.2906\n",
      "train Loss: 2.4145 Acc: 0.3728\n",
      "Epoch 16/19\n",
      "----------\n",
      "Epoch [17/20], Step [20/197], Loss: 2.4280\n",
      "Epoch [17/20], Step [40/197], Loss: 2.4064\n",
      "Epoch [17/20], Step [60/197], Loss: 2.3093\n",
      "Epoch [17/20], Step [80/197], Loss: 2.3730\n",
      "Epoch [17/20], Step [100/197], Loss: 2.2984\n",
      "Epoch [17/20], Step [120/197], Loss: 2.3921\n",
      "Epoch [17/20], Step [140/197], Loss: 2.2717\n",
      "Epoch [17/20], Step [160/197], Loss: 2.3531\n",
      "Epoch [17/20], Step [180/197], Loss: 2.5571\n",
      "train Loss: 2.4161 Acc: 0.3718\n",
      "Epoch 17/19\n",
      "----------\n",
      "Epoch [18/20], Step [20/197], Loss: 2.6581\n",
      "Epoch [18/20], Step [40/197], Loss: 2.5017\n",
      "Epoch [18/20], Step [60/197], Loss: 2.3961\n",
      "Epoch [18/20], Step [80/197], Loss: 2.4387\n",
      "Epoch [18/20], Step [100/197], Loss: 2.4416\n",
      "Epoch [18/20], Step [120/197], Loss: 2.3617\n",
      "Epoch [18/20], Step [140/197], Loss: 2.3854\n",
      "Epoch [18/20], Step [160/197], Loss: 2.5622\n",
      "Epoch [18/20], Step [180/197], Loss: 2.5613\n",
      "train Loss: 2.4141 Acc: 0.3730\n",
      "Epoch 18/19\n",
      "----------\n",
      "Epoch [19/20], Step [20/197], Loss: 2.1880\n",
      "Epoch [19/20], Step [40/197], Loss: 2.3888\n",
      "Epoch [19/20], Step [60/197], Loss: 2.4761\n",
      "Epoch [19/20], Step [80/197], Loss: 2.6888\n",
      "Epoch [19/20], Step [100/197], Loss: 2.5024\n",
      "Epoch [19/20], Step [120/197], Loss: 2.3169\n",
      "Epoch [19/20], Step [140/197], Loss: 2.3779\n",
      "Epoch [19/20], Step [160/197], Loss: 2.4787\n",
      "Epoch [19/20], Step [180/197], Loss: 2.3697\n",
      "train Loss: 2.4161 Acc: 0.3722\n",
      "Epoch 19/19\n",
      "----------\n",
      "Epoch [20/20], Step [20/197], Loss: 2.3547\n",
      "Epoch [20/20], Step [40/197], Loss: 2.4323\n",
      "Epoch [20/20], Step [60/197], Loss: 2.4412\n",
      "Epoch [20/20], Step [80/197], Loss: 2.2328\n",
      "Epoch [20/20], Step [100/197], Loss: 2.1650\n",
      "Epoch [20/20], Step [120/197], Loss: 2.2728\n",
      "Epoch [20/20], Step [140/197], Loss: 2.3926\n",
      "Epoch [20/20], Step [160/197], Loss: 2.4975\n",
      "Epoch [20/20], Step [180/197], Loss: 2.4625\n",
      "train Loss: 2.4126 Acc: 0.3710\n",
      "\n",
      "Training complete in 76m 57s\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save the trained model",
   "id": "e4d9605ef361a0d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:49:05.218210Z",
     "start_time": "2024-04-28T14:49:05.134333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pass\n",
    "print('Finished Training')\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "PATH = './models/trained_model.pth'\n",
    "torch.save(model_conv, PATH)"
   ],
   "id": "9f5f26cdefec21bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the model",
   "id": "6f3fea444bec58bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:04:49.378903Z",
     "start_time": "2024-04-28T14:04:49.336438Z"
    }
   },
   "cell_type": "code",
   "source": "trained_model=torch.load('./models/trained_model.pth',map_location=device)",
   "id": "fb1aa946a282ac0f",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate the model",
   "id": "9e3a434c2806a2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:34:09.514119Z",
     "start_time": "2024-04-28T14:34:09.496307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_model(model, dataloader, dataset_size):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "            # Statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ( f'Evaluating: [{i+1}/{test_size}]')\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_acc = running_corrects.double() / dataset_size\n",
    "\n",
    "    print('Test Acc: {:.4f}'.format( test_acc))\n",
    "    "
   ],
   "id": "6488b43f7e58c5d",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T14:37:39.499039Z",
     "start_time": "2024-04-28T14:34:13.135379Z"
    }
   },
   "cell_type": "code",
   "source": "test_model(trained_model, test_loader, test_size)",
   "id": "5b3a78850fc2ef92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: [100/12630]\n",
      "Evaluating: [200/12630]\n",
      "Evaluating: [300/12630]\n",
      "Evaluating: [400/12630]\n",
      "Evaluating: [500/12630]\n",
      "Evaluating: [600/12630]\n",
      "Evaluating: [700/12630]\n",
      "Evaluating: [800/12630]\n",
      "Evaluating: [900/12630]\n",
      "Evaluating: [1000/12630]\n",
      "Evaluating: [1100/12630]\n",
      "Evaluating: [1200/12630]\n",
      "Evaluating: [1300/12630]\n",
      "Evaluating: [1400/12630]\n",
      "Evaluating: [1500/12630]\n",
      "Evaluating: [1600/12630]\n",
      "Evaluating: [1700/12630]\n",
      "Evaluating: [1800/12630]\n",
      "Evaluating: [1900/12630]\n",
      "Evaluating: [2000/12630]\n",
      "Evaluating: [2100/12630]\n",
      "Evaluating: [2200/12630]\n",
      "Evaluating: [2300/12630]\n",
      "Evaluating: [2400/12630]\n",
      "Evaluating: [2500/12630]\n",
      "Evaluating: [2600/12630]\n",
      "Evaluating: [2700/12630]\n",
      "Evaluating: [2800/12630]\n",
      "Evaluating: [2900/12630]\n",
      "Evaluating: [3000/12630]\n",
      "Evaluating: [3100/12630]\n",
      "Evaluating: [3200/12630]\n",
      "Evaluating: [3300/12630]\n",
      "Evaluating: [3400/12630]\n",
      "Evaluating: [3500/12630]\n",
      "Evaluating: [3600/12630]\n",
      "Evaluating: [3700/12630]\n",
      "Evaluating: [3800/12630]\n",
      "Evaluating: [3900/12630]\n",
      "Evaluating: [4000/12630]\n",
      "Evaluating: [4100/12630]\n",
      "Evaluating: [4200/12630]\n",
      "Evaluating: [4300/12630]\n",
      "Evaluating: [4400/12630]\n",
      "Evaluating: [4500/12630]\n",
      "Evaluating: [4600/12630]\n",
      "Evaluating: [4700/12630]\n",
      "Evaluating: [4800/12630]\n",
      "Evaluating: [4900/12630]\n",
      "Evaluating: [5000/12630]\n",
      "Evaluating: [5100/12630]\n",
      "Evaluating: [5200/12630]\n",
      "Evaluating: [5300/12630]\n",
      "Evaluating: [5400/12630]\n",
      "Evaluating: [5500/12630]\n",
      "Evaluating: [5600/12630]\n",
      "Evaluating: [5700/12630]\n",
      "Evaluating: [5800/12630]\n",
      "Evaluating: [5900/12630]\n",
      "Evaluating: [6000/12630]\n",
      "Evaluating: [6100/12630]\n",
      "Evaluating: [6200/12630]\n",
      "Evaluating: [6300/12630]\n",
      "Evaluating: [6400/12630]\n",
      "Evaluating: [6500/12630]\n",
      "Evaluating: [6600/12630]\n",
      "Evaluating: [6700/12630]\n",
      "Evaluating: [6800/12630]\n",
      "Evaluating: [6900/12630]\n",
      "Evaluating: [7000/12630]\n",
      "Evaluating: [7100/12630]\n",
      "Evaluating: [7200/12630]\n",
      "Evaluating: [7300/12630]\n",
      "Evaluating: [7400/12630]\n",
      "Evaluating: [7500/12630]\n",
      "Evaluating: [7600/12630]\n",
      "Evaluating: [7700/12630]\n",
      "Evaluating: [7800/12630]\n",
      "Evaluating: [7900/12630]\n",
      "Evaluating: [8000/12630]\n",
      "Evaluating: [8100/12630]\n",
      "Evaluating: [8200/12630]\n",
      "Evaluating: [8300/12630]\n",
      "Evaluating: [8400/12630]\n",
      "Evaluating: [8500/12630]\n",
      "Evaluating: [8600/12630]\n",
      "Evaluating: [8700/12630]\n",
      "Evaluating: [8800/12630]\n",
      "Evaluating: [8900/12630]\n",
      "Evaluating: [9000/12630]\n",
      "Evaluating: [9100/12630]\n",
      "Evaluating: [9200/12630]\n",
      "Evaluating: [9300/12630]\n",
      "Evaluating: [9400/12630]\n",
      "Evaluating: [9500/12630]\n",
      "Evaluating: [9600/12630]\n",
      "Evaluating: [9700/12630]\n",
      "Evaluating: [9800/12630]\n",
      "Evaluating: [9900/12630]\n",
      "Evaluating: [10000/12630]\n",
      "Evaluating: [10100/12630]\n",
      "Evaluating: [10200/12630]\n",
      "Evaluating: [10300/12630]\n",
      "Evaluating: [10400/12630]\n",
      "Evaluating: [10500/12630]\n",
      "Evaluating: [10600/12630]\n",
      "Evaluating: [10700/12630]\n",
      "Evaluating: [10800/12630]\n",
      "Evaluating: [10900/12630]\n",
      "Evaluating: [11000/12630]\n",
      "Evaluating: [11100/12630]\n",
      "Evaluating: [11200/12630]\n",
      "Evaluating: [11300/12630]\n",
      "Evaluating: [11400/12630]\n",
      "Evaluating: [11500/12630]\n",
      "Evaluating: [11600/12630]\n",
      "Evaluating: [11700/12630]\n",
      "Evaluating: [11800/12630]\n",
      "Evaluating: [11900/12630]\n",
      "Evaluating: [12000/12630]\n",
      "Evaluating: [12100/12630]\n",
      "Evaluating: [12200/12630]\n",
      "Evaluating: [12300/12630]\n",
      "Evaluating: [12400/12630]\n",
      "Evaluating: [12500/12630]\n",
      "Evaluating: [12600/12630]\n",
      "Test Acc: 0.3157\n"
     ]
    }
   ],
   "execution_count": 167
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
