{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "95feb99553e5f381"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-01T21:46:34.075861Z",
     "start_time": "2024-05-01T21:46:31.027629Z"
    }
   },
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import ResNet152_Weights"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T21:46:34.079425Z",
     "start_time": "2024-05-01T21:46:34.077130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(123) # for replication\n",
    "os.makedirs('./models', exist_ok=True)"
   ],
   "id": "625f7f9d2019b024",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Helper functions",
   "id": "920e26d20bf8c3c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T21:46:34.092684Z",
     "start_time": "2024-05-01T21:46:34.080532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_classes_preds(images, labels, preds, probs):\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx + 1, xticks=[], yticks=[])\n",
    "        plt.imshow(np.transpose(images[idx].cpu().numpy(), (1, 2, 0)))  # because is a tensor \n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            preds[idx],\n",
    "            probs[idx] * 100.0,\n",
    "            labels[idx]),\n",
    "            color=(\"green\" if preds[idx] == labels[idx].item() else \"red\"))\n",
    "    return fig"
   ],
   "id": "5b5b2a8dbc382e69",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading the train dataset",
   "id": "1e0e1c4761d44bcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T21:46:34.169030Z",
     "start_time": "2024-05-01T21:46:34.093833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "    #TODO:think a better transformation pipeline\n",
    "    #naive transformation\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dir = './dataset/GTSRB/train'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, train_transform)\n",
    "train_size = len(train_dataset)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "print('Train size:', train_size)\n",
    "print('Class names:', class_names)"
   ],
   "id": "233a264dd2428bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 39209\n",
      "Class names: ['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00015', '00016', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1239b390bd17bb84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading the test dataset",
   "id": "8199467383be87c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T21:46:34.197670Z",
     "start_time": "2024-05-01T21:46:34.170553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_transform = transforms.Compose([\n",
    "    #TODO:think a better transformation pipeline\n",
    "    #naive transformation\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_dir = './dataset/GTSRB/test'\n",
    "\n",
    "test_dataset = datasets.ImageFolder(test_dir, test_transform)\n",
    "test_size = len(test_dataset)\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "print('Test size:', train_size)\n",
    "print('Class names:', class_names)"
   ],
   "id": "4757b88147ac3fbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 39209\n",
      "Class names: ['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00015', '00016', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining the training phase",
   "id": "3191a2bde55202e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T21:46:34.209505Z",
     "start_time": "2024-05-01T21:46:34.198737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(device, model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=25,\n",
    "                model_name='trained_model'):\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Choose the appropriate data loader\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                data_total_steps = len(train_loader)\n",
    "                data_loader = train_loader\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "                data_total_steps = len(val_loader)\n",
    "                data_loader = val_loader\n",
    "\n",
    "            for i, (images, labels) in enumerate(data_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    probs = [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, outputs)]\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                # Calculate entropy with epsilon\n",
    "                softmax_outputs = F.softmax(outputs, dim=1)\n",
    "                epsilon = 1e-10  # Small epsilon value to avoid zero probabilities\n",
    "                entropy = -torch.sum(softmax_outputs * torch.log2(softmax_outputs + epsilon), dim=1).mean()\n",
    "\n",
    "                # Log scalars\n",
    "                if phase == 'train':\n",
    "                    writer.add_scalar('Training/Training Loss',\n",
    "                                      loss.item(),\n",
    "                                      epoch * len(data_loader) + i)\n",
    "                    writer.add_scalar('Policy/Entropy',\n",
    "                                      entropy.item(),\n",
    "                                      epoch * len(data_loader) + i)\n",
    "                    writer.add_scalar('Policy/Learning Rate',\n",
    "                                      np.array(scheduler.get_last_lr()),\n",
    "                                      epoch * len(data_loader) + i)\n",
    "                else:\n",
    "                    writer.add_scalar('Training/Validation Loss',\n",
    "                                      loss.item(),\n",
    "                                      epoch * len(data_loader) + i)\n",
    "\n",
    "                #prints the stats every 20 steps (20 batches performed)\n",
    "                if (i + 1) % int(data_total_steps / 8) == 0:\n",
    "                    print(\n",
    "                        f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{data_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "                    # Log image predictions\n",
    "                    selected_indices = random.sample(range(len(images)), 4)  # Select 4 random indices\n",
    "                    selected_images = images[selected_indices]\n",
    "                    selected_labels = labels[selected_indices]\n",
    "                    selected_preds = preds[selected_indices]\n",
    "                    selected_probs = [probs[i] for i in selected_indices]\n",
    "                    if phase == 'train':\n",
    "                        writer.add_figure('Training/Training Predictions',\n",
    "                                          plot_classes_preds(selected_images, selected_labels, selected_preds,\n",
    "                                                             selected_probs),\n",
    "                                          global_step=epoch * len(data_loader) + i)\n",
    "                    else:\n",
    "                        writer.add_figure('Training/Validation Predictions',\n",
    "                                          plot_classes_preds(selected_images, selected_labels, selected_preds,\n",
    "                                                             selected_probs),\n",
    "                                          global_step=epoch * len(data_loader) + i)\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(data_loader.dataset)\n",
    "\n",
    "            if phase == 'train':\n",
    "                print('{} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    'Train phase - ', epoch + 1, epoch_loss, epoch_acc))\n",
    "                writer.add_scalar('Training/Training Accuracy',\n",
    "                                  running_corrects.double() / len(data_loader.dataset),\n",
    "                                  epoch * len(data_loader))\n",
    "                if (epoch + 1) % max(int(num_epochs / 8), 1) == 0:  # checkpoint the model\n",
    "                    print(\"----> model checkpoint...\")\n",
    "                    torch.save(model, f'./models/trained_model_{model_name}_epoch_{epoch + 1}.pth')\n",
    "            else:\n",
    "                print('{} Epoch {} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    'Validation phase - ', epoch + 1, epoch_loss, epoch_acc))\n",
    "                writer.add_scalar('Training/Validation Accuracy',\n",
    "                                  running_corrects.double() / len(data_loader.dataset),\n",
    "                                  epoch * len(data_loader))\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_dynamic_network(num_features, num_classes, num_layers=0, num_neurons=1):\n",
    "    layers = []\n",
    "    # Input layer to first hidden layer\n",
    "    if num_layers > 0:\n",
    "        layers.append(nn.Linear(num_features, num_neurons))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "    # Additional hidden layers\n",
    "    for _ in range(1, num_layers):\n",
    "        layers.append(nn.Linear(num_neurons, num_neurons))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "    # Always include the final specified layer\n",
    "    layers.append(nn.Linear(num_neurons if num_layers > 0 else num_features, num_classes))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ],
   "id": "d1388a73ca0b9760",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Setup",
   "id": "596398e0642aca56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T21:46:34.261092Z",
     "start_time": "2024-05-01T21:46:34.210555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setting device for the computation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "hyperparams = {\n",
    "    \"num_epochs\": 128,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"gamma\": 0.8,\n",
    "    \"decay_rate\": 0.5,\n",
    "    \"num_layers\": 1, # 0 layers means no hidden layers, just one layer from conv to classes: conv -> layer -> softmax\n",
    "    \"num_neurons\": 400,\n",
    "}"
   ],
   "id": "50d7d9e3cbf71956",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setting up the model using ResNet152 as backbone",
   "id": "7d53679acd744b28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T21:46:35.249862Z",
     "start_time": "2024-05-01T21:46:34.261977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "model_name = 'TSR-SGD-ReLU-optim-plateau-v2'\n",
    "writer = SummaryWriter(f'runs/{model_name}')\n",
    "\n",
    "# Convert config dictionary to a formatted string\n",
    "hyper_str = \"\\n\".join(f\"{key}: {value}\\n\" for key, value in hyperparams.items())\n",
    "writer.add_text('Configuration', hyper_str)\n",
    "\n",
    "# Create DataLoader instances for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=hyperparams[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=hyperparams[\"batch_size\"], shuffle=True)\n",
    "\n",
    "# Model initialization\n",
    "model = torchvision.models.resnet152(weights=ResNet152_Weights.IMAGENET1K_V2)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Define the layers you want to add\n",
    "model.fc = create_dynamic_network(model.fc.in_features, 43, num_layers=hyperparams[\"num_layers\"], num_neurons=hyperparams[\"num_neurons\"])\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function, optimizer, etc.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=hyperparams[\"learning_rate\"], momentum=hyperparams[\"gamma\"])\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=hyperparams[\"decay_rate\"], min_lr=1e-4, mode='min',\n",
    "                                           threshold=1e-4)"
   ],
   "id": "d53ebf690ba17e92",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train the model",
   "id": "6a9c4fc45c415b8f"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-01T21:46:35.250874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train model\n",
    "trained_model = train_model(device=device, model=model, criterion=criterion, optimizer=optimizer, scheduler=scheduler,\n",
    "                            train_loader=train_loader, val_loader=val_loader, num_epochs=hyperparams[\"num_epochs\"],\n",
    "                            model_name=model_name)"
   ],
   "id": "731771455515444c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/128\n",
      "----------\n",
      "Epoch [1/128], Step [3/27], Loss: 3.6733\n",
      "Epoch [1/128], Step [6/27], Loss: 3.4688\n",
      "Epoch [1/128], Step [9/27], Loss: 3.1136\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Saving the trained model",
   "id": "e4d9605ef361a0d3"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print('Finished Training')\n",
    "PATH = f'./models/trained_model_{model_name}_final.pth'\n",
    "torch.save(trained_model, PATH)"
   ],
   "id": "9f5f26cdefec21bb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
