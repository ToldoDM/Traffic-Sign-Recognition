{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "53bb43bad4c869b9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-13T08:43:11.309572Z",
     "start_time": "2024-05-13T08:43:11.294045Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import splitfolders"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Download the dataset",
   "id": "fe6a3582e4f42eab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T08:43:11.387730Z",
     "start_time": "2024-05-13T08:43:11.356447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def download_file(url, file_name):\n",
    "    if not os.path.exists('dataset/' + file_name):\n",
    "        with urllib.request.urlopen(url) as response, open('dataset/' + file_name, 'wb') as out_file:\n",
    "            content_length = int(response.headers['Content-Length'])\n",
    "            with tqdm(total=content_length, unit='B', unit_scale=True, desc=url.split('/')[-1]) as pbar:\n",
    "                while True:\n",
    "                    chunk = response.read(1024)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    out_file.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "    else:\n",
    "        print(f\"{file_name} already exists.\")\n",
    "\n",
    "\n",
    "os.makedirs(\"dataset/\", exist_ok=True)\n",
    "# Training\n",
    "download_file('https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip',\n",
    "              'GTSRB_Final_Training_Images.zip')\n",
    "# Testing\n",
    "download_file('https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip',\n",
    "              'GTSRB_Final_Test_Images.zip')\n",
    "# Ground truth\n",
    "download_file('https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip',\n",
    "              'GTSRB_Final_Test_GT.zip')"
   ],
   "id": "dc01ba7b79c1896f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTSRB_Final_Training_Images.zip already exists.\n",
      "GTSRB_Final_Test_Images.zip already exists.\n",
      "GTSRB_Final_Test_GT.zip already exists.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extract zip files",
   "id": "f905d089f305e5b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T08:44:01.612049Z",
     "start_time": "2024-05-13T08:43:11.387730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_file(file_name):\n",
    "    with zipfile.ZipFile(f\"dataset/{file_name}\", 'r') as zip_ref:\n",
    "        file_list = zip_ref.namelist()\n",
    "        with tqdm(total=len(file_list), desc=\"Extracting\") as pbar:\n",
    "            for file in file_list:\n",
    "                zip_ref.extract(file, 'dataset/')\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "extract_file('GTSRB_Final_Training_Images.zip')\n",
    "extract_file('GTSRB_Final_Test_Images.zip')\n",
    "extract_file('GTSRB_Final_Test_GT.zip')"
   ],
   "id": "3de5a631fc79d888",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 39299/39299 [00:38<00:00, 1013.55it/s]\n",
      "Extracting: 100%|██████████| 12635/12635 [00:10<00:00, 1172.30it/s]\n",
      "Extracting: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading CSV file",
   "id": "323d7c1bb67c1550"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T08:44:01.690180Z",
     "start_time": "2024-05-13T08:44:01.612049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#IMAGES: './dataset/GTSRB/test_images'\n",
    "#CSV ANNOTATIONS: './dataset/GTSRB/test_images/GT-final_test.csv'\n",
    "def csv_loader(csv_path):\n",
    "    data = np.loadtxt(csv_path,\n",
    "                      delimiter=\";\", dtype=str, skiprows=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "#You should download the testset ('GTSRB_Final_Test_Images.zip') from the website which contains only the images\n",
    "#Then you have to download the ground truth csv ('GTSRB_Final_Test_GT.zip') from the website and paste it into the testset images folder\n",
    "annotations = csv_loader('./dataset/GT-final_test.csv')\n",
    "#sort the annotations\n",
    "annotations = annotations[:, [0, 7]]\n",
    "num_samples = len(annotations)\n",
    "#Column 0: filename - Column 1: classid\n",
    "annotations = annotations[annotations[:, 1].astype(int).argsort()]"
   ],
   "id": "468db0ee5cdf9840",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Making training data accordingly",
   "id": "b8b6074543013fbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T08:44:01.877656Z",
     "start_time": "2024-05-13T08:44:01.690180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def move_directories(source, destination):\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "    # Get a list of all directories in the source directory\n",
    "    directories = [d for d in os.listdir(source) if os.path.isdir(os.path.join(source, d))]\n",
    "\n",
    "    # Move each directory to the destination\n",
    "    for directory in tqdm(directories):\n",
    "        source_path = os.path.join(source, directory)\n",
    "        destination_path = os.path.join(destination, directory)\n",
    "        shutil.move(source_path, destination_path)\n",
    "\n",
    "\n",
    "# Move directories with contents\n",
    "move_directories(\"./dataset/GTSRB/Final_Training/Images\", \"./dataset/GTSRB/train\")\n",
    "shutil.rmtree(\"./dataset/GTSRB/Final_Training\")"
   ],
   "id": "61a83a9b0d1825e4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 305.71it/s]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Making test data accordingly",
   "id": "5172c68f192d26ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T08:44:08.455266Z",
     "start_time": "2024-05-13T08:44:01.877656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for class_id in tqdm(np.unique(annotations[:, 1]), desc='Class_ID'):\n",
    "    newpath = './dataset/GTSRB/test/' + class_id.zfill(5)\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    for image_filename in annotations[annotations[:, 1] == class_id]:\n",
    "        shutil.move('./dataset/GTSRB/Final_Test/Images/' + image_filename[0], newpath + '/' + image_filename[0])\n",
    "\n",
    "shutil.rmtree(\"./dataset/GTSRB/Final_Test\")"
   ],
   "id": "df556df8aaf39e91",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class_ID: 100%|██████████| 43/43 [00:06<00:00,  6.58it/s]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merge the dataset and then resplit",
   "id": "a1462fa24b04b512"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T08:45:17.217196Z",
     "start_time": "2024-05-13T08:44:08.455266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory containing the test dataset\n",
    "test_dir = './dataset/GTSRB/test'\n",
    "# Directory containing the train dataset\n",
    "train_dir = './dataset/GTSRB/train'\n",
    "\n",
    "def merge(source_folder, destination_folder):\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Get the total number of files and directories in the source folder\n",
    "    total_items = sum([len(files) + len(dirs) for root, dirs, files in os.walk(source_folder)])\n",
    "\n",
    "    # Initialize tqdm to show progress\n",
    "    progress = tqdm(total=total_items, desc='Moving: ' + source_folder + ' --> ' + destination_folder, position=0, leave=True)\n",
    "\n",
    "    # Iterate over all files and subdirectories in the source folder\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        for item in files + dirs:\n",
    "            source_item = os.path.join(root, item)\n",
    "            destination_item = os.path.join(destination_folder, os.path.relpath(source_item, source_folder))\n",
    "\n",
    "            # If the item is a file, copy it to the destination folder\n",
    "            if os.path.isfile(source_item):\n",
    "                shutil.move(source_item, destination_item)\n",
    "            # If the item is a directory, create it in the destination folder\n",
    "            elif os.path.isdir(source_item):\n",
    "                os.makedirs(destination_item, exist_ok=True)\n",
    "\n",
    "            progress.update(1)  # Update progress bar\n",
    "\n",
    "    progress.close()  # Close tqdm\n",
    "    \n",
    "def merge_folders(source_folders, target_folder):\n",
    "    for sf in source_folders:\n",
    "        merge(sf, target_folder)\n",
    "        shutil.rmtree(sf)\n",
    "\n",
    "# Temporary directory to store the merged dataset\n",
    "merged_dir = \"./dataset/GTSRB/merged\"\n",
    "\n",
    "merge_folders([train_dir,test_dir], merged_dir)\n",
    "\n",
    "# Training 70\n",
    "# Testing 30\n",
    "splitfolders.ratio(merged_dir, output=\"./dataset/GTSRB/\", seed=123, ratio=(.7,0, 0.3),move=True)\n",
    "\n",
    "# Clear temporary folders\n",
    "shutil.rmtree('./dataset/GTSRB/merged')\n",
    "shutil.rmtree('./dataset/GTSRB/val')\n",
    "os.remove('./dataset/GTSRB/Readme-Images-Final-test.txt')\n",
    "os.remove('./dataset/GTSRB/Readme-Images.txt')"
   ],
   "id": "2d76bd67174211eb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving: ./dataset/GTSRB/train --> ./dataset/GTSRB/merged: 100%|██████████| 39295/39295 [00:25<00:00, 1543.81it/s]\n",
      "Moving: ./dataset/GTSRB/test --> ./dataset/GTSRB/merged: 100%|██████████| 12673/12673 [00:07<00:00, 1755.18it/s]\n",
      "Copying files: 51882 files [00:35, 1447.04 files/s]\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
